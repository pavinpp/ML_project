{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Part 1)\n",
    "\n",
    "## Objective\n",
    "The goal of this notebook is to clean and prepare the raw data for our analysis. We are working with three main data sources:\n",
    "1.  **Weather Data:** Rainfall, Solar Radiation, and Temperature.\n",
    "2.  **Crop Yield Data:** Agricultural output (our target variable).\n",
    "3.  **Farming Inputs:** Pesticide and Fertilizer usage.\n",
    "\n",
    "We will convert the data from \"wide\" format (where months are columns) to \"long\" format (where each row represents a specific date) and standardize the country names and dates.\n",
    "\n",
    "### 1. Setup and Library Imports\n",
    "We import the necessary libraries to handle dataframes, mathematical operations, and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988268d",
   "metadata": {},
   "source": [
    "### 2. Locate Raw Data Files\n",
    "We list all the CSV files located in the precipitation, solar radiation, and temperature folders. We will loop through these lists later to process every file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all CSV files in the data folders\n",
    "precipitation_files = sorted(os.listdir(\"Data/precipitation_csv/\"))\n",
    "solar_files = sorted(os.listdir(\"Data/solar_radiation_csv/\"))\n",
    "temp_files = sorted(os.listdir(\"Data/temperature_csv/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define Data Cleaning Functions\n",
    "\n",
    "We define three functions to handle the specific formatting of the weather files. Since the raw data formats are similar, the logic for all three functions is consistent:\n",
    "\n",
    "1.  **Read the file:** Load the CSV and skip the header rows.\n",
    "2.  **Extract Country:** Get the country name directly from the filename.\n",
    "3.  **Reshape Data:** Convert the monthly columns (Jan-Dec) into rows using the `melt` function.\n",
    "4.  **Clean Dates:** Convert month names to numbers and create a standard Date object.\n",
    "5.  **Handle Missing Values:** Replace `-999` (error code) with `NaN` (Not a Number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_rain(f):\n",
    "    # Load file and parse country name from filename\n",
    "    df = pd.read_csv(f\"Data/precipitation_csv/{f}\", header=10)\n",
    "    country = \"_\".join(f.split(\"_\")[:-6])\n",
    "\n",
    "    # Select only relevant columns\n",
    "    df['AREA'] = country\n",
    "    df = df[['AREA','YEAR', \n",
    "    'JAN', 'FEB', 'MAR', \n",
    "    'APR', 'MAY', 'JUN', \n",
    "    'JUL', 'AUG', 'SEP', \n",
    "    'OCT', 'NOV', 'DEC', \n",
    "    'ANN']]\n",
    "\n",
    "    month_cols = ['JAN', 'FEB', 'MAR', \n",
    "    'APR', 'MAY', 'JUN', \n",
    "    'JUL', 'AUG', 'SEP', \n",
    "    'OCT', 'NOV', 'DEC']\n",
    "    \n",
    "    # Melt into long format (Months become rows)\n",
    "    df_long = df.melt(\n",
    "        id_vars=[\"YEAR\", \"AREA\"],\n",
    "        value_vars=month_cols,\n",
    "        var_name=\"MONTH\",\n",
    "        value_name=\"SUM\"\n",
    "    )\n",
    "    \n",
    "    # Clean month name: \"jan_sum\" -> \"jan\"\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].map(lambda x: x.split(\"_\")[0])\n",
    "    \n",
    "    # Convert month abbreviations to numbers\n",
    "    month_map = {\n",
    "        \"JAN\": 1, \"FEB\": 2, \"MAR\": 3, \"APR\": 4, \"MAY\": 5, \"JUN\": 6,\n",
    "        \"JUL\": 7, \"AUG\": 8, \"SEP\": 9, \"OCT\": 10, \"NOV\": 11, \"DEC\": 12\n",
    "    }\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].map(month_map)\n",
    "    \n",
    "    # Sort data\n",
    "    df_long = df_long.sort_values([\"AREA\", \"YEAR\", \"MONTH\"])\n",
    "    df_long = df_long.dropna()\n",
    "    \n",
    "    # Create a proper datetime column\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].astype(int).astype(str).str.zfill(2)\n",
    "    df_long[\"YEAR\"] = df_long[\"YEAR\"].astype(str)\n",
    "    df_long[\"DATE\"] = pd.to_datetime(df_long[\"YEAR\"] + \"-\" + df_long[\"MONTH\"]) + pd.offsets.MonthEnd(0)\n",
    "    \n",
    "    # Rename and clean values\n",
    "    df_long.columns = ['year', 'area', 'month', 'rain', 'date']\n",
    "    df_long[\"rain\"] = df_long[\"rain\"].replace(-999, np.nan)\n",
    "    \n",
    "    return df_long.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_solar(f):\n",
    "    # Load file and parse country name from filename\n",
    "    df = pd.read_csv(f\"Data/solar_radiation_csv/{f}\", header=10)\n",
    "    country = \"_\".join(f.split(\"_\")[:-8])\n",
    "    \n",
    "    df['AREA'] = country\n",
    "    df = df[['AREA','YEAR', \n",
    "    'JAN', 'FEB', 'MAR', \n",
    "    'APR', 'MAY', 'JUN', \n",
    "    'JUL', 'AUG', 'SEP', \n",
    "    'OCT', 'NOV', 'DEC', \n",
    "    'ANN']]\n",
    "\n",
    "    month_cols = ['JAN', 'FEB', 'MAR', \n",
    "    'APR', 'MAY', 'JUN', \n",
    "    'JUL', 'AUG', 'SEP', \n",
    "    'OCT', 'NOV', 'DEC']\n",
    "    \n",
    "    # Melt into long format\n",
    "    df_long = df.melt(\n",
    "        id_vars=[\"YEAR\", \"AREA\"],\n",
    "        value_vars=month_cols,\n",
    "        var_name=\"MONTH\",\n",
    "        value_name=\"SUM\"\n",
    "    )\n",
    "    \n",
    "    # Clean month name\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].map(lambda x: x.split(\"_\")[0])\n",
    "    \n",
    "    # Convert month abbreviations to numbers\n",
    "    month_map = {\n",
    "        \"JAN\": 1, \"FEB\": 2, \"MAR\": 3, \"APR\": 4, \"MAY\": 5, \"JUN\": 6,\n",
    "        \"JUL\": 7, \"AUG\": 8, \"SEP\": 9, \"OCT\": 10, \"NOV\": 11, \"DEC\": 12\n",
    "    }\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].map(month_map)\n",
    "    \n",
    "    # Sort data\n",
    "    df_long = df_long.sort_values([\"AREA\", \"YEAR\", \"MONTH\"])\n",
    "    df_long = df_long.dropna()\n",
    "    \n",
    "    # Create a proper datetime column\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].astype(int).astype(str).str.zfill(2)\n",
    "    df_long[\"YEAR\"] = df_long[\"YEAR\"].astype(str)\n",
    "    df_long[\"DATE\"] = pd.to_datetime(df_long[\"YEAR\"] + \"-\" + df_long[\"MONTH\"]) + pd.offsets.MonthEnd(0)\n",
    "    \n",
    "    # Rename and clean values\n",
    "    df_long.columns = ['year', 'area', 'month', 'solar', 'date']\n",
    "    df_long[\"solar\"] = df_long[\"solar\"].replace(-999, np.nan)\n",
    "\n",
    "    return df_long.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_temp(f):\n",
    "    # Load file and parse country name from filename\n",
    "    df = pd.read_csv(f\"Data/temperature_csv/{f}\", header=10)\n",
    "    country = \"_\".join(f.split(\"_\")[:-5])\n",
    "    \n",
    "    df['AREA'] = country\n",
    "    df = df[['AREA','YEAR', \n",
    "    'JAN', 'FEB', 'MAR', \n",
    "    'APR', 'MAY', 'JUN', \n",
    "    'JUL', 'AUG', 'SEP', \n",
    "    'OCT', 'NOV', 'DEC', \n",
    "    'ANN']]\n",
    "\n",
    "    month_cols = ['JAN', 'FEB', 'MAR', \n",
    "    'APR', 'MAY', 'JUN', \n",
    "    'JUL', 'AUG', 'SEP', \n",
    "    'OCT', 'NOV', 'DEC', \n",
    "    'ANN']\n",
    "    \n",
    "    # Melt into long format\n",
    "    df_long = df.melt(\n",
    "        id_vars=[\"YEAR\", \"AREA\"],\n",
    "        value_vars=month_cols,\n",
    "        var_name=\"MONTH\",\n",
    "        value_name=\"SUM\"\n",
    "    )\n",
    "    \n",
    "    # Clean month name\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].map(lambda x: x.split(\"_\")[0])\n",
    "    \n",
    "    # Convert month abbreviations to numbers\n",
    "    month_map = {\n",
    "        \"JAN\": 1, \"FEB\": 2, \"MAR\": 3, \"APR\": 4, \"MAY\": 5, \"JUN\": 6,\n",
    "        \"JUL\": 7, \"AUG\": 8, \"SEP\": 9, \"OCT\": 10, \"NOV\": 11, \"DEC\": 12\n",
    "    }\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].map(month_map)\n",
    "    \n",
    "    # Sort data\n",
    "    df_long = df_long.sort_values([\"AREA\", \"YEAR\", \"MONTH\"])\n",
    "    df_long = df_long.dropna()\n",
    "    \n",
    "    # Create a proper datetime column\n",
    "    df_long[\"MONTH\"] = df_long[\"MONTH\"].astype(int).astype(str).str.zfill(2)\n",
    "    df_long[\"YEAR\"] = df_long[\"YEAR\"].astype(str)\n",
    "    df_long[\"DATE\"] = pd.to_datetime(df_long[\"YEAR\"] + \"-\" + df_long[\"MONTH\"]) + pd.offsets.MonthEnd(0)\n",
    "    \n",
    "    # Rename and clean values\n",
    "    df_long.columns = ['year', 'area', 'month', 'temp', 'date']\n",
    "    df_long[\"temp\"] = df_long[\"temp\"].replace(-999, np.nan)\n",
    "\n",
    "    return df_long.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Process and Merge Weather Data\n",
    "Now that our functions are defined, we apply them to all the files in our lists. We then combine (concatenate) the results into three main dataframes: one for rain, one for solar radiation, and one for temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the processing functions on all listed files\n",
    "rain_data = pd.concat([prep_rain(f) for f in precipitation_files])\n",
    "solar_data = pd.concat([prep_solar(f) for f in solar_files])\n",
    "temp_data = pd.concat([prep_temp(f) for f in temp_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d14d1c",
   "metadata": {},
   "source": [
    "### 5. Create Final Weather Dataset\n",
    "We merge the three weather datasets into a single dataframe called `nasa_df`. We join them based on `year`, `area`, `date`, and `month` to ensure the rows align correctly. Finally, we save this clean dataset as a Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Rain, Solar, and Temp based on Date and Area\n",
    "nasa_df = rain_data.merge(\n",
    "    solar_data, on=['year', 'area', 'date', 'month']\n",
    ").merge(\n",
    "    temp_data, on=['year', 'area', 'date', 'month']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final columns and save to Parquet format\n",
    "nasa_df = nasa_df[['date', 'area', 'rain', 'solar', 'temp']]\n",
    "nasa_df.to_parquet('Parquet/nasa_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>rain</th>\n",
       "      <th>solar</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-31</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>55.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-02-28</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>85.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-03-31</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>66.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-04-30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>23.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-05-31</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>23.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107839</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.47</td>\n",
       "      <td>18.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107840</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2.65</td>\n",
       "      <td>22.55</td>\n",
       "      <td>23.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107841</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>137.78</td>\n",
       "      <td>23.96</td>\n",
       "      <td>24.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107842</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>27.16</td>\n",
       "      <td>26.16</td>\n",
       "      <td>26.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107843</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>171.60</td>\n",
       "      <td>22.59</td>\n",
       "      <td>24.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107844 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         area    rain  solar   temp\n",
       "0      1981-01-31  Afghanistan   55.53    NaN  -0.95\n",
       "1      1981-02-28  Afghanistan   85.20    NaN   0.97\n",
       "2      1981-03-31  Afghanistan   66.13    NaN   6.18\n",
       "3      1981-04-30  Afghanistan   23.64    NaN  13.07\n",
       "4      1981-05-31  Afghanistan   23.92    NaN  17.61\n",
       "...           ...          ...     ...    ...    ...\n",
       "107839 2023-08-31     Zimbabwe    0.10  19.47  18.23\n",
       "107840 2023-09-30     Zimbabwe    2.65  22.55  23.64\n",
       "107841 2023-10-31     Zimbabwe  137.78  23.96  24.80\n",
       "107842 2023-11-30     Zimbabwe   27.16  26.16  26.37\n",
       "107843 2023-12-31     Zimbabwe  171.60  22.59  24.48\n",
       "\n",
       "[107844 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the result\n",
    "nasa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Process Crop Yield Data\n",
    "In this section, we prepare the target variable (crop yield).\n",
    "1.  We load the raw CSV file.\n",
    "2.  We clean the column names for consistency.\n",
    "3.  We standardize the `Area` names (replacing spaces with underscores).\n",
    "4.  We format the `Year` column to be a full date object (set to December 31st of that year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw yield data\n",
    "yield_crop = pd.read_csv('Data/yield_final.csv')\n",
    "\n",
    "# Select relevant columns\n",
    "yield_crop = yield_crop[['Area', 'Item', 'Year', 'Yield (kg/ha)']]\n",
    "\n",
    "# Rename columns to lower case\n",
    "yield_crop.columns = ['area', 'item', 'year', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Area names (replace spaces with underscores)\n",
    "yield_crop['area'] = yield_crop['area'].str.replace(' ', '_')\n",
    "\n",
    "# Convert Year to a full date (set to end of year)\n",
    "yield_crop['year'] = yield_crop['year'].map(lambda x: date(int(x), 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed yield data\n",
    "yield_crop.to_parquet('Parquet/label_yield.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>item</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Maize (corn)</td>\n",
       "      <td>1970-12-31</td>\n",
       "      <td>1475.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Maize (corn)</td>\n",
       "      <td>1971-12-31</td>\n",
       "      <td>1340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Maize (corn)</td>\n",
       "      <td>1972-12-31</td>\n",
       "      <td>1565.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Maize (corn)</td>\n",
       "      <td>1973-12-31</td>\n",
       "      <td>1617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Maize (corn)</td>\n",
       "      <td>1974-12-31</td>\n",
       "      <td>1617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89255</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Watermelons</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89256</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Watermelons</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>36000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89257</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Watermelons</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>31377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89258</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Watermelons</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>33841.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89259</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Watermelons</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>32668.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89260 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              area          item        year    label\n",
       "0      Afghanistan  Maize (corn)  1970-12-31   1475.7\n",
       "1      Afghanistan  Maize (corn)  1971-12-31   1340.0\n",
       "2      Afghanistan  Maize (corn)  1972-12-31   1565.2\n",
       "3      Afghanistan  Maize (corn)  1973-12-31   1617.0\n",
       "4      Afghanistan  Maize (corn)  1974-12-31   1617.0\n",
       "...            ...           ...         ...      ...\n",
       "89255     Zimbabwe   Watermelons  2019-12-31  25000.0\n",
       "89256     Zimbabwe   Watermelons  2020-12-31  36000.0\n",
       "89257     Zimbabwe   Watermelons  2021-12-31  31377.0\n",
       "89258     Zimbabwe   Watermelons  2022-12-31  33841.3\n",
       "89259     Zimbabwe   Watermelons  2023-12-31  32668.1\n",
       "\n",
       "[89260 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the result\n",
    "yield_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809416b",
   "metadata": {},
   "source": [
    "### 7. Process Pesticides & Fertilizers\n",
    "We incorporate data on farming inputs, which are key features for our model.\n",
    "\n",
    "**Steps taken:**\n",
    "1.  **Load Data:** Read the pesticide and fertilizer CSV files.\n",
    "2.  **Merge:** Combine them into one dataframe based on Country and Year.\n",
    "3.  **Standardize Country Names:** The raw data uses different spellings for countries (e.g., \"Turkey\" vs. \"Turkiye\"). We apply a dictionary mapping to ensure these names match our other datasets.\n",
    "4.  **Format Dates:** Convert the year into a standardized date format.\n",
    "5.  **Save:** Export the final cleaned dataframe to Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0850559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (14977, 4)\n",
      "          area        year  pesticides  fertilizer\n",
      "0  Afghanistan  1970-12-31         NaN    2.465057\n",
      "1  Afghanistan  1971-12-31         NaN    2.594937\n",
      "2  Afghanistan  1972-12-31         NaN    3.680152\n",
      "3  Afghanistan  1973-12-31         NaN    3.109987\n",
      "4  Afghanistan  1974-12-31         NaN    4.285714\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# 1. Load the datasets\n",
    "pesticides_df = pd.read_csv('Data/pesticides.csv')\n",
    "fertilizer_df = pd.read_csv('Data/fertilizer.csv')\n",
    "\n",
    "# 2. Merge them on 'Area' and 'Year'\n",
    "# Using outer join to keep all records from both files\n",
    "farming_df = pd.merge(pesticides_df, fertilizer_df, on=['Area', 'Year'], how='outer')\n",
    "\n",
    "# 3. Define the renaming dictionary based on your standard list\n",
    "area_mapping = {\n",
    "    \"Bolivia\": \"Bolivia (Plurinational State of)\",\n",
    "    \"Congo, Dem. Rep.\": \"Democratic Republic of the Congo\",\n",
    "    \"Congo, Rep.\": \"Congo\",\n",
    "    \"Cote d'Ivoire\": \"Côte d'Ivoire\",\n",
    "    \"Gambia, The\": \"Gambia\",\n",
    "    \"Hong Kong SAR, China\": \"China, Hong Kong SAR\",\n",
    "    \"Iran, Islamic Rep.\": \"Iran (Islamic Republic of)\",\n",
    "    \"Korea, Dem. People's Rep.\": \"Democratic People's Republic of Korea\",\n",
    "    \"Korea, Rep.\": \"Republic of Korea\",\n",
    "    \"Kyrgyz Republic\": \"Kyrgyzstan\",\n",
    "    \"Lao PDR\": \"Lao People's Democratic Republic\",\n",
    "    \"Micronesia, Fed. Sts.\": \"Micronesia (Federated States of)\",\n",
    "    \"Moldova\": \"Republic of Moldova\",\n",
    "    \"Netherlands\": \"Netherlands (Kingdom of the)\",\n",
    "    \"St. Kitts and Nevis\": \"Saint Kitts and Nevis\",\n",
    "    \"St. Lucia\": \"Saint Lucia\",\n",
    "    \"St. Vincent and the Grenadines\": \"Saint Vincent and the Grenadines\",\n",
    "    \"Slovak Republic\": \"Slovakia\",\n",
    "    \"Taiwan, China\": \"China, Taiwan Province of\",\n",
    "    \"Tanzania\": \"United Republic of Tanzania\",\n",
    "    \"Turkey\": \"Türkiye\",\n",
    "    \"Turkiye\": \"Türkiye\",\n",
    "    \"United Kingdom\": \"United Kingdom of Great Britain and Northern Ireland\",\n",
    "    \"United States\": \"United States of America\",\n",
    "    \"Venezuela, RB\": \"Venezuela (Bolivarian Republic of)\",\n",
    "    \"West Bank and Gaza\": \"Palestine\",\n",
    "    \"Yemen, Rep.\": \"Yemen\"\n",
    "}\n",
    "\n",
    "# 4. Apply the renaming\n",
    "farming_df['Area'] = farming_df['Area'].replace(area_mapping)\n",
    "\n",
    "# 5. Convert Year to a full date (set to end of year)\n",
    "# Drop rows with missing years (if any) and ensure integer type\n",
    "farming_df = farming_df.dropna(subset=['Year'])\n",
    "farming_df['Year'] = farming_df['Year'].astype(int)\n",
    "farming_df['Year'] = farming_df['Year'].map(lambda x: date(int(x), 12, 31))\n",
    "\n",
    "# 6. Standardize column names to lowercase\n",
    "farming_df.columns = farming_df.columns.str.lower()\n",
    "\n",
    "# 7. Save to Parquet\n",
    "farming_df.to_parquet('Parquet/farming_df.parquet', index=False)\n",
    "\n",
    "# Verification\n",
    "print(\"Shape:\", farming_df.shape)\n",
    "print(farming_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
