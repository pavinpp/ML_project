{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5986cd18",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction: PyTorch LSTM with Optuna (Part 5)\n",
    "\n",
    "## Overview\n",
    "This notebook trains a **Long Short-Term Memory (LSTM) Network** to predict crop yields. LSTMs are specialized neural networks designed to capture temporal dependencies in sequential data, making them ideal for time-series forecasting compared to standard Feedforward Networks.\n",
    "\n",
    "## Methodology\n",
    "1.  **Crop Selection:** Choose the specific crop to predict.\n",
    "2.  **Feature Analysis:** Review the input variables.\n",
    "3.  **Time-Series Split:** Divide data by year to ensure we don't predict the past using the future.\n",
    "4.  **Data Scaling & Sequence Generation:** Normalize features and create **3D sequences (Batch, Seq_Len, Features)** required for LSTM input. We use a **Sequence Length of 2**.\n",
    "5.  **Baseline:** Compare against a simple guess (Last Year's Yield).\n",
    "6.  **Initial Model:** Train a default LSTM model and check learning curves.\n",
    "7.  **Optimization:** Use **Optuna** to automatically find the best LSTM architecture (layers, hidden size, dropout) and hyperparameters.\n",
    "8.  **Final Evaluation:** Compare accuracy (RMSE) across all stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a747c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Optuna Visualization Tools\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008b386",
   "metadata": {},
   "source": [
    "### 1. Data Preparation and Crop Choice\n",
    "We load the main dataset and identify the available crops. For this analysis, we focus specifically on **Rice**. We clean the data by removing columns related to other crops and deleting any rows where the target yield information is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d2aa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Available Crops found in Dataset ---\n",
      "['bananas', 'barley', 'cassava_fresh', 'cucumbers_and_gherkins', 'maize_corn', 'oil_palm_fruit', 'other_vegetables_fresh_nec', 'potatoes', 'rice', 'soya_beans', 'sugar_beet', 'sugar_cane', 'tomatoes', 'watermelons', 'wheat']\n",
      "----------------------------------------\n",
      "Predicting Target: Y_rice\n",
      "Using Lag 1 Feature: avg_yield_rice_1y\n",
      "Data Loaded. Rows with valid target: 4729\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_parquet('Parquet/XY_v2.parquet')\n",
    "\n",
    "# --- LIST AVAILABLE CROPS ---\n",
    "# Assumes targets start with 'Y_'\n",
    "target_columns = [col for col in df.columns if col.startswith('Y_')]\n",
    "available_crops = [col.replace('Y_', '') for col in target_columns]\n",
    "\n",
    "print(\"--- Available Crops found in Dataset ---\")\n",
    "print(available_crops)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- CONFIGURATION: SET CROP HERE ---\n",
    "CHOSEN_CROP = 'rice'  # <--- CHANGE THIS to 'lettuce', 'pepper', etc. based on list above\n",
    "# ------------------------------------\n",
    "\n",
    "# Define Target and Dynamic Lag Features\n",
    "TARGET_COL = f'Y_{CHOSEN_CROP}'\n",
    "LAG_1_FEATURE = f'avg_yield_{CHOSEN_CROP}_1y'\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target {TARGET_COL} not found in dataset. Check spelling.\")\n",
    "\n",
    "print(f\"Predicting Target: {TARGET_COL}\")\n",
    "print(f\"Using Lag 1 Feature: {LAG_1_FEATURE}\")\n",
    "\n",
    "# Clean Missing Targets for the chosen crop\n",
    "df_model = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "print(f\"Data Loaded. Rows with valid target: {len(df_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce99f69",
   "metadata": {},
   "source": [
    "### 2. Selecting Features, Splitting, and Sequence Generation\n",
    "We identify the input variables. We split data by year to avoid data leakage. \n",
    "\n",
    "**Crucially, for LSTMs:**\n",
    "1. We scale the data (StandardScaler).\n",
    "2. We transform the 2D feature matrix into **3D sequences**.  \n",
    "   * **Sequence Length = 2**: We look at the data from the previous step and the current step to predict the target.\n",
    "   * Input Shape: `(Batch_Size, Sequence_Length, Features)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7734c123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Features Used: 23\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature Name</th>\n",
       "      <td>year</td>\n",
       "      <td>avg_yield_rice_1y</td>\n",
       "      <td>avg_yield_rice_3y</td>\n",
       "      <td>avg_yield_rice_5y</td>\n",
       "      <td>sum_rain_winter</td>\n",
       "      <td>sum_rain_spring</td>\n",
       "      <td>sum_rain_summer</td>\n",
       "      <td>sum_rain_autumn</td>\n",
       "      <td>sum_rain_annual</td>\n",
       "      <td>avg_solar_winter</td>\n",
       "      <td>...</td>\n",
       "      <td>avg_solar_annual</td>\n",
       "      <td>avg_temp_winter</td>\n",
       "      <td>avg_temp_spring</td>\n",
       "      <td>avg_temp_summer</td>\n",
       "      <td>avg_temp_autumn</td>\n",
       "      <td>avg_temp_annual</td>\n",
       "      <td>pesticides_lag1</td>\n",
       "      <td>fertilizer_lag1</td>\n",
       "      <td>latitude</td>\n",
       "      <td>longitude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                  1                  2                  3   \\\n",
       "Feature Name  year  avg_yield_rice_1y  avg_yield_rice_3y  avg_yield_rice_5y   \n",
       "\n",
       "                           4                5                6   \\\n",
       "Feature Name  sum_rain_winter  sum_rain_spring  sum_rain_summer   \n",
       "\n",
       "                           7                8                 9   ...  \\\n",
       "Feature Name  sum_rain_autumn  sum_rain_annual  avg_solar_winter  ...   \n",
       "\n",
       "                            13               14               15  \\\n",
       "Feature Name  avg_solar_annual  avg_temp_winter  avg_temp_spring   \n",
       "\n",
       "                           16               17               18  \\\n",
       "Feature Name  avg_temp_summer  avg_temp_autumn  avg_temp_annual   \n",
       "\n",
       "                           19               20        21         22  \n",
       "Feature Name  pesticides_lag1  fertilizer_lag1  latitude  longitude  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Data Shapes (Batch, Seq_Len, Features):\n",
      "Training:   (3578, 2, 23)\n",
      "Validation: (574, 2, 23)\n",
      "Testing:    (574, 2, 23)\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS (Add these if not already present) ---\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# --- DROP UNWANTED COLUMNS ---\n",
    "# Drop all columns that start with \"avg_yield_\" but do NOT match the chosen crop\n",
    "cols_to_drop = [c for c in df_model.columns \n",
    "                if c.startswith(\"avg_yield_\") and CHOSEN_CROP not in c]\n",
    "\n",
    "df_model = df_model.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- FEATURE SELECTION ---\n",
    "# Select independent variables (exclude 'Y_' columns and metadata)\n",
    "feature_cols = [c for c in df_model.columns \n",
    "                if not c.startswith('Y_') and c not in ['area']]\n",
    "\n",
    "# --- DISPLAY FEATURES TABLE ---\n",
    "print(f\"Total Features Used: {len(feature_cols)}\")\n",
    "print(\"-\" * 30)\n",
    "feature_preview = pd.DataFrame(feature_cols, columns=['Feature Name']).T\n",
    "display(feature_preview)\n",
    "\n",
    "# --- TIME-SERIES SPLIT ---\n",
    "TRAIN_END_YEAR = 2014\n",
    "VAL_END_YEAR = 2019\n",
    "\n",
    "# 1. Training Set (< 2014)\n",
    "mask_train = df_model['year'] < TRAIN_END_YEAR\n",
    "X_train_raw = df_model[mask_train][feature_cols]\n",
    "y_train = df_model[mask_train][TARGET_COL]\n",
    "\n",
    "# 2. Validation Set (>= 2014 and < 2019)\n",
    "mask_val = (df_model['year'] >= TRAIN_END_YEAR) & (df_model['year'] < VAL_END_YEAR)\n",
    "X_val_raw = df_model[mask_val][feature_cols]\n",
    "y_val = df_model[mask_val][TARGET_COL]\n",
    "\n",
    "# 3. Test Set (>= 2019)\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "X_test_raw = df_model[mask_test][feature_cols]\n",
    "y_test = df_model[mask_test][TARGET_COL]\n",
    "\n",
    "# --- IMPUTATION (Handle NaNs before scaling) ---\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train_raw), columns=feature_cols)\n",
    "X_val_imputed = pd.DataFrame(imputer.transform(X_val_raw), columns=feature_cols)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test_raw), columns=feature_cols)\n",
    "\n",
    "# --- SCALING (Required for LSTMs) ---\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_imputed)\n",
    "X_val = scaler.transform(X_val_imputed)\n",
    "X_test = scaler.transform(X_test_imputed)\n",
    "\n",
    "# --- LSTM SEQUENCE GENERATION ---\n",
    "SEQ_LEN = 2\n",
    "\n",
    "def create_sequences(data, targets, seq_len):\n",
    "    \"\"\"\n",
    "    Creates sliding window sequences for LSTM input.\n",
    "    Input Shape: (N, Features) -> Output Shape: (N - Seq_Len + 1, Seq_Len, Features)\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    # We iterate such that we can form a sequence of length seq_len\n",
    "    for i in range(len(data) - seq_len + 1):\n",
    "        x = data[i:(i + seq_len)]\n",
    "        # The target is the value corresponding to the LAST step in the sequence\n",
    "        y = targets[i + seq_len - 1]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences for all splits\n",
    "# Note: This slightly reduces the number of samples by (SEQ_LEN - 1)\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, SEQ_LEN)\n",
    "X_val_seq, y_val_seq = create_sequences(X_val, y_val.values, SEQ_LEN)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test.values, SEQ_LEN)\n",
    "\n",
    "# Convert to PyTorch Tensors (batch_first=True)\n",
    "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_seq, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val_seq, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"\\nLSTM Data Shapes (Batch, Seq_Len, Features):\")\n",
    "print(f\"Training:   {X_train_seq.shape}\")\n",
    "print(f\"Validation: {X_val_seq.shape}\")\n",
    "print(f\"Testing:    {X_test_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1eb4cf",
   "metadata": {},
   "source": [
    "### 3. Setting a Baseline\n",
    "Before using complex AI, we create a simple baseline to measure success. We assume that the yield this year will be exactly the same as last year. \n",
    "\n",
    "*Note: Because sequence generation removed the first `SEQ_LEN - 1` rows, we must align our baseline comparison to the remaining `y_test_seq`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d488f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE (Aligned): 533.91\n"
     ]
    }
   ],
   "source": [
    "# Baseline: yield(t) = yield(t-1)\n",
    "# We extract the Lag 1 feature corresponding to the test set sequences\n",
    "# X_test_seq has shape (N, 2, Feats). We want the feature at the last time step\n",
    "# corresponding to LAG_1_FEATURE.\n",
    "\n",
    "# Find index of lag feature\n",
    "lag_idx = feature_cols.index(LAG_1_FEATURE)\n",
    "\n",
    "# Extract the feature from the sequences (last time step in the window)\n",
    "# But wait! The LSTM input 'X' is scaled. We need unscaled values for meaningful RMSE.\n",
    "# It is easier to pull the unscaled targets directly from the original dataframe index alignment.\n",
    "\n",
    "# Get original indices after sequence trimming\n",
    "test_indices = y_test.index[SEQ_LEN - 1:]\n",
    "\n",
    "# Get predictions (Last year's yield) for these indices\n",
    "y_pred_baseline = df_model.loc[test_indices, LAG_1_FEATURE]\n",
    "y_true_aligned = df_model.loc[test_indices, TARGET_COL]\n",
    "\n",
    "# Clean NaNs for metric calculation\n",
    "mask_valid = ~y_pred_baseline.isna() & ~y_true_aligned.isna()\n",
    "y_test_clean = y_true_aligned[mask_valid]\n",
    "y_pred_clean = y_pred_baseline[mask_valid]\n",
    "\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test_clean, y_pred_clean))\n",
    "r2_baseline = r2_score(y_test_clean, y_pred_clean)\n",
    "\n",
    "print(f\"Baseline RMSE (Aligned): {rmse_baseline:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607fbb7",
   "metadata": {},
   "source": [
    "### 4. Initial Model Testing (LSTM)\n",
    "We train a basic **LSTM** model using standard settings. We plot the training vs validation loss to check for overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774242a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Initial LSTM Model...\n",
      "Epoch 0/200 | Train RMSE: 3827.83 | Val RMSE: 4578.60\n",
      "Epoch 20/200 | Train RMSE: 3238.25 | Val RMSE: 3987.74\n",
      "Epoch 40/200 | Train RMSE: 2726.66 | Val RMSE: 3458.20\n",
      "Epoch 60/200 | Train RMSE: 2266.70 | Val RMSE: 2963.69\n",
      "Epoch 80/200 | Train RMSE: 1874.99 | Val RMSE: 2523.29\n",
      "Epoch 100/200 | Train RMSE: 1543.63 | Val RMSE: 2140.76\n",
      "Epoch 120/200 | Train RMSE: 1267.10 | Val RMSE: 1814.72\n",
      "Epoch 140/200 | Train RMSE: 1040.93 | Val RMSE: 1553.82\n"
     ]
    }
   ],
   "source": [
    "# --- DEFINE LSTM STRUCTURE ---\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_layers, dropout):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM Layer\n",
    "        # batch_first=True means input shape is (batch, seq, feature)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Fully Connected Layer (Output)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# --- TRAINING HELPER FUNCTION ---\n",
    "#def train_model(model, X_t, y_t, X_v, y_v, lr=0.05, epochs=150, batch_size=32, verbose=True):\n",
    "def train_model(model, X_t, y_t, X_v, y_v, lr = 0.005,batch_size = 16,epochs = 200,dropout = 0.2,num_layers = 2,hidden_units = 24, verbose=True):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_t, y_t), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * batch_X.size(0)\n",
    "            \n",
    "        # Calculate average losses (RMSE representation)\n",
    "        train_mse = epoch_loss / len(X_t)\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_v)\n",
    "            val_loss = criterion(val_outputs, y_v)\n",
    "            val_rmse = np.sqrt(val_loss.item())\n",
    "            \n",
    "        train_losses.append(train_rmse)\n",
    "        val_losses.append(val_rmse)\n",
    "        \n",
    "        if verbose and (epoch % 20 == 0 or epoch == epochs-1):\n",
    "            print(f\"Epoch {epoch}/{epochs} | Train RMSE: {train_rmse:.2f} | Val RMSE: {val_rmse:.2f}\")\n",
    "            \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# --- INITIAL MODEL TRAINING ---\n",
    "input_dim = X_train_seq.shape[2] # Number of features\n",
    "\n",
    "# Initial Config\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "\n",
    "model_init = LSTMRegressor(input_dim, HIDDEN_SIZE, NUM_LAYERS, DROPOUT).to(device)\n",
    "\n",
    "print(\"Training Initial LSTM Model...\")\n",
    "train_hist, val_hist = train_model(model_init, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)\n",
    "\n",
    "# --- PLOT LEARNING CURVE ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_hist, label='Training RMSE', color='blue')\n",
    "plt.plot(val_hist, label='Validation RMSE', color='red')\n",
    "plt.title(f'LSTM Learning Curve ({CHOSEN_CROP})', fontsize=15)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on TEST Set\n",
    "model_init.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_init_test = model_init(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "rmse_init_test = np.sqrt(mean_squared_error(y_test_seq, y_pred_init_test))\n",
    "r2_init_test = r2_score(y_test_seq, y_pred_init_test)\n",
    "\n",
    "print(f\"Initial LSTM Test RMSE: {rmse_init_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d9630",
   "metadata": {},
   "source": [
    "### 5. Tuning the Model (Optuna)\n",
    "To improve performance, we use **Optuna** to find the best LSTM architecture. We run trials adjusting hidden size, number of layers, dropout rate, learning rate, and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596a1556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 15:58:07,437] A new study created in memory with name: Rice_Yield_LSTM\n",
      "[W 2025-11-29 15:58:33,885] Trial 0 failed with parameters: {'hidden_size': 19, 'num_layers': 2, 'dropout': 0.1225427497104476, 'lr': 0.0010015052772023086, 'batch_size': 8} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Temp\\ipykernel_23504\\3705250164.py\", line 32, in objective\n",
      "    loss.backward()\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-29 15:58:33,926] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m study_name = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHOSEN_CROP.capitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_Yield_LSTM\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     51\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m, study_name=study_name)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest Parameters found:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     30\u001b[39m     outputs = model(batch_X)\n\u001b[32m     31\u001b[39m     loss = criterion(outputs, batch_y)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     optimizer.step()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Evaluate on Validation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- OPTUNA OBJECTIVE FUNCTION FOR LSTM ---\n",
    "def objective(trial):\n",
    "    # 1. Suggest Hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 64)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.3)\n",
    "    lr = trial.suggest_float(\"lr\", 0.0005, 0.0015)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    \n",
    "    # LSTM requires dropout=0 if num_layers=1, handle this\n",
    "    if num_layers == 1:\n",
    "        dropout = 0.0\n",
    "\n",
    "    # 2. Build Model\n",
    "    model = LSTMRegressor(input_dim, hidden_size, num_layers, dropout).to(device)\n",
    "    \n",
    "    # 3. Setup Training\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), \n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 4. Training Loop with Pruning\n",
    "    epochs = 50  # Shorter epoch count for tuning speed\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate on Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_tensor)\n",
    "            val_mse = criterion(val_pred, y_val_tensor).item()\n",
    "            val_rmse = np.sqrt(val_mse)\n",
    "\n",
    "        # Pruning check\n",
    "        trial.report(val_rmse, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_rmse\n",
    "\n",
    "# --- RUN OPTIMIZATION ---\n",
    "study_name = f'{CHOSEN_CROP.capitalize()}_Yield_LSTM'\n",
    "study = optuna.create_study(direction='minimize', study_name=study_name)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"\\nBest Parameters found:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a3401",
   "metadata": {},
   "source": [
    "### 6. Visualizing Optimization\n",
    "We generate charts to understand the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d396ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OPTUNA VISUALIZATIONS ---\n",
    "name = f\"{CHOSEN_CROP.capitalize()}_Yield_LSTM\"\n",
    "\n",
    "# 1. Optimization History\n",
    "fig = plot_optimization_history(study)\n",
    "fig.update_layout(title=f'{name} Optimization History', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "# 2. Parallel Coordinate (Hyperparameter Relationships)\n",
    "fig = plot_parallel_coordinate(study)\n",
    "fig.update_layout(title=f'{name} Parallel Coordinate Plot', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "# 3. Slice Plot (Individual Parameter impact)\n",
    "fig = plot_slice(study)\n",
    "fig.update_layout(title=f'{name} Slice Plot', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "# 4. Parameter Importance\n",
    "try:\n",
    "    fig = plot_param_importances(study)\n",
    "    fig.update_layout(title=f'{name} Hyperparameter Importance', width=900, height=500)\n",
    "    fig.show()\n",
    "except (ValueError, RuntimeError) as e:\n",
    "    print(f'Could not plot parameter importance: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99bf3cf",
   "metadata": {},
   "source": [
    "### 7. Final Model Training\n",
    "Using the best settings found during the tuning phase, we build the final LSTM model. We train this model on both the Training and Validation data combined to maximize learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Combine Train + Validation for Final Training (Sequences)\n",
    "X_train_full_seq = np.concatenate((X_train_seq, X_val_seq), axis=0)\n",
    "y_train_full_seq = np.concatenate((y_train_seq, y_val_seq), axis=0)\n",
    "\n",
    "X_train_full_tensor = torch.tensor(X_train_full_seq, dtype=torch.float32).to(device)\n",
    "y_train_full_tensor = torch.tensor(y_train_full_seq, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# 2. Retrieve Best Params\n",
    "bp = study.best_params\n",
    "\n",
    "# Handle LSTM dropout rule for 1 layer again\n",
    "final_dropout = bp['dropout']\n",
    "if bp['num_layers'] == 1:\n",
    "    final_dropout = 0.0\n",
    "\n",
    "# 3. Initialize Best Model\n",
    "final_model = LSTMRegressor(\n",
    "    input_dim,\n",
    "    bp['hidden_size'], \n",
    "    bp['num_layers'], \n",
    "    final_dropout\n",
    ").to(device)\n",
    "\n",
    "# 4. Train on Full History\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=bp['lr'])\n",
    "criterion = nn.MSELoss()\n",
    "train_loader = DataLoader(TensorDataset(X_train_full_tensor, y_train_full_tensor), \n",
    "                          batch_size=bp['batch_size'], shuffle=True)\n",
    "\n",
    "print(\"Training Final LSTM Model...\")\n",
    "final_model.train()\n",
    "for epoch in range(150):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 5. Final Prediction on TEST Data\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_final_test = final_model(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "rmse_final_test = np.sqrt(mean_squared_error(y_test_seq, y_pred_final_test))\n",
    "r2_final_test = r2_score(y_test_seq, y_pred_final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1bd7",
   "metadata": {},
   "source": [
    "### 8. Results and Analysis\n",
    "We evaluate the final performance on the Test data.\n",
    "* **Comparison:** We check if the Tuned Model beats the Baseline and the Initial Model.\n",
    "* **Trend Analysis:** We plot the predicted yields against actual yields over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Improvement %\n",
    "imp_final = (rmse_baseline - rmse_final_test) / rmse_baseline * 100\n",
    "\n",
    "print(\"--- Final Performance Report (Test Set) ---\")\n",
    "print(f\"Baseline RMSE (Aligned): {rmse_baseline:.2f}\")\n",
    "print(f\"Initial LSTM Model RMSE: {rmse_init_test:.2f}\")\n",
    "print(f\"Tuned LSTM Model RMSE:   {rmse_final_test:.2f} (Improvement: {imp_final:.2f}%)\")\n",
    "print(f\"Tuned LSTM R2:           {r2_final_test:.4f}\")\n",
    "\n",
    "# --- PLOTTING RESULTS ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Axis Limits\n",
    "all_preds = np.concatenate([y_pred_clean, y_pred_init_test, y_pred_final_test])\n",
    "all_true = np.concatenate([y_test_clean, y_test_seq, y_test_seq])\n",
    "min_val, max_val = min(min(all_preds), min(all_true)), max(max(all_preds), max(all_true))\n",
    "\n",
    "# 1. Baseline Plot\n",
    "axes[0].scatter(y_test_clean, y_pred_clean, alpha=0.4, color='blue')\n",
    "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[0].set_title(f'Baseline Model\\nRMSE: {rmse_baseline:.2f}')\n",
    "\n",
    "# 2. Initial Model Plot\n",
    "axes[1].scatter(y_test_seq, y_pred_init_test, alpha=0.4, color='orange')\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[1].set_title(f'Initial LSTM Model\\nRMSE: {rmse_init_test:.2f}')\n",
    "\n",
    "# 3. Tuned Model Plot\n",
    "axes[2].scatter(y_test_seq, y_pred_final_test, alpha=0.4, color='green')\n",
    "axes[2].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[2].set_title(f'Tuned LSTM Model\\nRMSE: {rmse_final_test:.2f}')\n",
    "\n",
    "plt.suptitle(f'{CHOSEN_CROP.capitalize()} Yield: Performance Comparison (Actual vs Predicted)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FULL TIMELINE PLOT ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To plot the full timeline, we need to generate sequences for the entire dataset.\n",
    "# Note: create_sequences trims the first (SEQ_LEN-1) rows.\n",
    "X_all_scaled = scaler.transform(df_model[feature_cols])\n",
    "X_all_seq, _ = create_sequences(X_all_scaled, df_model[TARGET_COL].values, SEQ_LEN)\n",
    "X_all_tensor = torch.tensor(X_all_seq, dtype=torch.float32).to(device)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    all_predictions = final_model(X_all_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Align Dates (Slice off the first SEQ_LEN-1 years)\n",
    "aligned_years = df_model['year'].values[SEQ_LEN - 1:]\n",
    "aligned_actuals = df_model[TARGET_COL].values[SEQ_LEN - 1:]\n",
    "\n",
    "# 2. Create DataFrame\n",
    "df_full_trend = pd.DataFrame({\n",
    "    'Year': aligned_years,\n",
    "    'Actual': aligned_actuals,\n",
    "    'Predicted': all_predictions\n",
    "})\n",
    "\n",
    "# Aggregate by Year\n",
    "yearly_trend = df_full_trend.groupby('Year').mean()\n",
    "\n",
    "# 3. Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot Lines\n",
    "plt.plot(yearly_trend.index, yearly_trend['Actual'], \n",
    "         marker='o', label='Actual Yield', linewidth=2, color='blue')\n",
    "plt.plot(yearly_trend.index, yearly_trend['Predicted'], \n",
    "         marker='x', linestyle='--', label='Predicted Yield', linewidth=2, color='orange')\n",
    "\n",
    "# Define Split Boundaries\n",
    "MIN_YEAR = yearly_trend.index.min()\n",
    "MAX_YEAR = yearly_trend.index.max()\n",
    "train_boundary = TRAIN_END_YEAR - 0.5\n",
    "val_boundary = VAL_END_YEAR - 0.5\n",
    "\n",
    "# --- Highlight Periods ---\n",
    "plt.axvspan(MIN_YEAR - 0.5, train_boundary, color='green', alpha=0.1, label=f'Train (<{TRAIN_END_YEAR})')\n",
    "plt.axvspan(train_boundary, val_boundary, color='yellow', alpha=0.1, label=f'Validation ({TRAIN_END_YEAR}-{VAL_END_YEAR - 1})')\n",
    "plt.axvspan(val_boundary, MAX_YEAR + 0.5, color='red', alpha=0.1, label=f'Test (>={VAL_END_YEAR})')\n",
    "\n",
    "# Add Text Labels\n",
    "y_max = yearly_trend['Actual'].max()\n",
    "text_y = y_max * 1.05 \n",
    "\n",
    "plt.text((MIN_YEAR + train_boundary)/2, text_y, 'TRAINING', ha='center', fontsize=12, fontweight='bold', color='green')\n",
    "plt.text((train_boundary + val_boundary)/2, text_y, 'VALIDATION', ha='center', fontsize=12, fontweight='bold', color='#D4AC0D')\n",
    "plt.text((val_boundary + MAX_YEAR)/2, text_y, 'TESTING', ha='center', fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "# Final Formatting\n",
    "plt.title(f'Full Timeline Analysis: Actual vs. Predicted Yield ({CHOSEN_CROP}) - LSTM', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Yield (hg/ha)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(np.arange(MIN_YEAR, MAX_YEAR + 1, 2))\n",
    "plt.xlim(MIN_YEAR - 0.5, MAX_YEAR + 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02369b59",
   "metadata": {},
   "source": [
    "* **Geographic Error:** We map the error rates by country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RE-CREATE COMPARISON DF WITH FEATURE JOINED ---\n",
    "# We need the original 'area' column. Due to Sequence creation, \n",
    "# we trimmed (SEQ_LEN-1) rows from the START of each split chunk in create_sequences?\n",
    "# Actually, create_sequences is applied to the processed arrays X_test, etc.\n",
    "# X_test corresponds to indices in df_model[mask_test].\n",
    "# We need to align indices: The LSTM predictions correspond to indices [SEQ_LEN-1 : ] of the mask_test chunk.\n",
    "\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "df_test_full = df_model[mask_test]\n",
    "\n",
    "# Slice the df to match sequence output length\n",
    "# create_sequences removes first (SEQ_LEN-1) rows\n",
    "df_test_aligned = df_test_full.iloc[SEQ_LEN-1 : ].copy()\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Value': y_test_seq, # Aligned targets\n",
    "    'Predicted_Value': y_pred_final_test\n",
    "}, index=df_test_aligned.index)\n",
    "\n",
    "# Join metadata\n",
    "comparison_df = comparison_df.join(df_test_aligned[['area', 'year']])\n",
    "comparison_df = comparison_df[['year', 'area', 'Actual_Value', 'Predicted_Value']]\n",
    "\n",
    "print(\"--- Actual vs. Predicted Test Set Results ---\")\n",
    "print(comparison_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Name Cleaning for Map Plotting\n",
    "comparison_df['area'] = comparison_df['area'].replace({\n",
    "    'United_States_of_America': 'United States',\n",
    "    'United_Kingdom_of_Great_Britain_and_Northern_Ireland': 'United Kingdom',\n",
    "    'Russian_Federation': 'Russia',\n",
    "    'Viet_Nam': 'Vietnam',\n",
    "    'TÃ¼rkiye': 'Turkey',\n",
    "    'Bolivia_(Plurinational_State_of)': 'Bolivia',\n",
    "    'Iran_(Islamic_Republic_of)': 'Iran',\n",
    "    \"Lao_People's_Democratic_Republic\": 'Laos',\n",
    "    'China,_mainland': 'China',\n",
    "    'China,_Taiwan_Province_of': 'Taiwan',\n",
    "    \"Democratic_People's_Republic_of_Korea\": 'North Korea',\n",
    "    'Republic_of_Korea': 'South Korea',\n",
    "    'CÃ´te_d\\'Ivoire': \"Cote d'Ivoire\",\n",
    "    'United_Republic_of_Tanzania': 'Tanzania',\n",
    "    'Micronesia_(Federated_States_of)': 'Micronesia',\n",
    "    'Venezuela_(Bolivarian_Republic_of)': 'Venezuela'\n",
    "})\n",
    "\n",
    "def plot_geographic_error(comparison_df):\n",
    "    # Squared Error (for RMSE)\n",
    "    comparison_df['Squared_Error'] = (comparison_df['Actual_Value'] - comparison_df['Predicted_Value']) ** 2\n",
    "    # Squared Percentage Error (for RMSPE)\n",
    "    epsilon = 1e-6 \n",
    "    comparison_df['Squared_Percentage_Error'] = (\n",
    "        (comparison_df['Actual_Value'] - comparison_df['Predicted_Value']) / \n",
    "        (comparison_df['Actual_Value'] + epsilon)\n",
    "    ) ** 2\n",
    "\n",
    "    # Aggregate Errors by Country\n",
    "    rmse_df = (\n",
    "        comparison_df.groupby('area')['Squared_Error']\n",
    "        .mean().apply(np.sqrt).reset_index()\n",
    "        .rename(columns={'area': 'Country', 'Squared_Error': 'RMSE'})\n",
    "    )\n",
    "    rmspe_df = (\n",
    "        comparison_df.groupby('area')['Squared_Percentage_Error']\n",
    "        .mean().apply(np.sqrt).multiply(100).reset_index()\n",
    "        .rename(columns={'area': 'Country', 'Squared_Percentage_Error': 'RMSPE'})\n",
    "    )\n",
    "    ap_df = comparison_df.groupby('area')[['Actual_Value', 'Predicted_Value']].mean().reset_index()\n",
    "    ap_df = ap_df.rename(columns={'area': 'Country'})\n",
    "\n",
    "    # Merge stats\n",
    "    error_stats = rmspe_df.merge(rmse_df, on='Country', how='left')\n",
    "    error_stats = error_stats.merge(ap_df, on='Country', how='left') \n",
    "\n",
    "    # Plot\n",
    "    fig = px.choropleth(\n",
    "        error_stats,\n",
    "        locations='Country',\n",
    "        color='RMSPE',\n",
    "        locationmode='country names',\n",
    "        color_continuous_scale=['green', 'red'], \n",
    "        range_color=[0, 50], \n",
    "        title='Geographic Distribution of Prediction Error (RMSPE)',\n",
    "        labels={'RMSPE': 'RMSPE (%)'},\n",
    "        hover_name='Country',\n",
    "        hover_data={'RMSPE': ':.2f', 'RMSE': ':.2f', 'Actual_Value': ':.2f', 'Predicted_Value': ':.2f'},\n",
    "        projection='natural earth'\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title_font_size=18,\n",
    "        coloraxis_colorbar=dict(title='RMSPE (%)', orientation='h', len=0.5, yanchor='bottom', y=-0.12),\n",
    "        geo=dict(showframe=False, showcoastlines=True, showcountries=True, countrycolor='black', bgcolor='lightgrey')\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "plot_geographic_error(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fc4f6",
   "metadata": {},
   "source": [
    "### 9. Key Factors (Feature Importance)\n",
    "To estimate feature importance for an LSTM, we use **Permutation Importance** on the 2D input data. We wrap the sequence generation and prediction steps so that sklearn can permute one feature column at a time, we rebuild sequences, and measure error increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e313a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WRAPPER FOR SKLEARN COMPATIBILITY WITH 2D INPUT TO 3D SEQUENCE ---\n",
    "class LSTMSeqWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper to allow Sklearn's permutation_importance to work with the LSTM.\n",
    "    It takes 2D data (N, Feats), converts it to 3D sequences (N-Seq+1, Seq, Feats) internally,\n",
    "    and returns predictions aligned to the targets.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, device, seq_len):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass # Already trained\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X is 2D numpy array (N_samples, N_features)\n",
    "        # Create sequences\n",
    "        X_seq, _ = create_sequences(X, np.zeros(len(X)), self.seq_len)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_seq, dtype=torch.float32).to(self.device)\n",
    "            preds = self.model(X_tensor).cpu().numpy().flatten()\n",
    "        return preds\n",
    "\n",
    "# --- CALCULATE PERMUTATION IMPORTANCE ---\n",
    "wrapped_model = LSTMSeqWrapper(final_model, device, SEQ_LEN)\n",
    "\n",
    "# Use validation set (2D) for importance calculation\n",
    "# We must align y_val to match the output of the wrapper (which trims SEQ_LEN-1)\n",
    "y_val_aligned = y_val.values[SEQ_LEN - 1:]\n",
    "\n",
    "results = permutation_importance(\n",
    "    wrapped_model, \n",
    "    X_val, # Pass 2D data\n",
    "    y_val_aligned, \n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    n_repeats=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- PROCESS RESULTS ---\n",
    "importance_means = np.abs(results.importances_mean)\n",
    "feature_names = np.array(feature_cols)\n",
    "\n",
    "# Create DataFrame\n",
    "fi_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance_means\n",
    "}).sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print Top 20\n",
    "print(\"\\n--- Top 20 Most Important Features (Permutation Importance) ---\")\n",
    "print(fi_df.head(20))\n",
    "\n",
    "# --- PLOT ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=fi_df.head(20), palette='viridis')\n",
    "plt.title(f'Feature Importance (Permutation) - {CHOSEN_CROP.capitalize()} LSTM Model', fontsize=15)\n",
    "plt.xlabel('Increase in RMSE when shuffled')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
