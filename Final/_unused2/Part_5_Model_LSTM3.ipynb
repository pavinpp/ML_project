{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "desc_header",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction: LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavin/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cool, running on: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "\n",
    "# Tools for visualizing Optuna results\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "# Making the plots look a bit nicer\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Check if I have a GPU available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Cool, running on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_md",
   "metadata": {},
   "source": [
    "### 1. Loading Data & Picking the Target\n",
    "Loading the dataset and picking which crop to predict. I'll stick with **Rice**, same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the available crops:\n",
      "['bananas', 'barley', 'cassava_fresh', 'cucumbers_and_gherkins', 'maize_corn', 'oil_palm_fruit', 'other_vegetables_fresh_nec', 'potatoes', 'rice', 'soya_beans', 'sugar_beet', 'sugar_cane', 'tomatoes', 'watermelons', 'wheat']\n",
      "----------------------------------------\n",
      "Locked in target: Y_rice\n",
      "Valid data points found: 4687\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_parquet('Parquet/XY_v3.parquet')\n",
    "\n",
    "# --- CHECKING OPTIONS ---\n",
    "target_columns = [col for col in df.columns if col.startswith('Y_')]\n",
    "available_crops = [col.replace('Y_', '') for col in target_columns]\n",
    "\n",
    "print(\"Here are the available crops:\")\n",
    "print(available_crops)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- CHOOSE CROP HERE ---\n",
    "CHOSEN_CROP = 'rice'\n",
    "# ---------------------------\n",
    "\n",
    "TARGET_COL = f'Y_{CHOSEN_CROP}'\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Can't find {TARGET_COL}. Check the spelling?\")\n",
    "\n",
    "print(f\"Locked in target: {TARGET_COL}\")\n",
    "\n",
    "# Drop rows where the target is missing\n",
    "df_model = df.dropna(subset=[TARGET_COL])\n",
    "print(f\"Valid data points found: {len(df_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean_prep_md",
   "metadata": {},
   "source": [
    "### 2. Cleaning & Prep\n",
    "I'm keeping the cleaning process exactly the same as the Neural Network notebook to ensure a fair comparison. \n",
    "\n",
    "1. Remove extreme outliers per country.\n",
    "2. Drop irrelevant columns.\n",
    "3. **Split by time**: This time, I'll scale the full dataset first and *then* create sequences. This allows the Validation set to look back into the Training years for its initial sequences, so we don't lose data at the cut-off points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "clean_prep_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input features: 17\n",
      "Creating sequences...\n",
      "\n",
      "Training samples (sequences): 2904\n",
      "Validation samples (sequences): 534\n",
      "Test samples (sequences):       514\n",
      "Input Shape: torch.Size([2904, 5, 17])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- DROP IRRELEVANT COLUMNS ---\n",
    "cols_to_drop = [c for c in df_model.columns \n",
    "                if c.startswith(\"avg_yield_\") and CHOSEN_CROP not in c]\n",
    "df_model = df_model.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- SETUP FEATURES ---\n",
    "feature_cols = [c for c in df_model.columns \n",
    "                if not c.startswith('Y_') and c not in ['area']]\n",
    "\n",
    "print(f\"Total input features: {len(feature_cols)}\")\n",
    "\n",
    "# --- FILL MISSING VALUES (Full Dataset) ---\n",
    "# We impute before split to ensure continuity, using mean strategy.\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_full_imputed = pd.DataFrame(imputer.fit_transform(df_model[feature_cols]), columns=feature_cols)\n",
    "\n",
    "# --- NORMALIZE (SCALE) ---\n",
    "# We fit scaler ONLY on training data to avoid data leakage, but transform everything.\n",
    "TRAIN_END_YEAR = 2014\n",
    "VAL_END_YEAR = 2019\n",
    "\n",
    "train_idx = df_model[df_model['year'] < TRAIN_END_YEAR].index\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_full_imputed.loc[train_idx])\n",
    "\n",
    "X_full_scaled = scaler.transform(X_full_imputed)\n",
    "df_features = pd.DataFrame(X_full_scaled, columns=feature_cols, index=df_model.index)\n",
    "\n",
    "# --- LSTM SPECIFIC: CREATE SEQUENCES ---\n",
    "# Reshape: (Samples, Features) -> (Samples, Seq_Len, Features)\n",
    "SEQ_LEN = 5\n",
    "\n",
    "def create_sequences_and_split(df_feats, df_meta, target_col, seq_len=5):\n",
    "    X_train, y_train = [], []\n",
    "    X_val, y_val = [], []\n",
    "    X_test, y_test = [], []\n",
    "    \n",
    "    # We iterate by country to ensure sequences don't jump across borders\n",
    "    # We use the ORIGINAL index to map features and targets correctly\n",
    "    for area, group in df_meta.groupby('area'):\n",
    "        group = group.sort_values('year')\n",
    "        indices = group.index.values\n",
    "        years = group['year'].values\n",
    "        \n",
    "        if len(group) < seq_len:\n",
    "            continue\n",
    "            \n",
    "        # Sliding window across the FULL history of the country\n",
    "        for i in range(len(group) - seq_len + 1):\n",
    "            # Sequence input indices: i to i+seq_len-1\n",
    "            # Target index: i+seq_len-1 (Predicting the LAST year in the sequence)\n",
    "            \n",
    "            seq_indices = indices[i : i + seq_len]\n",
    "            target_idx = indices[i + seq_len - 1]\n",
    "            target_year = years[i + seq_len - 1]\n",
    "            \n",
    "            # Grab data\n",
    "            X_seq = df_feats.loc[seq_indices].values\n",
    "            y_target = df_meta.loc[target_idx, target_col]\n",
    "            \n",
    "            # Assign to split based on TARGET YEAR\n",
    "            if target_year < TRAIN_END_YEAR:\n",
    "                X_train.append(X_seq)\n",
    "                y_train.append(y_target)\n",
    "            elif target_year < VAL_END_YEAR:\n",
    "                X_val.append(X_seq)\n",
    "                y_val.append(y_target)\n",
    "            else:\n",
    "                X_test.append(X_seq)\n",
    "                y_test.append(y_target)\n",
    "            \n",
    "    return (\n",
    "        np.array(X_train), np.array(y_train), \n",
    "        np.array(X_val), np.array(y_val), \n",
    "        np.array(X_test), np.array(y_test)\n",
    "    )\n",
    "\n",
    "print(\"Creating sequences...\")\n",
    "X_train_seq, y_train_seq, X_val_seq, y_val_seq, X_test_seq, y_test_seq = create_sequences_and_split(\n",
    "    df_features, df_model, TARGET_COL, SEQ_LEN\n",
    ")\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_seq, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val_seq, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test_seq, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "print(f\"\\nTraining samples (sequences): {len(X_train_seq)}\")\n",
    "print(f\"Validation samples (sequences): {len(X_val_seq)}\")\n",
    "print(f\"Test samples (sequences):       {len(X_test_seq)}\")\n",
    "print(f\"Input Shape: {X_train_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init_model_md",
   "metadata": {},
   "source": [
    "### 3. First Try (Initial Model)\n",
    "I'll define the LSTM architecture here. It uses an LSTM layer to capture time dependencies, followed by a fully connected (linear) head for the final regression output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "init_model_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 -> Train RMSE: 3889.37 | Val RMSE: 4559.02\n",
      "Epoch 20/100 -> Train RMSE: 700.76 | Val RMSE: 920.83\n",
      "Epoch 40/100 -> Train RMSE: 469.99 | Val RMSE: 499.32\n",
      "Epoch 60/100 -> Train RMSE: 421.18 | Val RMSE: 488.68\n",
      "Epoch 80/100 -> Train RMSE: 398.56 | Val RMSE: 477.97\n",
      "Epoch 99/100 -> Train RMSE: 358.19 | Val RMSE: 511.84\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial LSTM Model Performance ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>332.682058</td>\n",
       "      <td>511.838689</td>\n",
       "      <td>568.102131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>0.968505</td>\n",
       "      <td>0.943973</td>\n",
       "      <td>0.931100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric       Train  Validation        Test\n",
       "0   RMSE  332.682058  511.838689  568.102131\n",
       "1     R    0.968505    0.943973    0.931100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- DEFINE THE LSTM NETWORK ---\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.2, activation=\"ReLU\"):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        \n",
    "        # 1. LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        \n",
    "        # 2. Output head: Linear -> Activation -> Linear\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            getattr(nn, activation)(),  # e.g. nn.ReLU(), nn.Tanh()\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, features)\n",
    "        out, _ = self.lstm(x)\n",
    "        last_step_out = out[:, -1, :]    # We only care about the output of the last time step\n",
    "        prediction = self.fc(last_step_out) \n",
    "        return prediction\n",
    "\n",
    "# --- TRAINING HELPER FUNCTION ---\n",
    "def train_model(model, X_t, y_t, X_v, y_v, lr=0.001, epochs=150, batch_size=32, verbose=True):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_t, y_t), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * batch_X.size(0)\n",
    "            \n",
    "        # Calculate metrics\n",
    "        train_rmse = np.sqrt(epoch_loss / len(X_t))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_v)\n",
    "            val_loss = criterion(val_outputs, y_v)\n",
    "            val_rmse = np.sqrt(val_loss.item())\n",
    "            \n",
    "        train_losses.append(train_rmse)\n",
    "        val_losses.append(val_rmse)\n",
    "        \n",
    "        if verbose and (epoch % 20 == 0 or epoch == epochs-1):\n",
    "            print(f\"Epoch {epoch}/{epochs} -> Train RMSE: {train_rmse:.2f} | Val RMSE: {val_rmse:.2f}\")\n",
    "            \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# --- RUNNING THE INITIAL MODEL ---\n",
    "input_dim = X_train_tensor.shape[2]\n",
    "model_init = LSTMRegressor(input_dim).to(device)\n",
    "\n",
    "# Training with standard settings\n",
    "train_hist, val_hist = train_model(model_init, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, \n",
    "                                   lr=0.001, epochs=100, batch_size=32)\n",
    "\n",
    "# --- PLOTTING HISTORY ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_hist, label='Training RMSE', color='blue')\n",
    "plt.plot(val_hist, label='Validation RMSE', color='red')\n",
    "plt.title(f'Learning Curve (First Try - LSTM - {CHOSEN_CROP})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- EVALUATION TABLE ---\n",
    "def get_metrics(model, X, y_true):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).cpu().numpy().flatten()\n",
    "    y_true_np = y_true\n",
    "    # Handle tensor vs numpy\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true_np = y_true.cpu().numpy().flatten()\n",
    "        \n",
    "    rmse = np.sqrt(mean_squared_error(y_true_np, preds))\n",
    "    r2 = r2_score(y_true_np, preds)\n",
    "    return rmse, r2, preds\n",
    "\n",
    "# Get stats for all sets\n",
    "rmse_t, r2_t, _ = get_metrics(model_init, X_train_tensor, y_train_tensor)\n",
    "rmse_v, r2_v, _ = get_metrics(model_init, X_val_tensor, y_val_tensor)\n",
    "rmse_test, r2_test, preds_init_test = get_metrics(model_init, X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Show results\n",
    "metrics_data = {\n",
    "    'Metric': ['RMSE', 'R'],\n",
    "    'Train': [rmse_t, r2_t],\n",
    "    'Validation': [rmse_v, r2_v],\n",
    "    'Test': [rmse_test, r2_test]\n",
    "}\n",
    "print(\"\\n--- Initial LSTM Model Performance ---\")\n",
    "display(pd.DataFrame(metrics_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optuna_md",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Tuning (Optuna)\n",
    "Now I'll use Optuna to find the best configuration for the LSTM (Hidden dimensions, layers, dropout, learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optuna_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 13:11:40,942] A new study created in memory with name: Crop_Yield_LSTM_Optuna\n",
      "[I 2025-12-09 13:11:57,491] Trial 0 finished with value: 572.2161960308359 and parameters: {'hidden_dim': 96, 'num_layers': 3, 'dropout': 0.4195509324382397, 'lr': 0.001702813936246648, 'activation': 'ReLU', 'batch_size': 32}. Best is trial 0 with value: 572.2161960308359.\n",
      "/Users/pavin/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.253068910895501 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-12-09 13:12:01,519] Trial 1 finished with value: 468.9411110416744 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.253068910895501, 'lr': 0.0028809275894673913, 'activation': 'ReLU', 'batch_size': 32}. Best is trial 1 with value: 468.9411110416744.\n",
      "[I 2025-12-09 13:12:10,567] Trial 2 finished with value: 4560.236397381171 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'dropout': 0.4938294810974234, 'lr': 0.00017001239573263976, 'activation': 'Tanh', 'batch_size': 16}. Best is trial 1 with value: 468.9411110416744.\n",
      "[I 2025-12-09 13:12:15,340] Trial 3 finished with value: 4572.887709095862 and parameters: {'hidden_dim': 32, 'num_layers': 3, 'dropout': 0.21006172615900734, 'lr': 0.00042518499528994264, 'activation': 'Tanh', 'batch_size': 64}. Best is trial 1 with value: 468.9411110416744.\n",
      "[I 2025-12-09 13:12:27,836] Trial 4 finished with value: 465.60281826359255 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.1223461666184095, 'lr': 0.003243094395660615, 'activation': 'ReLU', 'batch_size': 32}. Best is trial 4 with value: 465.60281826359255.\n",
      "[W 2025-12-09 13:12:45,107] Trial 5 failed with parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.25362495820277375, 'lr': 0.0006863814469238971, 'activation': 'ReLU', 'batch_size': 16} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pavin/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/zn/lrmslqwn0g3_slr732tvb0zw0000gn/T/ipykernel_4295/2076652026.py\", line 40, in objective\n",
      "    val_pred = model(X_val_tensor)\n",
      "  File \"/Users/pavin/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/pavin/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/var/folders/zn/lrmslqwn0g3_slr732tvb0zw0000gn/T/ipykernel_4295/2665430357.py\", line 24, in forward\n",
      "    out, _ = self.lstm(x)\n",
      "  File \"/Users/pavin/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/pavin/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/pavin/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py\", line 1124, in forward\n",
      "    result = _VF.lstm(\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-09 13:12:45,124] Trial 5 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# --- START TUNING ---\u001b[39;00m\n\u001b[1;32m     51\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrop_Yield_LSTM_Optuna\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFound the best settings:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:67\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:164\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:262\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    258\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    261\u001b[0m ):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/optuna/study/_optimize.py:205\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 40\u001b[0m     val_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     val_rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(criterion(val_pred, y_val_tensor)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Pruning mechanism (stops bad trials early)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m, in \u001b[0;36mLSTMRegressor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# x: (batch, seq_len, features)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     last_step_out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]    \u001b[38;5;66;03m# We only care about the output of the last time step\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(last_step_out) \n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_project/Final/.venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- OBJECTIVE FUNCTION ---\n",
    "def objective(trial):\n",
    "    # Defining the search space\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 128, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"ReLU\", \"Tanh\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "\n",
    "    # Build model with these params\n",
    "    model = LSTMRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        activation=activation\n",
    "    ).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), \n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Quick training loop\n",
    "    epochs = 40 # Keeping epochs lower for speed during tuning\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_tensor)\n",
    "            val_rmse = np.sqrt(criterion(val_pred, y_val_tensor).item())\n",
    "\n",
    "        # Pruning mechanism (stops bad trials early)\n",
    "        trial.report(val_rmse, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_rmse\n",
    "\n",
    "# --- START TUNING ---\n",
    "study = optuna.create_study(direction='minimize', study_name='Crop_Yield_LSTM_Optuna')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"\\nFound the best settings:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optuna_viz_md",
   "metadata": {},
   "source": [
    "### 5. Optuna Visuals\n",
    "Let's look at the charts to see how the optimization process went and which parameters mattered most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna_viz_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization History\n",
    "fig = plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "# Parameter Importance\n",
    "try:\n",
    "    fig = plot_param_importances(study)\n",
    "    fig.show()\n",
    "except:\n",
    "    print(\"Oops, couldn't plot importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_model_md",
   "metadata": {},
   "source": [
    "### 6. Training the Final Model\n",
    "I'll take the best parameters from Optuna and train a fresh LSTM model. This time, I'll combine the Training and Validation sets to give the model maximum data before the final Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_model_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Train and Validation Data (Sequences)\n",
    "X_train_full = torch.cat((X_train_tensor, X_val_tensor), dim=0)\n",
    "y_train_full = torch.cat((y_train_tensor, y_val_tensor), dim=0)\n",
    "\n",
    "bp = study.best_params\n",
    "\n",
    "final_model = LSTMRegressor(\n",
    "    input_dim,\n",
    "    hidden_dim=bp['hidden_dim'], \n",
    "    num_layers=bp['num_layers'], \n",
    "    dropout=bp['dropout'], \n",
    "    activation=bp['activation']\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=bp['lr'])\n",
    "criterion = nn.MSELoss()\n",
    "train_loader = DataLoader(TensorDataset(X_train_full, y_train_full), \n",
    "                          batch_size=bp['batch_size'], shuffle=True)\n",
    "\n",
    "print(\"Training the final version now...\")\n",
    "final_model.train()\n",
    "for epoch in range(150):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results_md",
   "metadata": {},
   "source": [
    "### 7. Results & Comparison\n",
    "Let's see the numbers. I'll compare the Initial LSTM Model side-by-side with the Tuned LSTM Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Final Model\n",
    "rmse_f_t, r2_f_t, _ = get_metrics(final_model, X_train_tensor, y_train_tensor)\n",
    "rmse_f_v, r2_f_v, _ = get_metrics(final_model, X_val_tensor, y_val_tensor)\n",
    "rmse_f_test, r2_f_test, preds_final_test = get_metrics(final_model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "metrics_final = {\n",
    "    'Metric': ['RMSE', 'R'],\n",
    "    'Train': [rmse_f_t, r2_f_t],\n",
    "    'Validation': [rmse_f_v, r2_f_v],\n",
    "    'Test': [rmse_f_test, r2_f_test]\n",
    "}\n",
    "\n",
    "print(\"--- Final Tuned LSTM Metrics ---\")\n",
    "display(pd.DataFrame(metrics_final))\n",
    "\n",
    "# --- PLOT COMPARISON ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Convert y_test tensor back to numpy for plotting if needed\n",
    "y_test_np = y_test_tensor.cpu().numpy().flatten()\n",
    "\n",
    "all_preds = np.concatenate([preds_init_test, preds_final_test])\n",
    "all_true = np.concatenate([y_test_np, y_test_np])\n",
    "min_val, max_val = min(all_preds.min(), all_true.min()), max(all_preds.max(), all_true.max())\n",
    "\n",
    "# Initial Model Plot\n",
    "axes[0].scatter(y_test_np, preds_init_test, alpha=0.4, color='orange')\n",
    "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[0].set_title(f'Initial LSTM\\nTest RMSE: {rmse_test:.2f}')\n",
    "\n",
    "# Tuned Model Plot\n",
    "axes[1].scatter(y_test_np, preds_final_test, alpha=0.4, color='green')\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[1].set_title(f'Tuned LSTM\\nTest RMSE: {rmse_f_test:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timeline_plot_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TIMELINE PLOT ---\n",
    "# We will reconstruct the timeline for the TEST set predictions.\n",
    "\n",
    "# Re-extract years for the test sequences to be exact\n",
    "# We iterate in the exact same order as sequence creation to match indices.\n",
    "test_years_seq = []\n",
    "for area, group in df_model.groupby('area'):\n",
    "    group = group.sort_values('year')\n",
    "    if len(group) < SEQ_LEN:\n",
    "        continue\n",
    "        \n",
    "    indices = group.index.values\n",
    "    years = group['year'].values\n",
    "    \n",
    "    for i in range(len(group) - SEQ_LEN + 1):\n",
    "        target_year = years[i + SEQ_LEN - 1]\n",
    "        if target_year >= VAL_END_YEAR:\n",
    "            test_years_seq.append(target_year)\n",
    "\n",
    "df_test_res = pd.DataFrame({\n",
    "    'Year': test_years_seq,\n",
    "    'Actual': y_test_tensor.cpu().numpy().flatten(),\n",
    "    'Predicted': preds_final_test\n",
    "})\n",
    "\n",
    "# Aggregate\n",
    "yearly_trend = df_test_res.groupby('Year').mean()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(yearly_trend.index, yearly_trend['Actual'], marker='o', label='Actual Yield', linewidth=2, color='blue')\n",
    "plt.plot(yearly_trend.index, yearly_trend['Predicted'], marker='x', linestyle='--', label='Predicted Yield', linewidth=2, color='orange')\n",
    "plt.title(f'Test Period Analysis: Actual vs. Predicted Yield ({CHOSEN_CROP})', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Yield (hg/ha)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "map_md",
   "metadata": {},
   "source": [
    "### 8. Geographic Error Map\n",
    "Which countries is the LSTM struggling with? Let's map out the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "map_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# We need to map predictions back to countries. \n",
    "# Re-running the sequence generation logic just to get the Area list corresponding to y_test_tensor.\n",
    "test_areas_seq = []\n",
    "\n",
    "for area, group in df_model.groupby('area'):\n",
    "    group = group.sort_values('year')\n",
    "    if len(group) < SEQ_LEN:\n",
    "        continue\n",
    "    \n",
    "    indices = group.index.values\n",
    "    years = group['year'].values\n",
    "    \n",
    "    for i in range(len(group) - SEQ_LEN + 1):\n",
    "        target_year = years[i + SEQ_LEN - 1]\n",
    "        if target_year >= VAL_END_YEAR:\n",
    "            test_areas_seq.append(area)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'area': test_areas_seq,\n",
    "    'Actual_Value': y_test_tensor.cpu().numpy().flatten(),\n",
    "    'Predicted_Value': preds_final_test\n",
    "})\n",
    "\n",
    "# Clean names\n",
    "comparison_df['area'] = comparison_df['area'].replace({\n",
    "    'United_States_of_America': 'United States',\n",
    "    'Russian_Federation': 'Russia',\n",
    "    'Viet_Nam': 'Vietnam',\n",
    "    'Trkiye': 'Turkey',\n",
    "    'China, mainland': 'China',\n",
    "    'Republic_of_Korea': 'South Korea'\n",
    "})\n",
    "\n",
    "comparison_df['Squared_Error'] = (comparison_df['Actual_Value'] - comparison_df['Predicted_Value']) ** 2\n",
    "comparison_df['Error_Pct'] = ((comparison_df['Actual_Value'] - comparison_df['Predicted_Value']) / (comparison_df['Actual_Value'] + 1e-6)) ** 2\n",
    "\n",
    "# Aggregate\n",
    "map_data = comparison_df.groupby('area').agg(\n",
    "    RMSPE=('Error_Pct', lambda x: np.sqrt(x.mean()) * 100),\n",
    "    RMSE=('Squared_Error', lambda x: np.sqrt(x.mean())),\n",
    "    Actual_Mean=('Actual_Value', 'mean'),\n",
    "    Predicted_Mean=('Predicted_Value', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "map_data.rename(columns={'area':'Country'}, inplace=True)\n",
    "\n",
    "fig = px.choropleth(\n",
    "    map_data,\n",
    "    locations='Country',\n",
    "    locationmode='country names',\n",
    "    color='RMSPE',\n",
    "    color_continuous_scale=['green', 'red'],\n",
    "    range_color=[0, 50],\n",
    "    title='Prediction Error by Country (LSTM RMSPE)',\n",
    "    hover_data={'RMSPE': ':.2f', 'RMSE': ':.2f'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feat_imp_md",
   "metadata": {},
   "source": [
    "### 9. Feature Importance\n",
    "Calculating feature importance for LSTMs is complex because the inputs are 3D sequences. Standard Permutation Importance shuffles a feature across the whole dataset, which breaks the time-series continuity for that feature. \n",
    "\n",
    "For this section, I will skip the standard Permutation Importance plot to avoid misleading results or dimension errors, as `sklearn.inspection` expects 2D inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feat_imp_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature importance analysis is skipped for the LSTM model due to 3D input structure compatibility issues with standard tools.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
