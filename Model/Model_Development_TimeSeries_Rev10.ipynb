{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction – Final Model Pipeline (Rev9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "from scipy.signal import detrend\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All libraries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Selection Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_MODELS = {\n",
    "    'LR': True,   # Baseline Linear Regression\n",
    "    'RF': True,   # Random Forest\n",
    "    'XGB': True,  # XGBoost\n",
    "    'LSTM': True, # LSTM\n",
    "    'CNN': True   # CNN\n",
    "}\n",
    "\n",
    "RUN_OPTUNA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load & Preprocess Data (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded initial data: (25932, 9)\n",
      "1. Initial data split: Train: (19032, 9), Val: (3424, 9), Test: (3476, 9)\n",
      "2. Encoders fitted on train set and applied to all sets.\n",
      "3. Fitting trend models on training data...\n",
      "   Fitted 588 group-specific trend models and 1 global model.\n",
      "   Detrending applied to all datasets.\n",
      "4. Lags created for ML models: Train: (17857, 25), Val: (3421, 25), Test: (3459, 25)\n",
      "5. X and y scalers for ML models fitted and applied.\n",
      "6. All transformers saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Corrected Data Preprocessing\n",
    "try:\n",
    "    df = pd.read_csv(\"cleaned_crop_data.csv\")\n",
    "    print(f\"Loaded initial data: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"Ensure 'cleaned_crop_data.csv' is present. Run the EDA notebook first.\")\n",
    "\n",
    "TARGET = 'hg/ha_yield'\n",
    "TIME_COL = 'Year'\n",
    "CAT_COLS = ['Area', 'Item']\n",
    "NUMERIC_COLS = ['average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp', 'fertilizer_kg/ha', 'solar_radiation_MJ/m2-day']\n",
    "TARGET_DET = 'yield_detrended'\n",
    "\n",
    "# 1. Split data chronologically\n",
    "TRAIN_END = 2007\n",
    "VAL_END = 2010\n",
    "train_df_orig = df[df[TIME_COL] <= TRAIN_END].copy()\n",
    "val_df_orig = df[(df[TIME_COL] > TRAIN_END) & (df[TIME_COL] <= VAL_END)].copy()\n",
    "test_df_orig = df[df[TIME_COL] > VAL_END].copy()\n",
    "print(f\"1. Initial data split: Train: {train_df_orig.shape}, Val: {val_df_orig.shape}, Test: {test_df_orig.shape}\")\n",
    "\n",
    "# 2. Fit encoders ON TRAINING DATA ONLY\n",
    "le_area = LabelEncoder().fit(train_df_orig['Area'])\n",
    "le_item = LabelEncoder().fit(train_df_orig['Item'])\n",
    "for d in [train_df_orig, val_df_orig, test_df_orig]:\n",
    "    d['Area_Encoded'] = d['Area'].apply(lambda x: le_area.transform([x])[0] if x in le_area.classes_ else -1)\n",
    "    d['Item_Encoded'] = d['Item'].apply(lambda x: le_item.transform([x])[0] if x in le_item.classes_ else -1)\n",
    "print(\"2. Encoders fitted on train set and applied to all sets.\")\n",
    "\n",
    "# 3. Fit trend models ON TRAINING DATA ONLY\n",
    "print(\"3. Fitting trend models on training data...\")\n",
    "trend_models = {}\n",
    "for group, group_df in train_df_orig.groupby(CAT_COLS):\n",
    "    trend_model = LinearRegression()\n",
    "    trend_model.fit(group_df[[TIME_COL]], group_df[TARGET])\n",
    "    trend_models[group] = trend_model\n",
    "\n",
    "global_trend_model = LinearRegression().fit(train_df_orig[[TIME_COL]], train_df_orig[TARGET])\n",
    "print(f\"   Fitted {len(trend_models)} group-specific trend models and 1 global model.\")\n",
    "\n",
    "# 4. Apply detrending to all datasets\n",
    "for df_set in [train_df_orig, val_df_orig, test_df_orig]:\n",
    "    df_set['yield_trend'] = 0.0\n",
    "    for group, group_df in df_set.groupby(CAT_COLS):\n",
    "        model = trend_models.get(group, global_trend_model)\n",
    "        trend_prediction = model.predict(group_df[[TIME_COL]])\n",
    "        df_set.loc[group_df.index, 'yield_trend'] = trend_prediction\n",
    "    df_set['yield_detrended'] = df_set[TARGET] - df_set['yield_trend']\n",
    "print(\"   Detrending applied to all datasets.\")\n",
    "\n",
    "# 5. Create lags and finalize split for ML models\n",
    "full_df_ml = pd.concat([train_df_orig, val_df_orig, test_df_orig]).sort_values(CAT_COLS + [TIME_COL])\n",
    "lag_cols = ['yield_detrended'] + NUMERIC_COLS\n",
    "for col in lag_cols:\n",
    "    for lag in [1, 2]:\n",
    "        full_df_ml[f'{col}_lag{lag}'] = full_df_ml.groupby(CAT_COLS)[col].shift(lag)\n",
    "\n",
    "df_ml = full_df_ml.dropna().copy()\n",
    "train_df = df_ml[df_ml[TIME_COL] <= TRAIN_END].copy()\n",
    "val_df = df_ml[(df_ml[TIME_COL] > TRAIN_END) & (df_ml[TIME_COL] <= VAL_END)].copy()\n",
    "test_df = df_ml[df_ml[TIME_COL] > VAL_END].copy()\n",
    "print(f\"4. Lags created for ML models: Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")\n",
    "\n",
    "# 6. Fit scalers for ML models ON TRAINING DATA ONLY\n",
    "lagged_cols = [c for c in df_ml.columns if '_lag' in c]\n",
    "ml_features = NUMERIC_COLS + lagged_cols + ['Area_Encoded', 'Item_Encoded']\n",
    "scale_cols = NUMERIC_COLS + lagged_cols\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "train_df[scale_cols] = x_scaler.fit_transform(train_df[scale_cols])\n",
    "val_df[scale_cols] = x_scaler.transform(val_df[scale_cols])\n",
    "test_df[scale_cols] = x_scaler.transform(test_df[scale_cols])\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "train_df[TARGET_DET] = y_scaler.fit_transform(train_df[[TARGET_DET]])\n",
    "val_df[TARGET_DET] = y_scaler.transform(val_df[[TARGET_DET]])\n",
    "test_df[TARGET_DET] = y_scaler.transform(test_df[[TARGET_DET]])\n",
    "print(\"5. X and y scalers for ML models fitted and applied.\")\n",
    "\n",
    "# 7. Save transformers\n",
    "joblib.dump(x_scaler, 'scaler.joblib')\n",
    "joblib.dump(y_scaler, 'y_scaler.joblib')\n",
    "joblib.dump(le_area, 'le_area.joblib')\n",
    "joblib.dump(le_item, 'le_item.joblib')\n",
    "joblib.dump(trend_models, 'trend_models.joblib')\n",
    "joblib.dump(global_trend_model, 'global_trend_model.joblib')\n",
    "print(\"6. All transformers saved to disk.\")\n",
    "\n",
    "N_AREAS = len(le_area.classes_)\n",
    "N_ITEMS = len(le_item.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Inputs (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML inputs prepared.\n",
      "DL features and target scaled.\n",
      "DL sequences created.\n",
      "DL tensors created.\n"
     ]
    }
   ],
   "source": [
    "# ML Inputs\n",
    "X_train_ml = train_df[ml_features]\n",
    "y_train_ml = train_df[TARGET_DET]\n",
    "X_val_ml = val_df[ml_features]\n",
    "y_val_ml = val_df[TARGET_DET]\n",
    "X_test_ml = test_df[ml_features]\n",
    "y_test_ml = test_df[TARGET_DET]\n",
    "print(\"ML inputs prepared.\")\n",
    "\n",
    "# DL Inputs\n",
    "LOOKBACK = 5\n",
    "DL_FEATS = NUMERIC_COLS + ['Area_Encoded', 'Item_Encoded']\n",
    "\n",
    "# Correctly scale DL features\n",
    "scaler_dl_x = StandardScaler()\n",
    "train_df_orig[NUMERIC_COLS] = scaler_dl_x.fit_transform(train_df_orig[NUMERIC_COLS])\n",
    "val_df_orig[NUMERIC_COLS] = scaler_dl_x.transform(val_df_orig[NUMERIC_COLS])\n",
    "test_df_orig[NUMERIC_COLS] = scaler_dl_x.transform(test_df_orig[NUMERIC_COLS])\n",
    "\n",
    "# Use the already fitted y_scaler for the target\n",
    "train_df_orig[TARGET_DET] = y_scaler.transform(train_df_orig[[TARGET_DET]])\n",
    "val_df_orig[TARGET_DET] = y_scaler.transform(val_df_orig[[TARGET_DET]])\n",
    "test_df_orig[TARGET_DET] = y_scaler.transform(test_df_orig[[TARGET_DET]])\n",
    "print(\"DL features and target scaled.\")\n",
    "\n",
    "def create_sequences(data, lookback, feats, target):\n",
    "    X, y = [], []\n",
    "    # Keep track of original index\n",
    "    y_indices = []\n",
    "    for _, group in data.groupby(CAT_COLS):\n",
    "        if len(group) < lookback:\n",
    "            continue\n",
    "        gf = group[feats].values\n",
    "        gt = group[target].values\n",
    "        indices = group.index\n",
    "        for i in range(len(group) - lookback + 1):\n",
    "            X.append(gf[i:i+lookback])\n",
    "            y.append(gt[i+lookback-1])\n",
    "            y_indices.append(indices[i+lookback-1])\n",
    "    return np.array(X), np.array(y), y_indices\n",
    "\n",
    "X_train_seq, y_train_seq, _ = create_sequences(train_df_orig, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "X_val_seq, y_val_seq, _ = create_sequences(val_df_orig, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "X_test_seq, y_test_seq, y_test_indices = create_sequences(test_df_orig, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "print(\"DL sequences created.\")\n",
    "\n",
    "# Create a reference dataframe for test set evaluation\n",
    "test_df_dl_seq_ref = test_df_orig.loc[y_test_indices]\n",
    "\n",
    "def split_dl(X):\n",
    "    # The number of numeric features is len(NUMERIC_COLS)\n",
    "    numeric_feature_count = len(NUMERIC_COLS)\n",
    "    return [\n",
    "        torch.tensor(X[..., :numeric_feature_count], dtype=torch.float32),\n",
    "        torch.tensor(X[..., numeric_feature_count], dtype=torch.long),\n",
    "        torch.tensor(X[..., numeric_feature_count+1], dtype=torch.long)\n",
    "    ]\n",
    "\n",
    "X_train_dl = split_dl(X_train_seq)\n",
    "X_val_dl = split_dl(X_val_seq)\n",
    "X_test_dl = split_dl(X_test_seq)\n",
    "\n",
    "y_train_t = torch.tensor(y_train_seq, dtype=torch.float32).unsqueeze(1)\n",
    "y_val_t = torch.tensor(y_val_seq, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_t = torch.tensor(y_test_seq, dtype=torch.float32).unsqueeze(1)\n",
    "print(\"DL tensors created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(((y_true - y_pred) / (y_true + 1e-8)) ** 2)) * 100\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optuna Objectives (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial):\n",
    "    # No hyperparameters to tune for Linear Regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    preds = model.predict(X_val_ml)\n",
    "    return np.sqrt(mean_squared_error(y_val_ml, preds)) # Return RMSE\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_float('max_features', 0.5, 1.0)\n",
    "    }\n",
    "    model = RandomForestRegressor(random_state=42, n_jobs=-1, **params)\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    preds = model.predict(X_val_ml)\n",
    "    return np.sqrt(mean_squared_error(y_val_ml, preds)) # Return RMSE\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000), \n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'early_stopping_rounds': 50, # Increase patience for lower LR\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        random_state=42,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_ml, y_train_ml,\n",
    "        eval_set=[(X_val_ml, y_val_ml)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_val_ml)\n",
    "    return np.sqrt(mean_squared_error(y_val_ml, preds)) # Return RMSE\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, n_areas, n_items, lstm_units, dense_units, dropout):\n",
    "        super().__init__()\n",
    "        self.embed_area = nn.Embedding(n_areas, 10)\n",
    "        self.embed_item = nn.Embedding(n_items, 5)\n",
    "        self.lstm = nn.LSTM(len(NUMERIC_COLS) + 10 + 5, lstm_units, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(lstm_units, dense_units)\n",
    "        self.fc2 = nn.Linear(dense_units, 1)\n",
    "    def forward(self, num, area, item):\n",
    "        e_area = self.embed_area(area)\n",
    "        e_item = self.embed_item(item)\n",
    "        x = torch.cat([num, e_area, e_item], dim=-1)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.drop(out[:, -1])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        return self.fc2(out)\n",
    "\n",
    "def train_dl(model, opt, loss_fn, train_loader, val_loader, target_scaler, epochs=100, patience=10, is_final=False):\n",
    "    scheduler = ReduceLROnPlateau(opt, 'min', patience=5, factor=0.5)\n",
    "    best_val_rmse = float('inf') # Optimize for RMSE\n",
    "    wait = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x1, x2, x3, y in train_loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(x1, x2, x3)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_inputs = [x.to(next(model.parameters()).device) for x in val_loader.dataset.tensors[:3]]\n",
    "            val_y = val_loader.dataset.tensors[3]\n",
    "            val_pred = model(*val_inputs)\n",
    "            val_mse = loss_fn(val_pred, val_y).item()\n",
    "            val_rmse = np.sqrt(val_mse) # Calculate RMSE\n",
    "            val_losses.append(val_mse)\n",
    "\n",
    "        scheduler.step(val_rmse) # Step based on validation RMSE\n",
    "\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            wait = 0\n",
    "            if is_final:\n",
    "                 torch.save(model.state_dict(), f'model_{model.__class__.__name__}.pth')\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                break\n",
    "    return train_losses, val_losses, best_val_rmse\n",
    "\n",
    "def objective_lstm(trial):\n",
    "    params = {\n",
    "        'lstm_units': trial.suggest_categorical('lstm_units', [64, 128]),\n",
    "        'dense_units': trial.suggest_categorical('dense_units', [32, 64]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.1, 0.4),\n",
    "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    }\n",
    "    lr = params.pop('lr')\n",
    "    weight_decay = params.pop('weight_decay')\n",
    "    model = LSTMModel(N_AREAS, N_ITEMS, **params)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_ds = TensorDataset(*X_train_dl, y_train_t)\n",
    "    val_ds = TensorDataset(*X_val_dl, y_val_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64)\n",
    "    _, _, best_val_rmse = train_dl(model, opt, nn.MSELoss(), train_loader, val_loader, y_scaler)\n",
    "    return best_val_rmse\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, n_areas, n_items, filters, kernel, dense_units): \n",
    "        super().__init__()\n",
    "        self.embed_area = nn.Embedding(n_areas, 10)\n",
    "        self.embed_item = nn.Embedding(n_items, 5)\n",
    "        self.conv = nn.Conv1d(len(NUMERIC_COLS) + 10 + 5, filters, kernel)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(filters, dense_units)\n",
    "        self.fc2 = nn.Linear(dense_units, 1)\n",
    "    def forward(self, num, area, item):\n",
    "        e_area = self.embed_area(area)\n",
    "        e_item = self.embed_item(item)\n",
    "        x = torch.cat([num, e_area, e_item], dim=-1).transpose(1, 2)\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def objective_cnn(trial):\n",
    "    params = {\n",
    "        'filters': trial.suggest_categorical('filters', [64, 128]),\n",
    "        'kernel': trial.suggest_categorical('kernel', [2, 3]),\n",
    "        'dense_units': trial.suggest_categorical('dense_units', [32, 64]),\n",
    "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    }\n",
    "    lr = params.pop('lr')\n",
    "    weight_decay = params.pop('weight_decay')\n",
    "    model = CNNModel(N_AREAS, N_ITEMS, **params)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_ds = TensorDataset(*X_train_dl, y_train_t)\n",
    "    val_ds = TensorDataset(*X_val_dl, y_val_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64)\n",
    "    _, _, best_val_rmse = train_dl(model, opt, nn.MSELoss(), train_loader, val_loader, y_scaler)\n",
    "    return best_val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:03,058] A new study created in memory with name: no-name-33436a35-2e23-41f8-af52-f92267fd65c0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning LR ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.18775: 100%|██████████| 1/1 [00:00<00:00, 81.89it/s]\n",
      "[I 2025-11-17 11:18:03,074] A new study created in memory with name: no-name-0b73434d-1b7d-48ad-909a-98177b8a79a2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:03,069] Trial 0 finished with value: 1.1877468914521914 and parameters: {}. Best is trial 0 with value: 1.1877468914521914.\n",
      "Best params for LR: {}\n",
      "--- Tuning RF ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.32379:   4%|▍         | 1/25 [00:03<01:18,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:06,350] Trial 0 finished with value: 1.3237878823351072 and parameters: {'n_estimators': 127, 'max_depth': 14, 'min_samples_leaf': 4, 'max_features': 0.7953033103358108}. Best is trial 0 with value: 1.3237878823351072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.31195:   8%|▊         | 2/25 [00:11<02:21,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:14,536] Trial 1 finished with value: 1.3119478296928748 and parameters: {'n_estimators': 310, 'max_depth': 19, 'min_samples_leaf': 4, 'max_features': 0.8108813840377675}. Best is trial 1 with value: 1.3119478296928748.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.31195:  12%|█▏        | 3/25 [00:20<02:45,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:23,655] Trial 2 finished with value: 1.331065843254153 and parameters: {'n_estimators': 368, 'max_depth': 24, 'min_samples_leaf': 3, 'max_features': 0.7469197316050981}. Best is trial 1 with value: 1.3119478296928748.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 1.30302:  16%|█▌        | 4/25 [00:24<02:07,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:27,560] Trial 3 finished with value: 1.3030187249856495 and parameters: {'n_estimators': 304, 'max_depth': 9, 'min_samples_leaf': 4, 'max_features': 0.8482974246181636}. Best is trial 3 with value: 1.3030187249856495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 1.30302:  20%|██        | 5/25 [00:26<01:29,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:29,196] Trial 4 finished with value: 1.3054598149104342 and parameters: {'n_estimators': 88, 'max_depth': 12, 'min_samples_leaf': 6, 'max_features': 0.9528407639199832}. Best is trial 3 with value: 1.3030187249856495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  24%|██▍       | 6/25 [00:31<01:31,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:34,643] Trial 5 finished with value: 1.3016511225537162 and parameters: {'n_estimators': 248, 'max_depth': 16, 'min_samples_leaf': 6, 'max_features': 0.9445279166656848}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  28%|██▊       | 7/25 [00:34<01:18,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:38,058] Trial 6 finished with value: 1.3645510000072751 and parameters: {'n_estimators': 192, 'max_depth': 27, 'min_samples_leaf': 2, 'max_features': 0.5052496931052741}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  32%|███▏      | 8/25 [00:40<01:18,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:43,280] Trial 7 finished with value: 1.310126980885065 and parameters: {'n_estimators': 382, 'max_depth': 9, 'min_samples_leaf': 7, 'max_features': 0.8784818858239706}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  36%|███▌      | 9/25 [00:41<00:58,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:44,860] Trial 8 finished with value: 1.3218879050282537 and parameters: {'n_estimators': 52, 'max_depth': 24, 'min_samples_leaf': 10, 'max_features': 0.9717924020872124}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  40%|████      | 10/25 [00:47<01:02,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:50,161] Trial 9 finished with value: 1.3206485781738786 and parameters: {'n_estimators': 235, 'max_depth': 17, 'min_samples_leaf': 10, 'max_features': 0.8793196734562245}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  44%|████▍     | 11/25 [00:48<00:46,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:51,577] Trial 10 finished with value: 1.3377873987280264 and parameters: {'n_estimators': 198, 'max_depth': 6, 'min_samples_leaf': 8, 'max_features': 0.6373375886399812}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  48%|████▊     | 12/25 [00:50<00:38,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:53,760] Trial 11 finished with value: 1.3124835559123338 and parameters: {'n_estimators': 290, 'max_depth': 5, 'min_samples_leaf': 5, 'max_features': 0.8915300158486481}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  52%|█████▏    | 13/25 [00:55<00:41,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:18:58,175] Trial 12 finished with value: 1.3884372251913286 and parameters: {'n_estimators': 284, 'max_depth': 12, 'min_samples_leaf': 1, 'max_features': 0.702842467821634}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  56%|█████▌    | 14/25 [01:01<00:46,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:04,381] Trial 13 finished with value: 1.3100765057644737 and parameters: {'n_estimators': 243, 'max_depth': 20, 'min_samples_leaf': 8, 'max_features': 0.9373150464070276}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  60%|██████    | 15/25 [01:07<00:49,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:10,958] Trial 14 finished with value: 1.3063150974965747 and parameters: {'n_estimators': 337, 'max_depth': 15, 'min_samples_leaf': 6, 'max_features': 0.8202679219356137}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 1.30165:  64%|██████▍   | 16/25 [01:09<00:35,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:12,625] Trial 15 finished with value: 1.3125565110853123 and parameters: {'n_estimators': 157, 'max_depth': 9, 'min_samples_leaf': 4, 'max_features': 0.6821652795957311}. Best is trial 5 with value: 1.3016511225537162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347:  68%|██████▊   | 17/25 [01:13<00:31,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:16,656] Trial 16 finished with value: 1.2934699421966933 and parameters: {'n_estimators': 269, 'max_depth': 9, 'min_samples_leaf': 5, 'max_features': 0.9821874749184043}. Best is trial 16 with value: 1.2934699421966933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347:  72%|███████▏  | 18/25 [01:20<00:34,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:23,971] Trial 17 finished with value: 1.301562546506108 and parameters: {'n_estimators': 256, 'max_depth': 22, 'min_samples_leaf': 7, 'max_features': 0.9967517590245661}. Best is trial 16 with value: 1.2934699421966933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347:  76%|███████▌  | 19/25 [01:26<00:31,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:29,908] Trial 18 finished with value: 1.3071013519950847 and parameters: {'n_estimators': 203, 'max_depth': 29, 'min_samples_leaf': 8, 'max_features': 0.9984857597110453}. Best is trial 16 with value: 1.2934699421966933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347:  80%|████████  | 20/25 [01:30<00:24,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:33,920] Trial 19 finished with value: 1.3419417160469826 and parameters: {'n_estimators': 265, 'max_depth': 22, 'min_samples_leaf': 7, 'max_features': 0.5624964194242656}. Best is trial 16 with value: 1.2934699421966933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347:  84%|████████▍ | 21/25 [01:39<00:24,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:42,745] Trial 20 finished with value: 1.3151756854201597 and parameters: {'n_estimators': 327, 'max_depth': 26, 'min_samples_leaf': 9, 'max_features': 0.9967824067205963}. Best is trial 16 with value: 1.2934699421966933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347:  88%|████████▊ | 22/25 [01:45<00:18,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:48,964] Trial 21 finished with value: 1.3007729535715478 and parameters: {'n_estimators': 257, 'max_depth': 16, 'min_samples_leaf': 5, 'max_features': 0.9204851554646619}. Best is trial 16 with value: 1.2934699421966933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347:  92%|█████████▏| 23/25 [01:53<00:13,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:19:56,571] Trial 22 finished with value: 1.3011374770221806 and parameters: {'n_estimators': 269, 'max_depth': 20, 'min_samples_leaf': 5, 'max_features': 0.9163543099170801}. Best is trial 16 with value: 1.2934699421966933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347:  96%|█████████▌| 24/25 [01:59<00:06,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:02,740] Trial 23 finished with value: 1.304328721849824 and parameters: {'n_estimators': 214, 'max_depth': 19, 'min_samples_leaf': 5, 'max_features': 0.9066785877575121}. Best is trial 16 with value: 1.2934699421966933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.29347: 100%|██████████| 25/25 [02:06<00:00,  5.08s/it]\n",
      "[I 2025-11-17 11:20:10,036] A new study created in memory with name: no-name-58a442bb-1ae7-453d-a43e-a86bd3036a8f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:10,030] Trial 24 finished with value: 1.316771018535357 and parameters: {'n_estimators': 349, 'max_depth': 13, 'min_samples_leaf': 3, 'max_features': 0.924170223976238}. Best is trial 16 with value: 1.2934699421966933.\n",
      "Best params for RF: {'n_estimators': 269, 'max_depth': 9, 'min_samples_leaf': 5, 'max_features': 0.9821874749184043}\n",
      "--- Tuning XGB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.41262:   4%|▍         | 1/25 [00:01<00:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:11,584] Trial 0 finished with value: 1.4126246074782591 and parameters: {'n_estimators': 1183, 'max_depth': 6, 'learning_rate': 0.005666911064757407, 'subsample': 0.9459901659419461, 'colsample_bytree': 0.9239210663423749, 'gamma': 1.3773467133132304}. Best is trial 0 with value: 1.4126246074782591.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:   8%|▊         | 2/25 [00:03<00:37,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:13,245] Trial 1 finished with value: 1.3868454997152093 and parameters: {'n_estimators': 1470, 'max_depth': 5, 'learning_rate': 0.002707125159094296, 'subsample': 0.6044122947953006, 'colsample_bytree': 0.9567752639488263, 'gamma': 3.4441813507200854}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  12%|█▏        | 3/25 [00:03<00:21,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:13,462] Trial 2 finished with value: 1.4023572376138884 and parameters: {'n_estimators': 1563, 'max_depth': 4, 'learning_rate': 0.036093456857605406, 'subsample': 0.7867477713446525, 'colsample_bytree': 0.7144268922356528, 'gamma': 2.0000163355044016}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  16%|█▌        | 4/25 [00:04<00:20,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:14,382] Trial 3 finished with value: 1.4157671826266554 and parameters: {'n_estimators': 1651, 'max_depth': 7, 'learning_rate': 0.0105517031610205, 'subsample': 0.8856288469750362, 'colsample_bytree': 0.7315765956030157, 'gamma': 1.7506565239211453}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  20%|██        | 5/25 [00:08<00:45,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:18,969] Trial 4 finished with value: 1.4491816977538434 and parameters: {'n_estimators': 1993, 'max_depth': 10, 'learning_rate': 0.003716429314394576, 'subsample': 0.9780690687570613, 'colsample_bytree': 0.6087223451585403, 'gamma': 0.9970079871990262}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  24%|██▍       | 6/25 [00:09<00:31,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:19,390] Trial 5 finished with value: 1.427800445770593 and parameters: {'n_estimators': 1310, 'max_depth': 8, 'learning_rate': 0.030816528764209934, 'subsample': 0.9941470574410317, 'colsample_bytree': 0.8453576532806993, 'gamma': 2.0710611831584185}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  28%|██▊       | 7/25 [00:11<00:31,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:21,291] Trial 6 finished with value: 1.4371831899871672 and parameters: {'n_estimators': 802, 'max_depth': 11, 'learning_rate': 0.0054219048848085285, 'subsample': 0.6719265894483845, 'colsample_bytree': 0.6685351433293973, 'gamma': 3.0622025120522585}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  32%|███▏      | 8/25 [00:13<00:31,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:23,427] Trial 7 finished with value: 1.4568276318181912 and parameters: {'n_estimators': 629, 'max_depth': 11, 'learning_rate': 0.0035139123472721486, 'subsample': 0.8471958632737626, 'colsample_bytree': 0.8624707188016052, 'gamma': 3.583781417729168}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  36%|███▌      | 9/25 [00:19<00:48,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:29,063] Trial 8 finished with value: 1.4285482188646528 and parameters: {'n_estimators': 1752, 'max_depth': 11, 'learning_rate': 0.0018027676099492535, 'subsample': 0.7404489446073645, 'colsample_bytree': 0.9297770835522645, 'gamma': 2.782352043059718}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  40%|████      | 10/25 [00:19<00:33,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:29,512] Trial 9 finished with value: 1.4092316439445032 and parameters: {'n_estimators': 1314, 'max_depth': 8, 'learning_rate': 0.027208552063069647, 'subsample': 0.64349877875749, 'colsample_bytree': 0.816397046896, 'gamma': 1.777635935088293}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  44%|████▍     | 11/25 [00:20<00:25,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:30,491] Trial 10 finished with value: 1.5576634066793031 and parameters: {'n_estimators': 992, 'max_depth': 3, 'learning_rate': 0.0010771454513609214, 'subsample': 0.6175159793692363, 'colsample_bytree': 0.998775636099762, 'gamma': 4.9180388472986065}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  48%|████▊     | 12/25 [00:20<00:18,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:30,928] Trial 11 finished with value: 1.3961835601203718 and parameters: {'n_estimators': 1531, 'max_depth': 4, 'learning_rate': 0.014022926203464679, 'subsample': 0.754791209073915, 'colsample_bytree': 0.7507631164358838, 'gamma': 4.039078098999485}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  52%|█████▏    | 13/25 [00:21<00:13,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:31,397] Trial 12 finished with value: 1.3975281144410947 and parameters: {'n_estimators': 1462, 'max_depth': 5, 'learning_rate': 0.011535876767580585, 'subsample': 0.7327618468107024, 'colsample_bytree': 0.7473381761053016, 'gamma': 4.177755999435998}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  56%|█████▌    | 14/25 [00:21<00:09,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:31,716] Trial 13 finished with value: 1.3921960974756782 and parameters: {'n_estimators': 1863, 'max_depth': 3, 'learning_rate': 0.01638411028569211, 'subsample': 0.7003699945976607, 'colsample_bytree': 0.7679598548569144, 'gamma': 3.9283105350157372}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  60%|██████    | 15/25 [00:23<00:10,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:33,259] Trial 14 finished with value: 1.3893373241002696 and parameters: {'n_estimators': 1998, 'max_depth': 3, 'learning_rate': 0.0020039724904930304, 'subsample': 0.6858698302077438, 'colsample_bytree': 0.8890993256164056, 'gamma': 4.965347167030881}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  64%|██████▍   | 16/25 [00:25<00:12,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:35,405] Trial 15 finished with value: 1.3902088162770052 and parameters: {'n_estimators': 1899, 'max_depth': 5, 'learning_rate': 0.001965249175873605, 'subsample': 0.6105449510084581, 'colsample_bytree': 0.9967880348968271, 'gamma': 0.06837136643057073}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  68%|██████▊   | 17/25 [00:27<00:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:37,103] Trial 16 finished with value: 1.4228331253134257 and parameters: {'n_estimators': 1118, 'max_depth': 6, 'learning_rate': 0.0021099018241667504, 'subsample': 0.6690915407092289, 'colsample_bytree': 0.9015662467033445, 'gamma': 4.9813205974168655}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  72%|███████▏  | 18/25 [00:28<00:10,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:38,780] Trial 17 finished with value: 1.4546827141691465 and parameters: {'n_estimators': 1781, 'max_depth': 3, 'learning_rate': 0.0011107030614044707, 'subsample': 0.6063489811746231, 'colsample_bytree': 0.9504130467436934, 'gamma': 3.308412499194212}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  76%|███████▌  | 19/25 [00:30<00:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:40,552] Trial 18 finished with value: 1.4133962805399398 and parameters: {'n_estimators': 931, 'max_depth': 5, 'learning_rate': 0.0029481801168205492, 'subsample': 0.6839400500890325, 'colsample_bytree': 0.8700443632732279, 'gamma': 4.481890448915032}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  80%|████████  | 20/25 [00:32<00:08,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:42,232] Trial 19 finished with value: 1.4173545079806171 and parameters: {'n_estimators': 1445, 'max_depth': 9, 'learning_rate': 0.007182240317672763, 'subsample': 0.8347676015777074, 'colsample_bytree': 0.950166249554744, 'gamma': 2.5408223001522905}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  84%|████████▍ | 21/25 [00:33<00:06,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:43,830] Trial 20 finished with value: 1.4180645623335095 and parameters: {'n_estimators': 1690, 'max_depth': 4, 'learning_rate': 0.0014967663669485402, 'subsample': 0.6462584375926912, 'colsample_bytree': 0.81756676361547, 'gamma': 4.521961240668922}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  88%|████████▊ | 22/25 [00:35<00:04,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:45,559] Trial 21 finished with value: 1.3927641216310311 and parameters: {'n_estimators': 1992, 'max_depth': 5, 'learning_rate': 0.002271243288360474, 'subsample': 0.6017827949042933, 'colsample_bytree': 0.9980391507496155, 'gamma': 0.1723086153460768}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  92%|█████████▏| 23/25 [00:37<00:03,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:47,633] Trial 22 finished with value: 1.3969709259456278 and parameters: {'n_estimators': 1901, 'max_depth': 6, 'learning_rate': 0.002763179037318324, 'subsample': 0.6341398886790031, 'colsample_bytree': 0.9669928203305969, 'gamma': 0.31307210461160395}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685:  96%|█████████▌| 24/25 [00:39<00:01,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:49,417] Trial 23 finished with value: 1.4121103725771291 and parameters: {'n_estimators': 1850, 'max_depth': 4, 'learning_rate': 0.0014510626593219032, 'subsample': 0.7237863971335747, 'colsample_bytree': 0.906945434946494, 'gamma': 0.7554964139881655}. Best is trial 1 with value: 1.3868454997152093.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.38685: 100%|██████████| 25/25 [00:41<00:00,  1.65s/it]\n",
      "[I 2025-11-17 11:20:51,228] A new study created in memory with name: no-name-44c492fc-808e-41f8-8678-15dcda19caa2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:20:51,224] Trial 24 finished with value: 1.4090271940050099 and parameters: {'n_estimators': 1655, 'max_depth': 7, 'learning_rate': 0.004526335425755974, 'subsample': 0.7001556496588544, 'colsample_bytree': 0.9748693450839212, 'gamma': 3.5585819531079275}. Best is trial 1 with value: 1.3868454997152093.\n",
      "Best params for XGB: {'n_estimators': 1470, 'max_depth': 5, 'learning_rate': 0.002707125159094296, 'subsample': 0.6044122947953006, 'colsample_bytree': 0.9567752639488263, 'gamma': 3.4441813507200854}\n",
      "--- Tuning LSTM ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.67768:   7%|▋         | 1/15 [00:41<09:42, 41.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:21:32,836] Trial 0 finished with value: 1.6776844945382643 and parameters: {'lstm_units': 64, 'dense_units': 32, 'dropout': 0.17575043254224332, 'lr': 0.0004294105118937871, 'weight_decay': 1.0627320213368103e-05}. Best is trial 0 with value: 1.6776844945382643.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.67768:  13%|█▎        | 2/15 [01:33<10:17, 47.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:22:24,449] Trial 1 finished with value: 1.695263347704261 and parameters: {'lstm_units': 128, 'dense_units': 32, 'dropout': 0.2926060942625537, 'lr': 0.002145708920990918, 'weight_decay': 0.0001820490258352781}. Best is trial 0 with value: 1.6776844945382643.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.67768:  20%|██        | 3/15 [01:48<06:32, 32.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:22:39,505] Trial 2 finished with value: 1.7454551536024363 and parameters: {'lstm_units': 128, 'dense_units': 32, 'dropout': 0.3765145253151616, 'lr': 0.00022705571314674908, 'weight_decay': 0.00031611015952137596}. Best is trial 0 with value: 1.6776844945382643.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.67768:  27%|██▋       | 4/15 [02:13<05:28, 29.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:23:04,997] Trial 3 finished with value: 1.7451139769180386 and parameters: {'lstm_units': 128, 'dense_units': 32, 'dropout': 0.30455953626877763, 'lr': 0.005777904411815902, 'weight_decay': 4.6629260568758854e-05}. Best is trial 0 with value: 1.6776844945382643.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.67768:  33%|███▎      | 5/15 [02:31<04:13, 25.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:23:22,311] Trial 4 finished with value: 1.734802262199146 and parameters: {'lstm_units': 64, 'dense_units': 64, 'dropout': 0.3689918542050725, 'lr': 0.0009678290962017685, 'weight_decay': 1.0843575272177972e-05}. Best is trial 0 with value: 1.6776844945382643.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.67768:  40%|████      | 6/15 [02:54<03:42, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:23:45,764] Trial 5 finished with value: 1.729663187767574 and parameters: {'lstm_units': 64, 'dense_units': 64, 'dropout': 0.27304496242944193, 'lr': 0.004252891943366674, 'weight_decay': 2.7089896216735266e-05}. Best is trial 0 with value: 1.6776844945382643.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 1.67179:  47%|████▋     | 7/15 [03:56<04:54, 36.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:24:47,478] Trial 6 finished with value: 1.671792001535755 and parameters: {'lstm_units': 128, 'dense_units': 32, 'dropout': 0.19542703532748512, 'lr': 0.0004437280938446898, 'weight_decay': 0.00026714365996161467}. Best is trial 6 with value: 1.671792001535755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 1.67179:  53%|█████▎    | 8/15 [04:49<04:54, 42.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:25:40,733] Trial 7 finished with value: 1.6875423143521118 and parameters: {'lstm_units': 128, 'dense_units': 64, 'dropout': 0.3018037322036329, 'lr': 0.0016799381451982865, 'weight_decay': 0.00019228419512275644}. Best is trial 6 with value: 1.671792001535755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 1.67179:  60%|██████    | 9/15 [05:46<04:40, 46.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:26:37,638] Trial 8 finished with value: 1.7448161185150168 and parameters: {'lstm_units': 64, 'dense_units': 64, 'dropout': 0.23430304233182203, 'lr': 0.00010223579819587528, 'weight_decay': 5.092144622370558e-05}. Best is trial 6 with value: 1.671792001535755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 1.67179:  67%|██████▋   | 10/15 [05:57<02:58, 35.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:26:48,970] Trial 9 finished with value: 1.7449112884357467 and parameters: {'lstm_units': 64, 'dense_units': 32, 'dropout': 0.1783151066801978, 'lr': 0.002443251353443344, 'weight_decay': 0.0008442965178437776}. Best is trial 6 with value: 1.671792001535755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 1.67179:  73%|███████▎  | 11/15 [06:11<01:56, 29.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:27:02,985] Trial 10 finished with value: 1.7455796545294078 and parameters: {'lstm_units': 128, 'dense_units': 32, 'dropout': 0.11669585052562781, 'lr': 0.0005234466510409959, 'weight_decay': 0.0009263224793399571}. Best is trial 6 with value: 1.671792001535755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 1.67179:  80%|████████  | 12/15 [06:23<01:11, 23.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:27:14,505] Trial 11 finished with value: 1.7459315965019067 and parameters: {'lstm_units': 64, 'dense_units': 32, 'dropout': 0.18017483183730515, 'lr': 0.00043806489824542986, 'weight_decay': 1.0260282543590158e-05}. Best is trial 6 with value: 1.671792001535755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 1.67179:  87%|████████▋ | 13/15 [06:50<00:49, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:27:41,311] Trial 12 finished with value: 1.7433477395789316 and parameters: {'lstm_units': 64, 'dense_units': 32, 'dropout': 0.18738416852391837, 'lr': 0.00027781085041593507, 'weight_decay': 0.0003503566614732333}. Best is trial 6 with value: 1.671792001535755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 1.63478:  93%|█████████▎| 14/15 [07:49<00:35, 35.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:28:41,057] Trial 13 finished with value: 1.6347789695495891 and parameters: {'lstm_units': 128, 'dense_units': 32, 'dropout': 0.10229058258091793, 'lr': 0.0006881935229186687, 'weight_decay': 7.466224843062375e-05}. Best is trial 13 with value: 1.6347789695495891.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 1.63478: 100%|██████████| 15/15 [08:42<00:00, 34.81s/it]\n",
      "[I 2025-11-17 11:29:33,351] A new study created in memory with name: no-name-e35d5ec9-54ae-465a-af88-6c041553f975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 11:29:33,345] Trial 14 finished with value: 1.6888845909353971 and parameters: {'lstm_units': 128, 'dense_units': 32, 'dropout': 0.11227145703485898, 'lr': 0.0008625518636271353, 'weight_decay': 9.739400462859756e-05}. Best is trial 13 with value: 1.6347789695495891.\n",
      "Best params for LSTM: {'lstm_units': 128, 'dense_units': 32, 'dropout': 0.10229058258091793, 'lr': 0.0006881935229186687, 'weight_decay': 7.466224843062375e-05}\n",
      "--- Tuning CNN ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-17 11:29:52,649] Trial 0 failed with parameters: {'filters': 128, 'kernel': 3, 'dense_units': 32, 'lr': 0.0007431836616249293, 'weight_decay': 0.0006689897869381488} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Temp\\ipykernel_17128\\1364281096.py\", line 157, in objective_cnn\n",
      "    _, _, best_val_rmse = train_dl(model, opt, nn.MSELoss(), train_loader, val_loader, y_scaler)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Temp\\ipykernel_17128\\1364281096.py\", line 73, in train_dl\n",
      "    for x1, x2, x3, y in train_loader:\n",
      "                         ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 788, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n",
      "    collate(samples, collate_fn_map=collate_fn_map)\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PavinP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 272, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-17 11:29:52,715] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m'\u001b[39m\u001b[33mLR\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     21\u001b[39m     n_trials = \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjectives\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m best_params[name] = study.best_params\n\u001b[32m     24\u001b[39m studies[name] = study\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 157\u001b[39m, in \u001b[36mobjective_cnn\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    155\u001b[39m train_loader = DataLoader(train_ds, batch_size=\u001b[32m64\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    156\u001b[39m val_loader = DataLoader(val_ds, batch_size=\u001b[32m64\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m _, _, best_val_rmse = \u001b[43mtrain_dl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_scaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m best_val_rmse\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mtrain_dl\u001b[39m\u001b[34m(model, opt, loss_fn, train_loader, val_loader, target_scaler, epochs, patience, is_final)\u001b[39m\n\u001b[32m     71\u001b[39m model.train()\n\u001b[32m     72\u001b[39m train_loss = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists('best_params_optuna.joblib'):\n",
    "    best_params = joblib.load('best_params_optuna.joblib')\n",
    "else:\n",
    "    best_params = {}\n",
    "\n",
    "if RUN_OPTUNA:\n",
    "    studies = {}\n",
    "    objectives = {\n",
    "        'LR': objective_lr,\n",
    "        'RF': objective_rf,\n",
    "        'XGB': objective_xgb,\n",
    "        'LSTM': objective_lstm,\n",
    "        'CNN': objective_cnn\n",
    "    }\n",
    "    for name, run in RUN_MODELS.items():\n",
    "        if run:\n",
    "            print(f'--- Tuning {name} ---')\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            n_trials = 25 if name in ['RF', 'XGB'] else 15\n",
    "            if name == 'LR':\n",
    "                n_trials = 1\n",
    "            study.optimize(objectives[name], n_trials=n_trials, show_progress_bar=True)\n",
    "            best_params[name] = study.best_params\n",
    "            studies[name] = study\n",
    "            joblib.dump(best_params, 'best_params_optuna.joblib') # Save after each study\n",
    "            print(f'Best params for {name}: {study.best_params}')\n",
    "else:\n",
    "    print('Skipping Optuna tuning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7a. Visualize Optuna Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "\n",
    "if RUN_OPTUNA and 'studies' in locals():\n",
    "    for name, study in studies.items():\n",
    "        if name == 'LR' or not study.trials:\n",
    "            continue\n",
    "        print(f'--- Visualizing Optuna results for {name} ---')\n",
    "        \n",
    "        # Optimization History\n",
    "        fig = plot_optimization_history(study)\n",
    "        fig.update_layout(title=f'{name} Optimization History')\n",
    "        fig.write_image(f'optuna_{name}_history.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Parallel Coordinate\n",
    "        fig = plot_parallel_coordinate(study)\n",
    "        fig.update_layout(title=f'{name} Parallel Coordinate')\n",
    "        fig.write_image(f'optuna_{name}_parallel_coordinate.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Slice Plot\n",
    "        fig = plot_slice(study)\n",
    "        fig.update_layout(title=f'{name} Slice Plot')\n",
    "        fig.write_image(f'optuna_{name}_slice.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Parameter Importance\n",
    "        try:\n",
    "            fig = plot_param_importances(study)\n",
    "            fig.update_layout(title=f'{name} Parameter Importance')\n",
    "            fig.write_image(f'optuna_{name}_param_importance.png')\n",
    "            fig.show()\n",
    "        except (ValueError, RuntimeError) as e:\n",
    "            print(f'Could not plot parameter importance for {name}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Training (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train+val for final ML model training\n",
    "X_train_full_ml = pd.concat([X_train_ml, X_val_ml])\n",
    "y_train_full_ml = pd.concat([y_train_ml, y_val_ml])\n",
    "\n",
    "models = {}\n",
    "print(\"--- Final Model Training ---\")\n",
    "\n",
    "if RUN_MODELS['LR']:\n",
    "    print(\"Training Linear Regression...\")\n",
    "    model_lr = LinearRegression()\n",
    "    model_lr.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['LR'] = model_lr\n",
    "    joblib.dump(model_lr, 'model_lr.joblib')\n",
    "\n",
    "if RUN_MODELS['RF']:\n",
    "    print(\"Training Random Forest...\")\n",
    "    # Use best params from Optuna, or default if not run\n",
    "    rf_params = best_params.get('RF', {'n_estimators': 100, 'max_depth': 10})\n",
    "    model_rf = RandomForestRegressor(random_state=42, n_jobs=-1, **rf_params)\n",
    "    model_rf.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['RF'] = model_rf\n",
    "    joblib.dump(model_rf, 'model_rf.joblib')\n",
    "\n",
    "if RUN_MODELS['XGB']:\n",
    "    print(\"Training XGBoost...\")\n",
    "    xgb_params = best_params.get('XGB', {'n_estimators': 200, 'learning_rate': 0.05})\n",
    "    model_xgb = xgb.XGBRegressor(random_state=42, **xgb_params)\n",
    "    model_xgb.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['XGB'] = model_xgb\n",
    "    joblib.dump(model_xgb, 'model_xgb.joblib')\n",
    "\n",
    "# Combine train+val for final DL model training\n",
    "X_train_full_seq = np.concatenate([X_train_seq, X_val_seq])\n",
    "y_train_full_seq = np.concatenate([y_train_seq, y_val_seq])\n",
    "X_train_full_dl = split_dl(X_train_full_seq)\n",
    "y_train_full_t = torch.tensor(y_train_full_seq, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_full_ds = TensorDataset(*[x.to(device) for x in X_train_full_dl], y_train_full_t.to(device))\n",
    "test_ds = TensorDataset(*[x.to(device) for x in X_test_dl], y_test_t.to(device))\n",
    "train_loader = DataLoader(train_full_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "if RUN_MODELS['LSTM']:\n",
    "    print(\"Training LSTM...\")\n",
    "    lstm_params = best_params.get('LSTM', {'lstm_units': 64, 'dense_units': 32, 'dropout': 0.2})\n",
    "    lr = lstm_params.pop('lr', 0.001)\n",
    "    weight_decay = lstm_params.pop('weight_decay', 1e-4)\n",
    "    model_lstm = LSTMModel(N_AREAS, N_ITEMS, **lstm_params).to(device)\n",
    "    opt_lstm = optim.Adam(model_lstm.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_losses_lstm, val_losses_lstm, _ = train_dl(model_lstm, opt_lstm, nn.MSELoss(), train_loader, test_loader, y_scaler, epochs=150, patience=15, is_final=True)\n",
    "    models['LSTM'] = model_lstm\n",
    "\n",
    "if RUN_MODELS['CNN']:\n",
    "    print(\"Training CNN...\")\n",
    "    cnn_params = best_params.get('CNN', {'filters': 64, 'kernel': 2, 'dense_units': 32})\n",
    "    lr = cnn_params.pop('lr', 0.001)\n",
    "    weight_decay = cnn_params.pop('weight_decay', 1e-4)\n",
    "    model_cnn = CNNModel(N_AREAS, N_ITEMS, **cnn_params).to(device)\n",
    "    opt_cnn = optim.Adam(model_cnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_losses_cnn, val_losses_cnn, _ = train_dl(model_cnn, opt_cnn, nn.MSELoss(), train_loader, test_loader, y_scaler, epochs=150, patience=15, is_final=True)\n",
    "    models['CNN'] = model_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot DL Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODELS['LSTM'] and RUN_MODELS['CNN']:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))\n",
    "    ax1.plot(train_losses_lstm, label='Train Loss')\n",
    "    ax1.plot(val_losses_lstm, label='Validation (Test) Loss')\n",
    "    ax1.set_title('LSTM Model Loss', fontsize=16)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Mean Squared Error')\n",
    "    ax1.legend()\n",
    "    ax2.plot(train_losses_cnn, label='Train Loss')\n",
    "    ax2.plot(val_losses_cnn, label='Validation (Test) Loss')\n",
    "    ax2.set_title('CNN Model Loss', fontsize=16)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Mean Squared Error')\n",
    "    ax2.legend()\n",
    "    plt.suptitle('Deep Learning Training Curves', fontsize=20)\n",
    "    plt.savefig(\"loss_curves.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_yield(y_pred_scaled, df_ref, y_scaler_obj):\n",
    "    \"\"\"Inverse transforms a prediction to the original yield scale.\"\"\"\n",
    "    if y_pred_scaled.ndim == 1:\n",
    "        y_pred_scaled = y_pred_scaled.reshape(-1, 1)\n",
    "    \n",
    "    y_pred_detrended = y_scaler_obj.inverse_transform(y_pred_scaled)\n",
    "    \n",
    "    trend = df_ref['yield_trend'].values.reshape(-1, 1)\n",
    "    y_pred_actual = y_pred_detrended + trend\n",
    "    \n",
    "    return y_pred_actual.flatten()\n",
    "\n",
    "# --- Evaluation ---\n",
    "results = []\n",
    "y_preds_original = {}\n",
    "\n",
    "print(\"\\n--- Final Performance (Test Set) ---\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name in ['LR', 'RF', 'XGB']:\n",
    "        # Predict on the scaled test set\n",
    "        preds_scaled = model.predict(X_test_ml)\n",
    "        # Reconstruct the predictions\n",
    "        pred_orig = reconstruct_yield(preds_scaled, test_df, y_scaler)\n",
    "        y_true_orig = test_df[TARGET].values\n",
    "        # Store for later use\n",
    "        y_preds_original[name] = pred_orig\n",
    "        \n",
    "    elif name in ['LSTM', 'CNN']:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Predict on the scaled test set\n",
    "            preds_scaled_t = model(*[x.to(device) for x in X_test_dl])\n",
    "            preds_scaled = preds_scaled_t.cpu().numpy()\n",
    "            # Reconstruct the predictions\n",
    "            pred_orig = reconstruct_yield(preds_scaled, test_df_dl_seq_ref, y_scaler)\n",
    "            y_true_orig = test_df_dl_seq_ref[TARGET].values\n",
    "            # Store for later use\n",
    "            y_preds_original[name] = pred_orig\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true_orig, pred_orig)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_orig, pred_orig))\n",
    "    map_e = mape(y_true_orig, pred_orig)\n",
    "    rms_pe = rmspe(y_true_orig, pred_orig)\n",
    "    r_2 = r2_score(y_true_orig, pred_orig)\n",
    "    results.append({'Model': name, 'MAE': mae, 'RMSE': rmse, 'MAPE (%)': map_e, 'RMSPE (%)': rms_pe, 'R²': r_2})\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index('Model').sort_values('RMSE')\n",
    "print(results_df.round(2))\n",
    "results_df.to_csv(\"final_model_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plot Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(24, 6))\n",
    "sns.barplot(data=results_df.reset_index(), x='Model', y='RMSE', ax=axs[0])\n",
    "axs[0].set_title('RMSE Comparison')\n",
    "sns.barplot(x='Model', y='MAE', data=results_df.reset_index(), ax=axs[1])\n",
    "axs[1].set_title('MAE Comparison')\n",
    "sns.barplot(x='Model', y='MAPE (%)', data=results_df.reset_index(), ax=axs[2])\n",
    "axs[2].set_title('MAPE Comparison')\n",
    "sns.barplot(x='Model', y='R²', data=results_df.reset_index(), ax=axs[3])\n",
    "axs[3].set_title('R² Comparison')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"model_performance_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Per-Crop Reporting (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.index[0]\n",
    "print(f\"Per-crop report for best model: {best_model_name}\")\n",
    "crop_results = []\n",
    "# Use the correctly aligned test dataframe based on the best model\n",
    "if best_model_name in ['LR', 'RF', 'XGB']:\n",
    "    reporting_df = test_df\n",
    "    y_true_original = reporting_df[TARGET].values\n",
    "else:\n",
    "    reporting_df = test_df_dl_seq_ref\n",
    "    y_true_original = reporting_df[TARGET].values\n",
    "\n",
    "items = reporting_df['Item'].values\n",
    "\n",
    "for crop in np.unique(items):\n",
    "    mask = items == crop\n",
    "    true = y_true_original[mask]\n",
    "    pred = y_preds_original[best_model_name][mask]\n",
    "    if len(true) > 0:\n",
    "        crop_results.append({\n",
    "            'Crop': crop,\n",
    "            'RMSPE (%)': rmspe(true, pred),\n",
    "            'MAPE (%)': mape(true, pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(true, pred)),\n",
    "            'R²': r2_score(true, pred)\n",
    "        })\n",
    "crop_df = pd.DataFrame(crop_results).sort_values('RMSPE (%)')\n",
    "print(crop_df.round(2))\n",
    "crop_df.to_csv('per_crop_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. SHAP Analysis (If Tree Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.index[0]\n",
    "if best_model_name in models and best_model_name in ['RF', 'XGB']:\n",
    "    best_model = models[best_model_name]\n",
    "    print(f\"Running SHAP on {best_model_name}\")\n",
    "    # For SHAP, we need to use the correctly aligned test features\n",
    "    X_test_shap = X_test_ml\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X_test_shap)\n",
    "    shap.summary_plot(shap_values, X_test_shap, plot_type=\"beeswarm\", show=False)\n",
    "    plt.title(f\"SHAP Beeswarm ({best_model_name})\", fontsize=16)\n",
    "    plt.savefig(\"shap_beeswarm.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    shap.summary_plot(shap_values, X_test_shap, plot_type=\"bar\", show=False)\n",
    "    plt.title(f\"Feature Importance ({best_model_name})\", fontsize=16)\n",
    "    plt.savefig(\"shap_importance.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"SHAP skipped for non-tree model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Export Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base dataframe for predictions. ML models have more test samples than DL models.\n",
    "final_predictions_df = test_df.copy()\n",
    "final_predictions_df['true_yield_original'] = final_predictions_df[TARGET]\n",
    "\n",
    "# Add predictions. Note that DL predictions will have NaNs for non-sequenced rows.\n",
    "for name, preds in y_preds_original.items():\n",
    "    if name in ['LR', 'RF', 'XGB']:\n",
    "        final_predictions_df[f'predicted_{name}'] = preds\n",
    "    else:\n",
    "        # Align DL predictions with the main test dataframe\n",
    "        dl_preds_series = pd.Series(preds, index=test_df_dl_seq_ref.index, name=f'predicted_{name}')\n",
    "        final_predictions_df = final_predictions_df.join(dl_preds_series)\n",
    "\n",
    "export_cols = ['Year', 'Area', 'Item', 'true_yield_original'] + [f'predicted_{name}' for name in models.keys()]\n",
    "final_predictions_df[export_cols].to_csv(\"final_test_predictions.csv\", index=False)\n",
    "print(\"Exported predictions.\")\n",
    "print(\"\\n--- Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
