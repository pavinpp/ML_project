{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction – Final Model Pipeline (Rev7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "from scipy.signal import detrend\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All libraries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Selection Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_MODELS = {\n",
    "    'LR': True,   # Baseline Linear Regression\n",
    "    'RF': True,   # Random Forest\n",
    "    'XGB': True,  # XGBoost\n",
    "    'LSTM': True, # LSTM\n",
    "    'CNN': True   # CNN\n",
    "}\n",
    "\n",
    "RUN_OPTUNA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"cleaned_crop_data.csv\")\n",
    "    print(f\"Loaded: {df.shape}\")\n",
    "except:\n",
    "    raise FileNotFoundError(\"Run EDA first!\")\n",
    "\n",
    "TARGET = 'hg/ha_yield'\n",
    "TIME_COL = 'Year'\n",
    "CAT_COLS = ['Area', 'Item']\n",
    "NUMERIC_COLS = ['average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp', 'fertilizer_kg/ha', 'solar_radiation_MJ/m2-day']\n",
    "\n",
    "# De-trend per group\n",
    "df = df.sort_values(CAT_COLS + [TIME_COL])\n",
    "df['yield_detrended'] = df.groupby(CAT_COLS)[TARGET].transform(detrend)\n",
    "df['yield_trend'] = df[TARGET] - df['yield_detrended']\n",
    "TARGET_DET = 'yield_detrended'\n",
    "\n",
    "# Lags for ML\n",
    "LAG_COLS = [TARGET_DET] + NUMERIC_COLS\n",
    "for col in LAG_COLS:\n",
    "    for lag in [1, 2]:\n",
    "        df[f'{col}_lag{lag}'] = df.groupby(CAT_COLS)[col].shift(lag)\n",
    "df_ml = df.dropna().copy()\n",
    "\n",
    "# Split\n",
    "TRAIN_END = 2007\n",
    "VAL_END = 2010\n",
    "train_df = df_ml[df_ml[TIME_COL] <= TRAIN_END].copy()\n",
    "val_df = df_ml[(df_ml[TIME_COL] > TRAIN_END) & (df_ml[TIME_COL] <= VAL_END)].copy()\n",
    "test_df = df_ml[df_ml[TIME_COL] > VAL_END].copy()\n",
    "\n",
    "# Encode\n",
    "le_area = LabelEncoder().fit(df_ml['Area'])\n",
    "le_item = LabelEncoder().fit(df_ml['Item'])\n",
    "for d in [train_df, val_df, test_df]:\n",
    "    d['Area_Encoded'] = le_area.transform(d['Area'])\n",
    "    d['Item_Encoded'] = le_item.transform(d['Item'])\n",
    "\n",
    "# Scale\n",
    "lagged_cols = [c for c in df_ml.columns if '_lag' in c]\n",
    "scale_cols = NUMERIC_COLS + lagged_cols\n",
    "scaler = StandardScaler()\n",
    "train_df[scale_cols] = scaler.fit_transform(train_df[scale_cols])\n",
    "val_df[scale_cols] = scaler.transform(val_df[scale_cols])\n",
    "test_df[scale_cols] = scaler.transform(test_df[scale_cols])\n",
    "\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(le_area, 'le_area.joblib')\n",
    "joblib.dump(le_item, 'le_item.joblib')\n",
    "\n",
    "N_AREAS = len(le_area.classes_)\n",
    "N_ITEMS = len(le_item.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML\n",
    "ML_FEATS = NUMERIC_COLS + lagged_cols + ['Area_Encoded', 'Item_Encoded']\n",
    "X_train_ml = train_df[ML_FEATS]\n",
    "y_train_ml = train_df[TARGET_DET]\n",
    "X_val_ml = val_df[ML_FEATS]\n",
    "y_val_ml = val_df[TARGET_DET]\n",
    "X_test_ml = test_df[ML_FEATS]\n",
    "y_test_ml = test_df[TARGET_DET]\n",
    "\n",
    "# DL Sequences\n",
    "LOOKBACK = 5\n",
    "DL_FEATS = NUMERIC_COLS + ['Area_Encoded', 'Item_Encoded']\n",
    "\n",
    "def create_sequences(data, lookback, feats, target):\n",
    "    X, y = [], []\n",
    "    for _, group in data.groupby(CAT_COLS):\n",
    "        if len(group) < lookback:\n",
    "            continue\n",
    "        gf = group[feats].values\n",
    "        gt = group[target].values\n",
    "        for i in range(len(group) - lookback + 1):\n",
    "            X.append(gf[i:i+lookback])\n",
    "            y.append(gt[i+lookback-1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "scaler_dl = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "train_df_dl = df[df[TIME_COL] <= TRAIN_END].copy()\n",
    "val_df_dl = df[(df[TIME_COL] > TRAIN_END) & (df[TIME_COL] <= VAL_END)].copy()\n",
    "test_df_dl = df[df[TIME_COL] > VAL_END].copy()\n",
    "train_df_dl['Area_Encoded'] = le_area.transform(train_df_dl['Area'])\n",
    "train_df_dl['Item_Encoded'] = le_item.transform(train_df_dl['Item'])\n",
    "val_df_dl['Area_Encoded'] = le_area.transform(val_df_dl['Area'])\n",
    "val_df_dl['Item_Encoded'] = le_item.transform(val_df_dl['Item'])\n",
    "test_df_dl['Area_Encoded'] = le_area.transform(test_df_dl['Area'])\n",
    "test_df_dl['Item_Encoded'] = le_item.transform(test_df_dl['Item'])\n",
    "train_df_dl[NUMERIC_COLS] = scaler_dl.fit_transform(train_df_dl[NUMERIC_COLS])\n",
    "val_df_dl[NUMERIC_COLS] = scaler_dl.transform(val_df_dl[NUMERIC_COLS])\n",
    "test_df_dl[NUMERIC_COLS] = scaler_dl.transform(test_df_dl[NUMERIC_COLS])\n",
    "\n",
    "# Fit scaler on train target only\n",
    "train_df_dl[TARGET_DET] = target_scaler.fit_transform(train_df_dl[[TARGET_DET]])\n",
    "val_df_dl[TARGET_DET] = target_scaler.transform(val_df_dl[[TARGET_DET]])\n",
    "test_df_dl[TARGET_DET] = target_scaler.transform(test_df_dl[[TARGET_DET]])\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(train_df_dl, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "X_val_seq, y_val_seq = create_sequences(val_df_dl, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "X_test_seq, y_test_seq = create_sequences(test_df_dl, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "\n",
    "def split_dl(X):\n",
    "    return [\n",
    "        torch.tensor(X[..., :-2], dtype=torch.float32),\n",
    "        torch.tensor(X[..., -2], dtype=torch.long),\n",
    "        torch.tensor(X[..., -1], dtype=torch.long)\n",
    "    ]\n",
    "\n",
    "X_train_dl = split_dl(X_train_seq)\n",
    "X_val_dl = split_dl(X_val_seq)\n",
    "X_test_dl = split_dl(X_test_seq)\n",
    "\n",
    "y_train_t = torch.tensor(y_train_seq, dtype=torch.float32).unsqueeze(1)\n",
    "y_val_t = torch.tensor(y_val_seq, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_t = torch.tensor(y_test_seq, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(((y_true - y_pred) / (y_true + 1e-8)) ** 2)) * 100\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optuna Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial):\n",
    "    # No hyperparameters to tune for Linear Regression\n",
    "    return 0\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_float('max_features', 0.5, 1.0)\n",
    "    }\n",
    "    model = RandomForestRegressor(random_state=42, n_jobs=-1, **params)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_train_ml):\n",
    "        model.fit(X_train_ml.iloc[train_idx], y_train_ml.iloc[train_idx])\n",
    "        pred = model.predict(X_train_ml.iloc[val_idx])\n",
    "        scores.append(rmspe(y_train_ml.iloc[val_idx], pred))\n",
    "    return np.mean(scores)\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5)\n",
    "    }\n",
    "    model = xgb.XGBRegressor(random_state=42, **params)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_train_ml):\n",
    "        model.fit(X_train_ml.iloc[train_idx], y_train_ml.iloc[train_idx])\n",
    "        pred = model.predict(X_train_ml.iloc[val_idx])\n",
    "        scores.append(rmspe(y_train_ml.iloc[val_idx], pred))\n",
    "    return np.mean(scores)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, n_areas, n_items, lstm_units, dense_units, dropout):\n",
    "        super().__init__()\n",
    "        self.embed_area = nn.Embedding(n_areas, 10)\n",
    "        self.embed_item = nn.Embedding(n_items, 5)\n",
    "        self.lstm = nn.LSTM(len(NUMERIC_COLS) + 10 + 5, lstm_units, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(lstm_units, dense_units)\n",
    "        self.fc2 = nn.Linear(dense_units, 1)\n",
    "    def forward(self, num, area, item):\n",
    "        e_area = self.embed_area(area)\n",
    "        e_item = self.embed_item(item)\n",
    "        x = torch.cat([num, e_area, e_item], dim=-1)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.drop(out[:, -1])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        return self.fc2(out)\n",
    "\n",
    "def train_dl(model, opt, loss_fn, train_loader, val_loader, target_scaler, epochs=100, patience=10, is_final=False):\n",
    "    best_val_loss = float('inf')\n",
    "    best_rmspe = float('inf')\n",
    "    wait = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x1, x2, x3, y in train_loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(x1, x2, x3)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_inputs = [x.to(next(model.parameters()).device) for x in val_loader.dataset.tensors[:3]]\n",
    "            val_y = val_loader.dataset.tensors[3]\n",
    "            val_pred = model(*val_inputs)\n",
    "            val_mse = loss_fn(val_pred, val_y).item()\n",
    "            val_losses.append(val_mse)\n",
    "            \n",
    "            y_true_inv = target_scaler.inverse_transform(val_y.cpu().numpy())\n",
    "            y_pred_inv = target_scaler.inverse_transform(val_pred.cpu().numpy())\n",
    "            val_rmspe = rmspe(y_true_inv.flatten(), y_pred_inv.flatten())\n",
    "\n",
    "        if val_mse < best_val_loss:\n",
    "            best_val_loss = val_mse\n",
    "            best_rmspe = val_rmspe\n",
    "            wait = 0\n",
    "            if is_final:\n",
    "                torch.save(model.state_dict(), f'model_{model.__class__.__name__}.pth')\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                break\n",
    "    return train_losses, val_losses, best_val_loss\n",
    "\n",
    "def objective_lstm(trial):\n",
    "    params = {\n",
    "        'lstm_units': trial.suggest_categorical('lstm_units', [64, 128]),\n",
    "        'dense_units': trial.suggest_categorical('dense_units', [32, 64]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.1, 0.4),\n",
    "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    }\n",
    "    lr = params.pop('lr')\n",
    "    weight_decay = params.pop('weight_decay')\n",
    "    model = LSTMModel(N_AREAS, N_ITEMS, **params)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_ds = TensorDataset(*X_train_dl, y_train_t)\n",
    "    val_ds = TensorDataset(*X_val_dl, y_val_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64)\n",
    "    _, _, best_val_loss = train_dl(model, opt, nn.MSELoss(), train_loader, val_loader, target_scaler)\n",
    "    return best_val_loss\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, n_areas, n_items, filters, kernel, dense_units): \n",
    "        super().__init__()\n",
    "        self.embed_area = nn.Embedding(n_areas, 10)\n",
    "        self.embed_item = nn.Embedding(n_items, 5)\n",
    "        self.conv = nn.Conv1d(len(NUMERIC_COLS) + 10 + 5, filters, kernel)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(filters, dense_units)\n",
    "        self.fc2 = nn.Linear(dense_units, 1)\n",
    "    def forward(self, num, area, item):\n",
    "        e_area = self.embed_area(area)\n",
    "        e_item = self.embed_item(item)\n",
    "        x = torch.cat([num, e_area, e_item], dim=-1).transpose(1, 2)\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def objective_cnn(trial):\n",
    "    params = {\n",
    "        'filters': trial.suggest_categorical('filters', [64, 128]),\n",
    "        'kernel': trial.suggest_categorical('kernel', [2, 3]),\n",
    "        'dense_units': trial.suggest_categorical('dense_units', [32, 64]),\n",
    "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    }\n",
    "    lr = params.pop('lr')\n",
    "    weight_decay = params.pop('weight_decay')\n",
    "    model = CNNModel(N_AREAS, N_ITEMS, **params)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_ds = TensorDataset(*X_train_dl, y_train_t)\n",
    "    val_ds = TensorDataset(*X_val_dl, y_val_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64)\n",
    "    _, _, best_val_loss = train_dl(model, opt, nn.MSELoss(), train_loader, val_loader, target_scaler)\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('best_params_optuna.joblib'):\n",
    "    best_params = joblib.load('best_params_optuna.joblib')\n",
    "else:\n",
    "    best_params = {}\n",
    "\n",
    "if RUN_OPTUNA:\n",
    "    studies = {}\n",
    "    objectives = {\n",
    "        'LR': objective_lr,\n",
    "        'RF': objective_rf,\n",
    "        'XGB': objective_xgb,\n",
    "        'LSTM': objective_lstm,\n",
    "        'CNN': objective_cnn\n",
    "    }\n",
    "    for name, run in RUN_MODELS.items():\n",
    "        if run:\n",
    "            print(f'--- Tuning {name} ---')\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            n_trials = 50 if name in ['RF', 'XGB'] else 30\n",
    "            if name == 'LR':\n",
    "                n_trials = 1\n",
    "            study.optimize(objectives[name], n_trials=n_trials, show_progress_bar=True)\n",
    "            best_params[name] = study.best_params\n",
    "            studies[name] = study\n",
    "            joblib.dump(best_params, 'best_params_optuna.joblib') # Save after each study\n",
    "            print(f'Best params for {name}: {study.best_params}')\n",
    "else:\n",
    "    print('Skipping Optuna tuning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7a. Visualize Optuna Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "\n",
    "if RUN_OPTUNA and 'studies' in locals():\n",
    "    for name, study in studies.items():\n",
    "        if name == 'LR' or not study.trials:\n",
    "            continue\n",
    "        print(f'--- Visualizing Optuna results for {name} ---')\n",
    "        \n",
    "        # Optimization History\n",
    "        fig = plot_optimization_history(study)\n",
    "        fig.update_layout(title=f'{name} Optimization History')\n",
    "        fig.write_image(f'optuna_{name}_history.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Parallel Coordinate\n",
    "        fig = plot_parallel_coordinate(study)\n",
    "        fig.update_layout(title=f'{name} Parallel Coordinate')\n",
    "        fig.write_image(f'optuna_{name}_parallel_coordinate.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Slice Plot\n",
    "        fig = plot_slice(study)\n",
    "        fig.update_layout(title=f'{name} Slice Plot')\n",
    "        fig.write_image(f'optuna_{name}_slice.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Parameter Importance\n",
    "        try:\n",
    "            fig = plot_param_importances(study)\n",
    "            fig.update_layout(title=f'{name} Parameter Importance')\n",
    "            fig.write_image(f'optuna_{name}_param_importance.png')\n",
    "            fig.show()\n",
    "        except (ValueError, RuntimeError) as e:\n",
    "            print(f'Could not plot parameter importance for {name}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train+val\n",
    "X_train_full_ml = pd.concat([X_train_ml, X_val_ml])\n",
    "y_train_full_ml = pd.concat([y_train_ml, y_val_ml])\n",
    "X_train_full_seq = np.concatenate([X_train_seq, X_val_seq])\n",
    "y_train_full_seq = np.concatenate([y_train_seq, y_val_seq])\n",
    "X_train_full_dl = split_dl(X_train_full_seq)\n",
    "y_train_full_t = torch.tensor(y_train_full_seq, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "models = {}\n",
    "\n",
    "if RUN_MODELS['LR']:\n",
    "    model_lr = LinearRegression()\n",
    "    model_lr.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['LR'] = model_lr\n",
    "    joblib.dump(model_lr, 'model_lr.joblib')\n",
    "\n",
    "if RUN_MODELS['RF']:\n",
    "    model_rf = RandomForestRegressor(random_state=42, n_jobs=-1, **best_params['RF'])\n",
    "    model_rf.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['RF'] = model_rf\n",
    "    joblib.dump(model_rf, 'model_rf.joblib')\n",
    "\n",
    "if RUN_MODELS['XGB']:\n",
    "    model_xgb = xgb.XGBRegressor(random_state=42, **best_params['XGB'])\n",
    "    model_xgb.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['XGB'] = model_xgb\n",
    "    joblib.dump(model_xgb, 'model_xgb.joblib')\n",
    "\n",
    "# DL\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_full_ds = TensorDataset(*[x.to(device) for x in X_train_full_dl], y_train_full_t.to(device))\n",
    "test_ds = TensorDataset(*[x.to(device) for x in X_test_dl], y_test_t.to(device))\n",
    "train_loader = DataLoader(train_full_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "if RUN_MODELS['LSTM']:\n",
    "    lstm_params = best_params['LSTM'].copy()\n",
    "    lr = lstm_params.pop('lr')\n",
    "    weight_decay = lstm_params.pop('weight_decay')\n",
    "    model_lstm = LSTMModel(N_AREAS, N_ITEMS, **lstm_params).to(device)\n",
    "    opt_lstm = optim.Adam(model_lstm.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_losses_lstm, val_losses_lstm, _ = train_dl(model_lstm, opt_lstm, nn.MSELoss(), train_loader, test_loader, target_scaler, epochs=150, patience=15, is_final=True)\n",
    "    models['LSTM'] = model_lstm\n",
    "\n",
    "if RUN_MODELS['CNN']:\n",
    "    cnn_params = best_params['CNN'].copy()\n",
    "    lr = cnn_params.pop('lr')\n",
    "    weight_decay = cnn_params.pop('weight_decay')\n",
    "    model_cnn = CNNModel(N_AREAS, N_ITEMS, **cnn_params).to(device)\n",
    "    opt_cnn = optim.Adam(model_cnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_losses_cnn, val_losses_cnn, _ = train_dl(model_cnn, opt_cnn, nn.MSELoss(), train_loader, test_loader, target_scaler, epochs=150, patience=15, is_final=True)\n",
    "    models['CNN'] = model_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot DL Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODELS['LSTM'] and RUN_MODELS['CNN']:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))\n",
    "    ax1.plot(train_losses_lstm, label='Train Loss')\n",
    "    ax1.plot(val_losses_lstm, label='Validation (Test) Loss')\n",
    "    ax1.set_title('LSTM Model Loss', fontsize=16)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Mean Squared Error')\n",
    "    ax1.legend()\n",
    "    ax2.plot(train_losses_cnn, label='Train Loss')\n",
    "    ax2.plot(val_losses_cnn, label='Validation (Test) Loss')\n",
    "    ax2.set_title('CNN Model Loss', fontsize=16)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Mean Squared Error')\n",
    "    ax2.legend()\n",
    "    plt.suptitle('Deep Learning Training Curves', fontsize=20)\n",
    "    plt.savefig(\"loss_curves.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align test sets\n",
    "matched_test_df = pd.concat([group.iloc[LOOKBACK-1:] for _, group in test_df_dl.groupby(CAT_COLS) if len(group) >= LOOKBACK])\n",
    "matched_test_ml_df = pd.concat([group.iloc[LOOKBACK-1:] for _, group in test_df.groupby(CAT_COLS) if len(group) >= LOOKBACK])\n",
    "X_test_ml_matched = matched_test_ml_df[ML_FEATS]\n",
    "X_test_dl_matched, y_test_det_matched = create_sequences(matched_test_df, 1, DL_FEATS, TARGET_DET)\n",
    "y_test_det_matched = y_test_det_matched.flatten()\n",
    "trend_test = matched_test_df['yield_trend'].values\n",
    "y_true_original = matched_test_df[TARGET].values\n",
    "\n",
    "# Predictions\n",
    "test_preds = {}\n",
    "for name in models:\n",
    "    if name in ['LR', 'RF', 'XGB']:\n",
    "        test_preds[name] = models[name].predict(X_test_ml_matched)\n",
    "    elif name in ['LSTM', 'CNN']:\n",
    "        X_test_dl_inputs_m = split_dl(X_test_seq)\n",
    "        models[name].eval()\n",
    "        with torch.no_grad():\n",
    "            preds_scaled = models[name](*[x.to(device) for x in X_test_dl_inputs_m]).cpu().numpy()\n",
    "            test_preds[name] = target_scaler.inverse_transform(preds_scaled).flatten()\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "y_preds_original = {}\n",
    "for name, pred_det in test_preds.items():\n",
    "    pred_orig = pred_det + trend_test\n",
    "    y_preds_original[name] = pred_orig\n",
    "    mae = mean_absolute_error(y_true_original, pred_orig)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_original, pred_orig))\n",
    "    map_e = mape(y_true_original, pred_orig)\n",
    "    rms_pe = rmspe(y_true_original, pred_orig)\n",
    "    r_2 = r2_score(y_true_original, pred_orig)\n",
    "    results.append({'Model': name, 'MAE': mae, 'RMSE': rmse, 'MAPE (%)': map_e, 'RMSPE (%)': rms_pe, 'R²': r_2})\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index('Model').sort_values('RMSPE (%)')\n",
    "print(\"\\n--- Final Performance (Test Set) ---\")\n",
    "print(results_df.round(2))\n",
    "results_df.to_csv(\"final_model_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plot Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(24, 6))\n",
    "sns.barplot(data=results_df.reset_index(), x='Model', y='RMSE', ax=axs[0])\n",
    "axs[0].set_title('RMSE Comparison')\n",
    "sns.barplot(x='Model', y='MAE', data=results_df.reset_index(), ax=axs[1])\n",
    "axs[1].set_title('MAE Comparison')\n",
    "sns.barplot(x='Model', y='MAPE (%)', data=results_df.reset_index(), ax=axs[2])\n",
    "axs[2].set_title('MAPE Comparison')\n",
    "sns.barplot(x='Model', y='R²', data=results_df.reset_index(), ax=axs[3])\n",
    "axs[3].set_title('R² Comparison')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"model_performance_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Per-Crop Reporting (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.index[0]\n",
    "print(f\"Per-crop report for best model: {best_model_name}\")\n",
    "crop_results = []\n",
    "items = matched_test_df['Item'].values\n",
    "for crop in np.unique(items):\n",
    "    mask = items == crop\n",
    "    true = y_true_original[mask]\n",
    "    pred = y_preds_original[best_model_name][mask]\n",
    "    crop_results.append({\n",
    "        'Crop': crop,\n",
    "        'RMSPE (%)': rmspe(true, pred),\n",
    "        'MAPE (%)': mape(true, pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(true, pred)),\n",
    "        'R²': r2_score(true, pred)\n",
    "    })\n",
    "crop_df = pd.DataFrame(crop_results).sort_values('RMSPE (%)')\n",
    "print(crop_df.round(2))\n",
    "crop_df.to_csv('per_crop_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. SHAP Analysis (If Tree Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.index[0]\n",
    "if best_model_name in models and best_model_name in ['RF', 'XGB']:\n",
    "    best_model = models[best_model_name]\n",
    "    print(f\"Running SHAP on {best_model_name}\")\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X_test_ml_matched)\n",
    "    shap.summary_plot(shap_values, X_test_ml_matched, plot_type=\"beeswarm\", show=False)\n",
    "    plt.title(f\"SHAP Beeswarm ({best_model_name})\", fontsize=16)\n",
    "    plt.savefig(\"shap_beeswarm.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    shap.summary_plot(shap_values, X_test_ml_matched, plot_type=\"bar\", show=False)\n",
    "    plt.title(f\"Feature Importance ({best_model_name})\", fontsize=16)\n",
    "    plt.savefig(\"shap_importance.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"SHAP skipped for non-tree model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Export Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df = matched_test_df.copy()\n",
    "final_predictions_df['true_yield_original'] = y_true_original\n",
    "for name in test_preds:\n",
    "    final_predictions_df[f'predicted_{name}'] = y_preds_original[name]\n",
    "export_cols = ['Year', 'Area', 'Item', 'true_yield_original'] + [f'predicted_{name}' for name in test_preds]\n",
    "final_predictions_df[export_cols].to_csv(\"final_test_predictions.csv\", index=False)\n",
    "print(\"Exported predictions.\")\n",
    "print(\"\\n--- Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
