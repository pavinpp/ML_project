{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f88844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 209 canonical country names from 'Area' in coordinates_countries_full_209.csv\n",
      "[OK] Saved precipitation long format to temperature_annual_long.csv\n",
      "Rows: 8,987 | Countries: 209 | Years: 1981–2023\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# === CONFIG ===\n",
    "# input directory is now a local folder\n",
    "INPUT_DIR = \"temperature_csv\"\n",
    "\n",
    "# output file in the same folder\n",
    "OUTPUT_LONG = \"temperature_annual_long.csv\"\n",
    "\n",
    "# reference coordinates file in the same folder\n",
    "REF_COUNTRIES_PATH = \"coordinates_countries_full_209.csv\"\n",
    "# ==============\n",
    "\n",
    "def load_canonical_names(path):\n",
    "    \"\"\"\n",
    "    Load canonical country names from your coordinates file.\n",
    "    This file is assumed to have either an 'Area' or 'Country' column\n",
    "    that contains the names you want to standardize to.\n",
    "\n",
    "    Returns:\n",
    "        mapping: dict normalized_name -> canonical_name\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[WARN] Reference countries file not found: {path}\")\n",
    "        return {}\n",
    "\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".csv\":\n",
    "        ref = pd.read_csv(path)\n",
    "    else:\n",
    "        ref = pd.read_excel(path)\n",
    "\n",
    "    # Detect the canonical name column: 'Area' or 'Country'\n",
    "    cols_lower = {c.lower().strip(): c for c in ref.columns}\n",
    "    canon_col = None\n",
    "    for key in (\"area\", \"country\", \"country name\", \"name\"):\n",
    "        if key in cols_lower:\n",
    "            canon_col = cols_lower[key]\n",
    "            break\n",
    "\n",
    "    if canon_col is None:\n",
    "        print(\"[WARN] Could not find a canonical country column (Area/Country) in reference file.\")\n",
    "        print(\"       Columns found:\", list(ref.columns))\n",
    "        return {}\n",
    "\n",
    "    canon_series = ref[canon_col].astype(str)\n",
    "\n",
    "    def norm(s):\n",
    "        return re.sub(r'[^a-z]', '', s.lower())\n",
    "\n",
    "    mapping = {norm(name): name for name in canon_series}\n",
    "    print(f\"[INFO] Loaded {len(mapping)} canonical country names from '{canon_col}' in {path}\")\n",
    "    return mapping\n",
    "\n",
    "CANON_MAP = load_canonical_names(REF_COUNTRIES_PATH)\n",
    "\n",
    "def align_to_canonical(name):\n",
    "    \"\"\"\n",
    "    Replace underscores with spaces, then try to align to canonical mapping\n",
    "    (case/punctuation-insensitive). Fallback to the cleaned name if no match.\n",
    "\n",
    "    Output string will MATCH exactly the name used in the coordinates file.\n",
    "    \"\"\"\n",
    "    cleaned = name.replace('_', ' ').strip()\n",
    "    if not CANON_MAP:\n",
    "        return cleaned\n",
    "\n",
    "    def norm(s):\n",
    "        return re.sub(r'[^a-z]', '', s.lower())\n",
    "\n",
    "    key = norm(cleaned)\n",
    "    return CANON_MAP.get(key, cleaned)\n",
    "\n",
    "def country_from_filename(path):\n",
    "    \"\"\"\n",
    "    Extract the country name from filenames like:\n",
    "      'Viet_Nam_15.0_100.0_1990_2013.csv'\n",
    "      'Albania_41.33_19.82_1990_2013.csv'\n",
    "      'Côte_d'Ivoire_7.54_-5.55_1980_2023.csv'\n",
    "\n",
    "    We grab everything up to the first _<latitude> token (a signed float/int),\n",
    "    then align that name to the canonical version from coordinates_countries_full_209.\n",
    "    \"\"\"\n",
    "    base = os.path.basename(path)\n",
    "    stem = os.path.splitext(base)[0]\n",
    "\n",
    "    # Regex: capture everything until an underscore followed by a number (lat)\n",
    "    m = re.match(r'^(?P<country>.+?)_(?:-?\\d+(?:\\.\\d+)?)_(?:-?\\d+(?:\\.\\d+)?)(?:_.+)?$', stem)\n",
    "    if m:\n",
    "        return align_to_canonical(m.group('country'))\n",
    "    # Fallback: replace underscores with spaces and align\n",
    "    return align_to_canonical(stem)\n",
    "\n",
    "def sniff_delimiter(path, sample_lines=20):\n",
    "    \"\"\"Detect delimiter automatically; default to comma.\"\"\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            sample = \"\".join([next(f) for _ in range(sample_lines)])\n",
    "        dialect = csv.Sniffer().sniff(sample, delimiters=[\",\", \";\", \"\\t\", \"|\"])\n",
    "        return dialect.delimiter\n",
    "    except Exception:\n",
    "        return \",\"\n",
    "\n",
    "def find_header_and_format(text):\n",
    "    \"\"\"\n",
    "    Find the actual tabular header in a POWER CSV blob and return:\n",
    "      (format_type, header_idx, lines)\n",
    "\n",
    "    format_type:\n",
    "        'monthly' if it has YEAR+MO+PRECTOT*\n",
    "        'annual'  if it has YEAR+ANN or YEAR+PRECTOT*\n",
    "    \"\"\"\n",
    "    lines = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").split(\"\\n\")\n",
    "    header_idx = None\n",
    "    fmt = None\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        u = line.upper()\n",
    "        # Try monthly header first\n",
    "        if (\"YEAR\" in u) and ((\"MO\" in u) or (\"MONTH\" in u)) and (\"PRECTOT\" in u):\n",
    "            header_idx = i\n",
    "            fmt = \"monthly\"\n",
    "            break\n",
    "        # Then annual style\n",
    "        if (\"YEAR\" in u) and ((\"ANN\" in u) or (\"PRECTOT\" in u)):\n",
    "            if header_idx is None:  # only take as fallback\n",
    "                header_idx = i\n",
    "                fmt = \"annual\"\n",
    "\n",
    "    if header_idx is None:\n",
    "        raise ValueError(\"Could not locate tabular header containing YEAR + (MO/MONTH or ANN/PRECTOT).\")\n",
    "    return fmt, header_idx, lines\n",
    "\n",
    "def parse_monthly_to_annual(text):\n",
    "    \"\"\"\n",
    "    Parse a POWER CSV (monthly or annual) and return a DataFrame:\n",
    "        Year | ANN\n",
    "    where ANN is the annual total of the precipitation parameter.\n",
    "    \"\"\"\n",
    "    fmt, header_idx, lines = find_header_and_format(text)\n",
    "    data_csv = \"\\n\".join(lines[header_idx:])\n",
    "    df = pd.read_csv(StringIO(data_csv))\n",
    "\n",
    "    # Normalize columns\n",
    "    df.columns = [str(c).strip().upper() for c in df.columns]\n",
    "\n",
    "    if fmt == \"monthly\":\n",
    "        # Find value column\n",
    "        value_col = None\n",
    "        for cand in [\"PRECTOTCORR_SUM\", \"PRECTOTCORR\", \"PRECTOT_SUM\", \"PRECTOT\"]:\n",
    "            if cand in df.columns:\n",
    "                value_col = cand\n",
    "                break\n",
    "        if value_col is None:\n",
    "            raise ValueError(f\"Could not find monthly precipitation column in: {list(df.columns)}\")\n",
    "\n",
    "        year_col = \"YEAR\"\n",
    "        month_col = \"MO\" if \"MO\" in df.columns else (\"MONTH\" if \"MONTH\" in df.columns else None)\n",
    "        if (year_col not in df.columns) or (month_col is None):\n",
    "            raise ValueError(\"Missing YEAR/MO columns in monthly data.\")\n",
    "\n",
    "        sub = df[[year_col, month_col, value_col]].copy()\n",
    "        sub[year_col] = pd.to_numeric(sub[year_col], errors=\"coerce\")\n",
    "        sub[value_col] = pd.to_numeric(sub[value_col], errors=\"coerce\")\n",
    "        sub = sub.dropna(subset=[year_col, value_col])\n",
    "        sub[year_col] = sub[year_col].astype(int)\n",
    "\n",
    "        ann = sub.groupby(year_col, as_index=False)[value_col].sum()\n",
    "        ann = ann.rename(columns={year_col: \"Year\", value_col: \"ANN\"})  # use 'ANN' for consistency\n",
    "        return ann  # Year | ANN\n",
    "\n",
    "    elif fmt == \"annual\":\n",
    "        # Handle annual data directly\n",
    "        value_col = None\n",
    "        if \"ANN\" in df.columns:\n",
    "            value_col = \"ANN\"\n",
    "        else:\n",
    "            for cand in [\"PRECTOTCORR\", \"PRECTOT\"]:\n",
    "                if cand in df.columns:\n",
    "                    value_col = cand\n",
    "                    break\n",
    "        if value_col is None:\n",
    "            raise ValueError(f\"Annual format detected but no ANN/PRECTOT column found in: {list(df.columns)}\")\n",
    "\n",
    "        if \"YEAR\" not in df.columns:\n",
    "            raise ValueError(\"Annual format detected but missing YEAR column.\")\n",
    "\n",
    "        sub = df[[\"YEAR\", value_col]].copy()\n",
    "        sub[\"YEAR\"] = pd.to_numeric(sub[\"YEAR\"], errors=\"coerce\")\n",
    "        sub[value_col] = pd.to_numeric(sub[value_col], errors=\"coerce\")\n",
    "        sub = sub.dropna(subset=[\"YEAR\", value_col])\n",
    "        sub[\"YEAR\"] = sub[\"YEAR\"].astype(int)\n",
    "        sub = sub.rename(columns={\"YEAR\": \"Year\", value_col: \"ANN\"})\n",
    "        return sub\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown format: {fmt}\")\n",
    "\n",
    "def load_year_ann_precip(path):\n",
    "    \"\"\"\n",
    "    Read a precipitation CSV (monthly or annual) and return:\n",
    "        Country | Year | ANN\n",
    "    where Country is aligned to the canonical name from coordinates_countries.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    ann_df = parse_monthly_to_annual(text)\n",
    "    country = country_from_filename(path)   # <- name mapped to coordinates_countries_full_209\n",
    "    ann_df[\"Country\"] = country\n",
    "    return ann_df[[\"Country\", \"Year\", \"ANN\"]]\n",
    "\n",
    "def main():\n",
    "    files = sorted(glob.glob(os.path.join(INPUT_DIR, \"*.csv\")))\n",
    "    if not files:\n",
    "        print(f\"No CSV files found in: {INPUT_DIR}\")\n",
    "        return\n",
    "\n",
    "    parts = []\n",
    "    for fpath in files:\n",
    "        try:\n",
    "            part = load_year_ann_precip(fpath)\n",
    "            if part is not None and not part.empty:\n",
    "                parts.append(part)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {os.path.basename(fpath)} -> {e}\")\n",
    "\n",
    "    if not parts:\n",
    "        print(\"No data combined — please check file formats.\")\n",
    "        return\n",
    "\n",
    "    combined = pd.concat(parts, ignore_index=True)\n",
    "    combined = combined.sort_values([\"Country\", \"Year\"]).reset_index(drop=True)\n",
    "\n",
    "    # Save long format only\n",
    "    combined.to_csv(OUTPUT_LONG, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[OK] Saved precipitation long format to {OUTPUT_LONG}\")\n",
    "    print(f\"Rows: {len(combined):,} | Countries: {combined['Country'].nunique()} | Years: {combined['Year'].min()}–{combined['Year'].max()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
