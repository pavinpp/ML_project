{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction – Final Model Pipeline (Rev9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "from scipy.signal import detrend\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All libraries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Selection Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_MODELS = {\n",
    "    'LR': True,   # Baseline Linear Regression\n",
    "    'RF': True,   # Random Forest\n",
    "    'XGB': True,  # XGBoost\n",
    "    'LSTM': True, # LSTM\n",
    "    'CNN': True   # CNN\n",
    "}\n",
    "\n",
    "RUN_OPTUNA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load & Preprocess Data (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected Data Preprocessing\n",
    "try:\n",
    "    df = pd.read_csv(\"cleaned_crop_data.csv\")\n",
    "    print(f\"Loaded initial data: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"Ensure 'cleaned_crop_data.csv' is present. Run the EDA notebook first.\")\n",
    "\n",
    "TARGET = 'hg/ha_yield'\n",
    "TIME_COL = 'Year'\n",
    "CAT_COLS = ['Area', 'Item']\n",
    "NUMERIC_COLS = ['average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp', 'fertilizer_kg/ha', 'solar_radiation_MJ/m2-day']\n",
    "TARGET_DET = 'yield_detrended'\n",
    "\n",
    "# 1. Split data chronologically\n",
    "TRAIN_END = 2007\n",
    "VAL_END = 2010\n",
    "train_df_orig = df[df[TIME_COL] <= TRAIN_END].copy()\n",
    "val_df_orig = df[(df[TIME_COL] > TRAIN_END) & (df[TIME_COL] <= VAL_END)].copy()\n",
    "test_df_orig = df[df[TIME_COL] > VAL_END].copy()\n",
    "print(f\"1. Initial data split: Train: {train_df_orig.shape}, Val: {val_df_orig.shape}, Test: {test_df_orig.shape}\")\n",
    "\n",
    "# 2. Fit encoders ON TRAINING DATA ONLY\n",
    "le_area = LabelEncoder().fit(train_df_orig['Area'])\n",
    "le_item = LabelEncoder().fit(train_df_orig['Item'])\n",
    "for d in [train_df_orig, val_df_orig, test_df_orig]:\n",
    "    d['Area_Encoded'] = d['Area'].apply(lambda x: le_area.transform([x])[0] if x in le_area.classes_ else -1)\n",
    "    d['Item_Encoded'] = d['Item'].apply(lambda x: le_item.transform([x])[0] if x in le_item.classes_ else -1)\n",
    "print(\"2. Encoders fitted on train set and applied to all sets.\")\n",
    "\n",
    "# 3. Fit trend models ON TRAINING DATA ONLY\n",
    "print(\"3. Fitting trend models on training data...\")\n",
    "trend_models = {}\n",
    "for group, group_df in train_df_orig.groupby(CAT_COLS):\n",
    "    trend_model = LinearRegression()\n",
    "    trend_model.fit(group_df[[TIME_COL]], group_df[TARGET])\n",
    "    trend_models[group] = trend_model\n",
    "\n",
    "global_trend_model = LinearRegression().fit(train_df_orig[[TIME_COL]], train_df_orig[TARGET])\n",
    "print(f\"   Fitted {len(trend_models)} group-specific trend models and 1 global model.\")\n",
    "\n",
    "# 4. Apply detrending to all datasets\n",
    "for df_set in [train_df_orig, val_df_orig, test_df_orig]:\n",
    "    df_set['yield_trend'] = 0.0\n",
    "    for group, group_df in df_set.groupby(CAT_COLS):\n",
    "        model = trend_models.get(group, global_trend_model)\n",
    "        trend_prediction = model.predict(group_df[[TIME_COL]])\n",
    "        df_set.loc[group_df.index, 'yield_trend'] = trend_prediction\n",
    "    df_set['yield_detrended'] = df_set[TARGET] - df_set['yield_trend']\n",
    "print(\"   Detrending applied to all datasets.\")\n",
    "\n",
    "# 5. Create lags and finalize split for ML models\n",
    "full_df_ml = pd.concat([train_df_orig, val_df_orig, test_df_orig]).sort_values(CAT_COLS + [TIME_COL])\n",
    "lag_cols = ['yield_detrended'] + NUMERIC_COLS\n",
    "for col in lag_cols:\n",
    "    for lag in [1, 2]:\n",
    "        full_df_ml[f'{col}_lag{lag}'] = full_df_ml.groupby(CAT_COLS)[col].shift(lag)\n",
    "\n",
    "df_ml = full_df_ml.dropna().copy()\n",
    "train_df = df_ml[df_ml[TIME_COL] <= TRAIN_END].copy()\n",
    "val_df = df_ml[(df_ml[TIME_COL] > TRAIN_END) & (df_ml[TIME_COL] <= VAL_END)].copy()\n",
    "test_df = df_ml[df_ml[TIME_COL] > VAL_END].copy()\n",
    "print(f\"4. Lags created for ML models: Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")\n",
    "\n",
    "# 6. Fit scalers for ML models ON TRAINING DATA ONLY\n",
    "lagged_cols = [c for c in df_ml.columns if '_lag' in c]\n",
    "ml_features = NUMERIC_COLS + lagged_cols + ['Area_Encoded', 'Item_Encoded']\n",
    "scale_cols = NUMERIC_COLS + lagged_cols\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "train_df[scale_cols] = x_scaler.fit_transform(train_df[scale_cols])\n",
    "val_df[scale_cols] = x_scaler.transform(val_df[scale_cols])\n",
    "test_df[scale_cols] = x_scaler.transform(test_df[scale_cols])\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "train_df[TARGET_DET] = y_scaler.fit_transform(train_df[[TARGET_DET]])\n",
    "val_df[TARGET_DET] = y_scaler.transform(val_df[[TARGET_DET]])\n",
    "test_df[TARGET_DET] = y_scaler.transform(test_df[[TARGET_DET]])\n",
    "print(\"5. X and y scalers for ML models fitted and applied.\")\n",
    "\n",
    "# 7. Save transformers\n",
    "joblib.dump(x_scaler, 'scaler.joblib')\n",
    "joblib.dump(y_scaler, 'y_scaler.joblib')\n",
    "joblib.dump(le_area, 'le_area.joblib')\n",
    "joblib.dump(le_item, 'le_item.joblib')\n",
    "joblib.dump(trend_models, 'trend_models.joblib')\n",
    "joblib.dump(global_trend_model, 'global_trend_model.joblib')\n",
    "print(\"6. All transformers saved to disk.\")\n",
    "\n",
    "N_AREAS = len(le_area.classes_)\n",
    "N_ITEMS = len(le_item.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Inputs\n",
    "# These variables are already prepared in Section 3, we just assign them here for clarity\n",
    "X_train_ml = train_df[ml_features]\n",
    "y_train_ml = train_df[TARGET_DET]\n",
    "X_val_ml = val_df[ml_features]\n",
    "y_val_ml = val_df[TARGET_DET]\n",
    "X_test_ml = test_df[ml_features]\n",
    "y_test_ml = test_df[TARGET_DET]\n",
    "print(\"ML inputs prepared.\")\n",
    "\n",
    "# DL Inputs\n",
    "LOOKBACK = 5\n",
    "DL_FEATS = NUMERIC_COLS + ['Area_Encoded', 'Item_Encoded']\n",
    "\n",
    "# We use copies of the 'orig' dataframes from Section 3 for Deep Learning\n",
    "# (These have Encodings and Detrending but NO Scaling yet)\n",
    "train_dl_df = train_df_orig.copy()\n",
    "val_dl_df = val_df_orig.copy()\n",
    "test_dl_df = test_df_orig.copy()\n",
    "\n",
    "# Scale DL features (Fit on Train, Transform Val/Test)\n",
    "scaler_dl_x = StandardScaler()\n",
    "train_dl_df[NUMERIC_COLS] = scaler_dl_x.fit_transform(train_dl_df[NUMERIC_COLS])\n",
    "val_dl_df[NUMERIC_COLS] = scaler_dl_x.transform(val_dl_df[NUMERIC_COLS])\n",
    "test_dl_df[NUMERIC_COLS] = scaler_dl_x.transform(test_dl_df[NUMERIC_COLS])\n",
    "\n",
    "# Scale Target (Use the y_scaler already fitted in Section 3)\n",
    "train_dl_df[TARGET_DET] = y_scaler.transform(train_dl_df[[TARGET_DET]])\n",
    "val_dl_df[TARGET_DET] = y_scaler.transform(val_dl_df[[TARGET_DET]])\n",
    "test_dl_df[TARGET_DET] = y_scaler.transform(test_dl_df[[TARGET_DET]])\n",
    "print(\"DL features and target scaled.\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_sequences(data, lookback, feats, target):\n",
    "    X, y = [], []\n",
    "    y_indices = []\n",
    "    \n",
    "    # Group by categories so we don't mix data between different Areas/Items\n",
    "    for _, group in data.groupby(CAT_COLS):\n",
    "        if len(group) < lookback:\n",
    "            continue\n",
    "            \n",
    "        gf = group[feats].values\n",
    "        gt = group[target].values\n",
    "        indices = group.index\n",
    "        \n",
    "        for i in range(len(group) - lookback + 1):\n",
    "            X.append(gf[i:i+lookback])\n",
    "            y.append(gt[i+lookback-1])\n",
    "            y_indices.append(indices[i+lookback-1])\n",
    "\n",
    "    # Return numpy arrays to avoid \"NoneType\" errors\n",
    "    return np.array(X), np.array(y), np.array(y_indices)\n",
    "\n",
    "# --- CRITICAL FIX: Extend Validation/Test sets ---\n",
    "# The validation set (2008-2010) is too short for LOOKBACK=5 on its own.\n",
    "# We grab the last (LOOKBACK-1) rows from the previous set to provide context.\n",
    "def extend_dataset(prev_df, curr_df, lookback, cat_cols):\n",
    "    # Get the tail of the previous dataset for each group\n",
    "    tails = prev_df.groupby(cat_cols).tail(lookback - 1)\n",
    "    # Combine with current dataset\n",
    "    return pd.concat([tails, curr_df]).sort_values(cat_cols + [TIME_COL])\n",
    "\n",
    "# Create extended datasets for Sequence Generation\n",
    "val_dl_df_ext = extend_dataset(train_dl_df, val_dl_df, LOOKBACK, CAT_COLS)\n",
    "test_dl_df_ext = extend_dataset(val_dl_df, test_dl_df, LOOKBACK, CAT_COLS)\n",
    "\n",
    "# Generate Sequences\n",
    "X_train_seq, y_train_seq, _ = create_sequences(train_dl_df, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "X_val_seq, y_val_seq, _ = create_sequences(val_dl_df_ext, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "X_test_seq, y_test_seq, y_test_indices = create_sequences(test_dl_df_ext, LOOKBACK, DL_FEATS, TARGET_DET)\n",
    "\n",
    "print(f\"Train seq shape: {X_train_seq.shape}\")\n",
    "print(f\"Val seq shape:   {X_val_seq.shape}\")\n",
    "print(\"DL sequences created.\")\n",
    "\n",
    "# Reference DataFrame for Test evaluation (to map predictions back to real values)\n",
    "# We use the indices returned by create_sequences to ensure alignment\n",
    "test_df_dl_seq_ref = test_dl_df_ext.loc[y_test_indices] if len(y_test_indices) > 0 else pd.DataFrame()\n",
    "\n",
    "def split_dl(X):\n",
    "    if len(X) == 0:\n",
    "        # Return empty tensors if no data to prevent crashes\n",
    "        return [torch.empty(0), torch.empty(0), torch.empty(0)]\n",
    "        \n",
    "    numeric_feature_count = len(NUMERIC_COLS)\n",
    "    return [\n",
    "        torch.tensor(X[..., :numeric_feature_count], dtype=torch.float32),\n",
    "        torch.tensor(X[..., numeric_feature_count], dtype=torch.long),\n",
    "        torch.tensor(X[..., numeric_feature_count+1], dtype=torch.long)\n",
    "    ]\n",
    "\n",
    "X_train_dl = split_dl(X_train_seq)\n",
    "X_val_dl = split_dl(X_val_seq)\n",
    "X_test_dl = split_dl(X_test_seq)\n",
    "\n",
    "y_train_t = torch.tensor(y_train_seq, dtype=torch.float32).unsqueeze(1)\n",
    "y_val_t = torch.tensor(y_val_seq, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_t = torch.tensor(y_test_seq, dtype=torch.float32).unsqueeze(1)\n",
    "print(\"DL tensors created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(((y_true - y_pred) / (y_true + 1e-8)) ** 2)) * 100\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optuna Objectives (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# --- CRITICAL FIX 1: DROP TARGET LAGS FROM ML DATA ---\n",
    "cols_to_drop = ['yield_detrended_lag1', 'yield_detrended_lag2']\n",
    "\n",
    "# Safely drop from ML DataFrames if they exist\n",
    "existing_drop_cols = [c for c in cols_to_drop if c in X_train_ml.columns]\n",
    "\n",
    "if existing_drop_cols:\n",
    "    print(f\"DROPPING CAUSAL LEAKAGE FEATURES FROM ML: {existing_drop_cols}\")\n",
    "    X_train_ml = X_train_ml.drop(columns=existing_drop_cols)\n",
    "    X_val_ml = X_val_ml.drop(columns=existing_drop_cols)\n",
    "else:\n",
    "    print(\"Target lags already removed from ML data or not found.\")\n",
    "\n",
    "\n",
    "# --- CRITICAL FIX 2: SLICE EXISTING DL TENSORS ---\n",
    "# We cannot rebuild DL tensors from X_train_ml because of shape/sequence differences.\n",
    "# We must identify which indices in the EXISTING tensors correspond to the dropped columns\n",
    "# and slice them out.\n",
    "\n",
    "# 1. Identify indices to keep based on NUMERIC_COLS\n",
    "keep_indices = [i for i, col in enumerate(NUMERIC_COLS) if col not in cols_to_drop]\n",
    "NUMERIC_COLS_UPDATED = [NUMERIC_COLS[i] for i in keep_indices]\n",
    "\n",
    "print(f\"DL Tensors: Keeping {len(keep_indices)} numeric features out of {len(NUMERIC_COLS)}\")\n",
    "\n",
    "# 2. Slice the existing numeric tensors (Feature dim is always the last dimension)\n",
    "# X_train_dl is a tuple: (numeric_tensor, area_tensor, item_tensor)\n",
    "X_train_num_t_updated = X_train_dl[0][..., keep_indices]\n",
    "X_val_num_t_updated = X_val_dl[0][..., keep_indices]\n",
    "\n",
    "# 3. Re-pack the tuples with the sliced numeric data\n",
    "X_train_dl_updated = (X_train_num_t_updated, X_train_dl[1], X_train_dl[2])\n",
    "X_val_dl_updated = (X_val_num_t_updated, X_val_dl[1], X_val_dl[2])\n",
    "\n",
    "\n",
    "# --- MODEL DEFINITIONS ---\n",
    "\n",
    "def objective_lr(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.1, 10.0, log=True)\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    preds = model.predict(X_val_ml)\n",
    "    return np.sqrt(mean_squared_error(y_val_ml, preds))\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 12),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 5, 20), \n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 10),    \n",
    "        'max_features': trial.suggest_float('max_features', 0.5, 0.9)        \n",
    "    }\n",
    "    model = RandomForestRegressor(random_state=42, n_jobs=-1, **params)\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    preds = model.predict(X_val_ml)\n",
    "    return np.sqrt(mean_squared_error(y_val_ml, preds))\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 8),         \n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 0.9),   \n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 5, 20), \n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 10.0, log=True), \n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 10.0, log=True), \n",
    "        'gamma': trial.suggest_float('gamma', 0, 5), \n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBRegressor(random_state=42, early_stopping_rounds=50, **params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_ml, y_train_ml,\n",
    "        eval_set=[(X_val_ml, y_val_ml)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_val_ml)\n",
    "    return np.sqrt(mean_squared_error(y_val_ml, preds))\n",
    "\n",
    "# --- DEEP LEARNING MODELS ---\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, n_areas, n_items, lstm_units, dense_units, dropout):\n",
    "        super().__init__()\n",
    "        self.embed_area = nn.Embedding(n_areas, 10)\n",
    "        self.embed_item = nn.Embedding(n_items, 5)\n",
    "        # UPDATED: Uses len(NUMERIC_COLS_UPDATED)\n",
    "        self.lstm = nn.LSTM(len(NUMERIC_COLS_UPDATED) + 10 + 5, lstm_units, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(lstm_units, dense_units)\n",
    "        self.fc2 = nn.Linear(dense_units, 1)\n",
    "    def forward(self, num, area, item):\n",
    "        e_area = self.embed_area(area)\n",
    "        e_item = self.embed_item(item)\n",
    "        x = torch.cat([num, e_area, e_item], dim=-1)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.drop(out[:, -1])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        return self.fc2(out)\n",
    "\n",
    "def train_dl(model, opt, loss_fn, train_loader, val_loader, target_scaler, epochs=100, patience=15, is_final=False):\n",
    "    scheduler = ReduceLROnPlateau(opt, 'min', patience=5, factor=0.5)\n",
    "    best_val_rmse = float('inf')\n",
    "    wait = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x1, x2, x3, y in train_loader:\n",
    "            x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            pred = model(x1, x2, x3)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss_sum = 0\n",
    "            for val_x1, val_x2, val_x3, val_y in val_loader:\n",
    "                val_x1, val_x2, val_x3, val_y = val_x1.to(device), val_x2.to(device), val_x3.to(device), val_y.to(device)\n",
    "                val_pred = model(val_x1, val_x2, val_x3)\n",
    "                val_loss_sum += loss_fn(val_pred, val_y).item()\n",
    "            \n",
    "            val_mse = val_loss_sum / len(val_loader)\n",
    "            val_rmse = np.sqrt(val_mse)\n",
    "            val_losses.append(val_mse)\n",
    "\n",
    "        scheduler.step(val_rmse)\n",
    "\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            wait = 0\n",
    "            if is_final:\n",
    "                 torch.save(model.state_dict(), f'model_{model.__class__.__name__}.pth')\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                break\n",
    "    return train_losses, val_losses, best_val_rmse\n",
    "\n",
    "def objective_lstm(trial):\n",
    "    params = {\n",
    "        'lstm_units': trial.suggest_categorical('lstm_units', [32, 64]),\n",
    "        'dense_units': trial.suggest_categorical('dense_units', [16, 32]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.2, 0.5),\n",
    "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True)\n",
    "    }\n",
    "    lr = params.pop('lr')\n",
    "    weight_decay = params.pop('weight_decay')\n",
    "    \n",
    "    model = LSTMModel(N_AREAS, N_ITEMS, **params)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # UPDATED: Use X_train_dl_updated (the sliced tensors)\n",
    "    train_ds = TensorDataset(*X_train_dl_updated, y_train_t)\n",
    "    val_ds = TensorDataset(*X_val_dl_updated, y_val_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64)\n",
    "    \n",
    "    _, _, best_val_rmse = train_dl(model, opt, nn.MSELoss(), train_loader, val_loader, y_scaler, patience=15)\n",
    "    return best_val_rmse\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, n_areas, n_items, filters, kernel, dense_units, dropout): \n",
    "        super().__init__()\n",
    "        self.embed_area = nn.Embedding(n_areas, 10)\n",
    "        self.embed_item = nn.Embedding(n_items, 5)\n",
    "        # UPDATED: Uses len(NUMERIC_COLS_UPDATED)\n",
    "        self.conv = nn.Conv1d(len(NUMERIC_COLS_UPDATED) + 10 + 5, filters, kernel)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(filters, dense_units)\n",
    "        self.fc2 = nn.Linear(dense_units, 1)\n",
    "    def forward(self, num, area, item):\n",
    "        e_area = self.embed_area(area)\n",
    "        e_item = self.embed_item(item)\n",
    "        x = torch.cat([num, e_area, e_item], dim=-1).transpose(1, 2)\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.drop(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def objective_cnn(trial):\n",
    "    params = {\n",
    "        'filters': trial.suggest_categorical('filters', [32, 64]),\n",
    "        'kernel': trial.suggest_categorical('kernel', [2, 3]),\n",
    "        'dense_units': trial.suggest_categorical('dense_units', [16, 32]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.2, 0.5),\n",
    "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True)\n",
    "    }\n",
    "    lr = params.pop('lr')\n",
    "    weight_decay = params.pop('weight_decay')\n",
    "    \n",
    "    model = CNNModel(N_AREAS, N_ITEMS, **params)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # UPDATED: Use X_train_dl_updated\n",
    "    train_ds = TensorDataset(*X_train_dl_updated, y_train_t)\n",
    "    val_ds = TensorDataset(*X_val_dl_updated, y_val_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64)\n",
    "    \n",
    "    _, _, best_val_rmse = train_dl(model, opt, nn.MSELoss(), train_loader, val_loader, y_scaler, patience=15)\n",
    "    return best_val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('best_params_optuna.joblib'):\n",
    "    best_params = joblib.load('best_params_optuna.joblib')\n",
    "else:\n",
    "    best_params = {}\n",
    "\n",
    "if RUN_OPTUNA:\n",
    "    studies = {}\n",
    "    objectives = {\n",
    "        'LR': objective_lr,\n",
    "        'RF': objective_rf,\n",
    "        'XGB': objective_xgb,\n",
    "        'LSTM': objective_lstm,\n",
    "        'CNN': objective_cnn\n",
    "    }\n",
    "    for name, run in RUN_MODELS.items():\n",
    "        if run:\n",
    "            print(f'--- Tuning {name} ---')\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            n_trials = 10 if name in ['RF', 'XGB'] else 6\n",
    "            if name == 'LR':\n",
    "                n_trials = 1\n",
    "            study.optimize(objectives[name], n_trials=n_trials, show_progress_bar=True)\n",
    "            best_params[name] = study.best_params\n",
    "            studies[name] = study\n",
    "            joblib.dump(best_params, 'best_params_optuna.joblib') # Save after each study\n",
    "            print(f'Best params for {name}: {study.best_params}')\n",
    "else:\n",
    "    print('Skipping Optuna tuning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7a. Visualize Optuna Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "\n",
    "if RUN_OPTUNA and 'studies' in locals():\n",
    "    for name, study in studies.items():\n",
    "        if name == 'LR' or not study.trials:\n",
    "            continue\n",
    "        print(f'--- Visualizing Optuna results for {name} ---')\n",
    "        \n",
    "        # Optimization History\n",
    "        fig = plot_optimization_history(study)\n",
    "        fig.update_layout(title=f'{name} Optimization History')\n",
    "        fig.write_image(f'optuna_{name}_history.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Parallel Coordinate\n",
    "        fig = plot_parallel_coordinate(study)\n",
    "        fig.update_layout(title=f'{name} Parallel Coordinate')\n",
    "        fig.write_image(f'optuna_{name}_parallel_coordinate.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Slice Plot\n",
    "        fig = plot_slice(study)\n",
    "        fig.update_layout(title=f'{name} Slice Plot')\n",
    "        fig.write_image(f'optuna_{name}_slice.png')\n",
    "        fig.show()\n",
    "\n",
    "        # Parameter Importance\n",
    "        try:\n",
    "            fig = plot_param_importances(study)\n",
    "            fig.update_layout(title=f'{name} Parameter Importance')\n",
    "            fig.write_image(f'optuna_{name}_param_importance.png')\n",
    "            fig.show()\n",
    "        except (ValueError, RuntimeError) as e:\n",
    "            print(f'Could not plot parameter importance for {name}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Training (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train+val for final ML model training\n",
    "X_train_full_ml = pd.concat([X_train_ml, X_val_ml])\n",
    "y_train_full_ml = pd.concat([y_train_ml, y_val_ml])\n",
    "\n",
    "models = {}\n",
    "print(\"--- Final Model Training ---\")\n",
    "\n",
    "if RUN_MODELS['LR']:\n",
    "    print(\"Training Linear Regression...\")\n",
    "    model_lr = LinearRegression()\n",
    "    model_lr.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['LR'] = model_lr\n",
    "    joblib.dump(model_lr, 'model_lr.joblib')\n",
    "\n",
    "if RUN_MODELS['RF']:\n",
    "    print(\"Training Random Forest...\")\n",
    "    # Use best params from Optuna, or default if not run\n",
    "    rf_params = best_params.get('RF', {'n_estimators': 100, 'max_depth': 10})\n",
    "    model_rf = RandomForestRegressor(random_state=42, n_jobs=-1, **rf_params)\n",
    "    model_rf.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['RF'] = model_rf\n",
    "    joblib.dump(model_rf, 'model_rf.joblib')\n",
    "\n",
    "if RUN_MODELS['XGB']:\n",
    "    print(\"Training XGBoost...\")\n",
    "    xgb_params = best_params.get('XGB', {'n_estimators': 200, 'learning_rate': 0.05})\n",
    "    model_xgb = xgb.XGBRegressor(random_state=42, **xgb_params)\n",
    "    model_xgb.fit(X_train_full_ml, y_train_full_ml)\n",
    "    models['XGB'] = model_xgb\n",
    "    joblib.dump(model_xgb, 'model_xgb.joblib')\n",
    "\n",
    "# Combine train+val for final DL model training\n",
    "X_train_full_seq = np.concatenate([X_train_seq, X_val_seq])\n",
    "y_train_full_seq = np.concatenate([y_train_seq, y_val_seq])\n",
    "X_train_full_dl = split_dl(X_train_full_seq)\n",
    "y_train_full_t = torch.tensor(y_train_full_seq, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_full_ds = TensorDataset(*[x.to(device) for x in X_train_full_dl], y_train_full_t.to(device))\n",
    "test_ds = TensorDataset(*[x.to(device) for x in X_test_dl], y_test_t.to(device))\n",
    "train_loader = DataLoader(train_full_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "if RUN_MODELS['LSTM']:\n",
    "    print(\"Training LSTM...\")\n",
    "    lstm_params = best_params.get('LSTM', {'lstm_units': 64, 'dense_units': 32, 'dropout': 0.2})\n",
    "    lr = lstm_params.pop('lr', 0.001)\n",
    "    weight_decay = lstm_params.pop('weight_decay', 1e-4)\n",
    "    model_lstm = LSTMModel(N_AREAS, N_ITEMS, **lstm_params).to(device)\n",
    "    opt_lstm = optim.Adam(model_lstm.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_losses_lstm, val_losses_lstm, _ = train_dl(model_lstm, opt_lstm, nn.MSELoss(), train_loader, test_loader, y_scaler, epochs=150, patience=15, is_final=True)\n",
    "    models['LSTM'] = model_lstm\n",
    "\n",
    "if RUN_MODELS['CNN']:\n",
    "    print(\"Training CNN...\")\n",
    "    cnn_params = best_params.get('CNN', {'filters': 64, 'kernel': 2, 'dense_units': 32})\n",
    "    lr = cnn_params.pop('lr', 0.001)\n",
    "    weight_decay = cnn_params.pop('weight_decay', 1e-4)\n",
    "    model_cnn = CNNModel(N_AREAS, N_ITEMS, **cnn_params).to(device)\n",
    "    opt_cnn = optim.Adam(model_cnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_losses_cnn, val_losses_cnn, _ = train_dl(model_cnn, opt_cnn, nn.MSELoss(), train_loader, test_loader, y_scaler, epochs=150, patience=15, is_final=True)\n",
    "    models['CNN'] = model_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot DL Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODELS['LSTM'] and RUN_MODELS['CNN']:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))\n",
    "    ax1.plot(train_losses_lstm, label='Train Loss')\n",
    "    ax1.plot(val_losses_lstm, label='Validation (Test) Loss')\n",
    "    ax1.set_title('LSTM Model Loss', fontsize=16)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Mean Squared Error')\n",
    "    ax1.legend()\n",
    "    ax2.plot(train_losses_cnn, label='Train Loss')\n",
    "    ax2.plot(val_losses_cnn, label='Validation (Test) Loss')\n",
    "    ax2.set_title('CNN Model Loss', fontsize=16)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Mean Squared Error')\n",
    "    ax2.legend()\n",
    "    plt.suptitle('Deep Learning Training Curves', fontsize=20)\n",
    "    plt.savefig(\"loss_curves.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation (Corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_yield(y_pred_scaled, df_ref, y_scaler_obj):\n",
    "    \"\"\"Inverse transforms a prediction to the original yield scale.\"\"\"\n",
    "    if y_pred_scaled.ndim == 1:\n",
    "        y_pred_scaled = y_pred_scaled.reshape(-1, 1)\n",
    "    \n",
    "    y_pred_detrended = y_scaler_obj.inverse_transform(y_pred_scaled)\n",
    "    \n",
    "    trend = df_ref['yield_trend'].values.reshape(-1, 1)\n",
    "    y_pred_actual = y_pred_detrended + trend\n",
    "    \n",
    "    return y_pred_actual.flatten()\n",
    "\n",
    "# --- Evaluation ---\n",
    "results = []\n",
    "y_preds_original = {}\n",
    "\n",
    "print(\"\\n--- Final Performance (Test Set) ---\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name in ['LR', 'RF', 'XGB']:\n",
    "        # Predict on the scaled test set\n",
    "        preds_scaled = model.predict(X_test_ml)\n",
    "        # Reconstruct the predictions\n",
    "        pred_orig = reconstruct_yield(preds_scaled, test_df, y_scaler)\n",
    "        y_true_orig = test_df[TARGET].values\n",
    "        # Store for later use\n",
    "        y_preds_original[name] = pred_orig\n",
    "        \n",
    "    elif name in ['LSTM', 'CNN']:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Predict on the scaled test set\n",
    "            preds_scaled_t = model(*[x.to(device) for x in X_test_dl])\n",
    "            preds_scaled = preds_scaled_t.cpu().numpy()\n",
    "            # Reconstruct the predictions\n",
    "            pred_orig = reconstruct_yield(preds_scaled, test_df_dl_seq_ref, y_scaler)\n",
    "            y_true_orig = test_df_dl_seq_ref[TARGET].values\n",
    "            # Store for later use\n",
    "            y_preds_original[name] = pred_orig\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true_orig, pred_orig)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_orig, pred_orig))\n",
    "    map_e = mape(y_true_orig, pred_orig)\n",
    "    rms_pe = rmspe(y_true_orig, pred_orig)\n",
    "    r_2 = r2_score(y_true_orig, pred_orig)\n",
    "    results.append({'Model': name, 'MAE': mae, 'RMSE': rmse, 'MAPE (%)': map_e, 'RMSPE (%)': rms_pe, 'R²': r_2})\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index('Model').sort_values('RMSE')\n",
    "print(results_df.round(2))\n",
    "results_df.to_csv(\"final_model_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10a. Visualize Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Predicted vs Actual Scatter Plots\n",
    "print(\"--- Visualizing Predicted vs. Actual ---\")\n",
    "n_models = len(y_preds_original)\n",
    "n_cols = 3\n",
    "n_rows = (n_models + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, y_pred) in enumerate(y_preds_original.items()):\n",
    "    ax = axes[i]\n",
    "    if name in ['LR', 'RF', 'XGB']:\n",
    "        y_true = test_df[TARGET].values\n",
    "    else:\n",
    "        y_true = test_df_dl_seq_ref[TARGET].values\n",
    "    \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    ax.scatter(y_true, y_pred, alpha=0.5, label=f'Predictions')\n",
    "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2, label='Ideal')\n",
    "    ax.set_xlabel(\"Actual Yield\")\n",
    "    ax.set_ylabel(\"Predicted Yield\")\n",
    "    ax.set_title(f'{name}: Predicted vs Actual (R² = {r2:.3f})')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"predicted_vs_true.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot 2: Time Series Predictions per Crop (Best Model Only)\n",
    "print(\"\\n--- Visualizing Time Series Predictions per Crop (Best Model) ---\")\n",
    "\n",
    "# 1. Identify the Best Model based on RMSE\n",
    "results_df = pd.DataFrame(results).set_index('Model').sort_values('RMSE')\n",
    "best_model_name = results_df.index[0]\n",
    "best_y_pred = y_preds_original[best_model_name]\n",
    "\n",
    "print(f\"Selected Best Model for Plotting: {best_model_name}\")\n",
    "\n",
    "# 2. Prepare the prediction dataframe\n",
    "if best_model_name in ['LR', 'RF', 'XGB', 'SVR', 'Stacking', 'Voting']:\n",
    "    pred_df = test_df.copy()\n",
    "else:\n",
    "    pred_df = test_df_dl_seq_ref.copy()\n",
    "\n",
    "pred_df['prediction'] = best_y_pred\n",
    "\n",
    "unique_crops = df['Item'].unique()\n",
    "\n",
    "for crop in unique_crops:\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    \n",
    "    # --- Actual Data (All Years) ---\n",
    "    # Filter for the crop, then group by Year to get the global average\n",
    "    actual_crop_df = df[df['Item'] == crop]\n",
    "    actual_grouped = actual_crop_df.groupby('Year')[TARGET].mean()\n",
    "    \n",
    "    # Plot single black line for all actual history\n",
    "    plt.plot(actual_grouped.index, actual_grouped.values, 'k-', label='Actual Data', linewidth=2)\n",
    "\n",
    "    # --- Predicted Data ---\n",
    "    # Filter for the crop in the prediction set, then group by Year\n",
    "    crop_pred_df = pred_df[pred_df['Item'] == crop]\n",
    "    \n",
    "    if not crop_pred_df.empty:\n",
    "        pred_grouped = crop_pred_df.groupby('Year')['prediction'].mean()\n",
    "        \n",
    "        # Plot red dotted line for predictions\n",
    "        plt.plot(pred_grouped.index, pred_grouped.values, \n",
    "                 color='red', linestyle=':', marker='o', markersize=4, \n",
    "                 label=f'Predicted ({best_model_name})')\n",
    "\n",
    "    plt.title(f'Average Yield: Actual vs Predicted for {crop}', fontsize=16)\n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.ylabel('Average Yield (hg/ha)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plot Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(24, 6))\n",
    "sns.barplot(data=results_df.reset_index(), x='Model', y='RMSE', ax=axs[0])\n",
    "axs[0].set_title('RMSE Comparison')\n",
    "sns.barplot(x='Model', y='MAE', data=results_df.reset_index(), ax=axs[1])\n",
    "axs[1].set_title('MAE Comparison')\n",
    "sns.barplot(x='Model', y='MAPE (%)', data=results_df.reset_index(), ax=axs[2])\n",
    "axs[2].set_title('MAPE Comparison')\n",
    "sns.barplot(x='Model', y='R²', data=results_df.reset_index(), ax=axs[3])\n",
    "axs[3].set_title('R² Comparison')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"model_performance_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Per-Crop Reporting (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.index[0]\n",
    "print(f\"Per-crop report for best model: {best_model_name}\")\n",
    "crop_results = []\n",
    "# Use the correctly aligned test dataframe based on the best model\n",
    "if best_model_name in ['LR', 'RF', 'XGB']:\n",
    "    reporting_df = test_df\n",
    "    y_true_original = reporting_df[TARGET].values\n",
    "else:\n",
    "    reporting_df = test_df_dl_seq_ref\n",
    "    y_true_original = reporting_df[TARGET].values\n",
    "\n",
    "items = reporting_df['Item'].values\n",
    "\n",
    "for crop in np.unique(items):\n",
    "    mask = items == crop\n",
    "    true = y_true_original[mask]\n",
    "    pred = y_preds_original[best_model_name][mask]\n",
    "    if len(true) > 0:\n",
    "        crop_results.append({\n",
    "            'Crop': crop,\n",
    "            'RMSPE (%)': rmspe(true, pred),\n",
    "            'MAPE (%)': mape(true, pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(true, pred)),\n",
    "            'R²': r2_score(true, pred)\n",
    "        })\n",
    "crop_df = pd.DataFrame(crop_results).sort_values('RMSPE (%)')\n",
    "print(crop_df.round(2))\n",
    "crop_df.to_csv('per_crop_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. SHAP Analysis (If Tree Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.index[0]\n",
    "if best_model_name in models and best_model_name in ['RF', 'XGB']:\n",
    "    best_model = models[best_model_name]\n",
    "    print(f\"Running SHAP on {best_model_name}\")\n",
    "    # For SHAP, we need to use the correctly aligned test features\n",
    "    X_test_shap = X_test_ml\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X_test_shap)\n",
    "    shap.summary_plot(shap_values, X_test_shap, plot_type=\"beeswarm\", show=False)\n",
    "    plt.title(f\"SHAP Beeswarm ({best_model_name})\", fontsize=16)\n",
    "    plt.savefig(\"shap_beeswarm.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    shap.summary_plot(shap_values, X_test_shap, plot_type=\"bar\", show=False)\n",
    "    plt.title(f\"Feature Importance ({best_model_name})\", fontsize=16)\n",
    "    plt.savefig(\"shap_importance.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"SHAP skipped for non-tree model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Export Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base dataframe for predictions. ML models have more test samples than DL models.\n",
    "final_predictions_df = test_df.copy()\n",
    "final_predictions_df['true_yield_original'] = final_predictions_df[TARGET]\n",
    "\n",
    "# Add predictions. Note that DL predictions will have NaNs for non-sequenced rows.\n",
    "for name, preds in y_preds_original.items():\n",
    "    if name in ['LR', 'RF', 'XGB']:\n",
    "        final_predictions_df[f'predicted_{name}'] = preds\n",
    "    else:\n",
    "        # Align DL predictions with the main test dataframe\n",
    "        dl_preds_series = pd.Series(preds, index=test_df_dl_seq_ref.index, name=f'predicted_{name}')\n",
    "        final_predictions_df = final_predictions_df.join(dl_preds_series)\n",
    "\n",
    "export_cols = ['Year', 'Area', 'Item', 'true_yield_original'] + [f'predicted_{name}' for name in models.keys()]\n",
    "final_predictions_df[export_cols].to_csv(\"final_test_predictions.csv\", index=False)\n",
    "print(\"Exported predictions.\")\n",
    "print(\"\\n--- Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in your Jupyter Notebook after defining X_train_ml and y_train_ml\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Train a quick probe model\n",
    "print(\"Training diagnostic model...\")\n",
    "probe_model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "probe_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# 2. Get Feature Importance\n",
    "# Assuming X_train_ml is a DataFrame. If it's a numpy array, we can't get names easily.\n",
    "if isinstance(X_train_ml, pd.DataFrame):\n",
    "    importances = probe_model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    feature_names = X_train_ml.columns\n",
    "\n",
    "    print(\"\\n--- TOP 10 FEATURES DRIVING THE MODEL ---\")\n",
    "    for f in range(10):\n",
    "        if f < len(feature_names):\n",
    "            print(f\"{f+1}. {feature_names[indices[f]]} ({importances[indices[f]]:.4f})\")\n",
    "\n",
    "    # 3. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Feature Importance (Check for Leakage)\")\n",
    "    plt.bar(range(10), importances[indices[:10]], align=\"center\")\n",
    "    plt.xticks(range(10), [feature_names[i] for i in indices[:10]], rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"X_train_ml is a numpy array. Cannot map feature names automatically.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-1 (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
