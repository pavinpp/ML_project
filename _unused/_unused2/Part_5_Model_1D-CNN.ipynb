{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5986cd18",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction: PyTorch 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a747c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Optuna Visualization Tools\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008b386",
   "metadata": {},
   "source": [
    "### 1. Data Preparation and Crop Choice\n",
    "We load the main dataset and identify the available crops. For this analysis, we focus specifically on **Rice**. We clean the data by removing columns related to other crops and deleting any rows where the target yield information is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_parquet('Parquet/XY_v3.parquet')\n",
    "\n",
    "# --- LIST AVAILABLE CROPS ---\n",
    "# Assumes targets start with 'Y_'\n",
    "target_columns = [col for col in df.columns if col.startswith('Y_')]\n",
    "available_crops = [col.replace('Y_', '') for col in target_columns]\n",
    "\n",
    "print(\"--- Available Crops found in Dataset ---\")\n",
    "print(available_crops)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- CONFIGURATION: SET CROP HERE ---\n",
    "CHOSEN_CROP = 'rice'  # <--- CHANGE THIS to 'lettuce', 'pepper', etc. based on list above\n",
    "# ------------------------------------\n",
    "\n",
    "# Define Target and Dynamic Lag Features\n",
    "TARGET_COL = f'Y_{CHOSEN_CROP}'\n",
    "LAG_1_FEATURE = f'avg_yield_{CHOSEN_CROP}_1y'\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target {TARGET_COL} not found in dataset. Check spelling.\")\n",
    "\n",
    "print(f\"Predicting Target: {TARGET_COL}\")\n",
    "print(f\"Using Lag 1 Feature: {LAG_1_FEATURE}\")\n",
    "\n",
    "# Clean Missing Targets for the chosen crop\n",
    "df_model = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "print(f\"Data Loaded. Rows with valid target: {len(df_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce99f69",
   "metadata": {},
   "source": [
    "### 2. Selecting Features, Splitting, and Scaling Data\n",
    "We identify the input variables. We split data by year to avoid data leakage. **Crucially**, for Neural Networks, we must scale the data (StandardScaler) so that all features have a mean of 0 and variance of 1, preventing gradient instability.\n",
    "\n",
    "**1D-CNN Note:** While we are treating tabular data, we will reshape the tensors later to be `[Batch_Size, Channels, Length]`. Here, we treat each feature as a \"time-step\" or sequence element with 1 channel, or more commonly for tabular CNNs, treat the row as `[Batch, 1, Features]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTS (Add these if not already present) ---\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# --- Remove min/max outliers per country ---\n",
    "df_model = df_model.copy()\n",
    "\n",
    "# Find indices for min and max yields\n",
    "idx_min = df_model.groupby('area')[TARGET_COL].idxmin().values\n",
    "idx_max = df_model.groupby('area')[TARGET_COL].idxmax().values\n",
    "\n",
    "# Combine them\n",
    "rows_to_drop = np.concatenate([idx_min, idx_max])\n",
    "\n",
    "# Drop them\n",
    "df_model = df_model.iloc[~df_model.index.isin(rows_to_drop)].reset_index(drop=True)\n",
    "print(f\"Data count after cleaning outliers: {len(df_model)}\")\n",
    "\n",
    "\n",
    "# --- DROP UNWANTED COLUMNS ---\n",
    "# Drop all columns that start with \"avg_yield_\" but do NOT match the chosen crop\n",
    "cols_to_drop = [c for c in df_model.columns \n",
    "                if c.startswith(\"avg_yield_\") and CHOSEN_CROP not in c]\n",
    "\n",
    "df_model = df_model.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- FEATURE SELECTION ---\n",
    "# Select independent variables (exclude 'Y_' columns and metadata)\n",
    "feature_cols = [c for c in df_model.columns \n",
    "                if not c.startswith('Y_') and c not in ['area']]\n",
    "\n",
    "# --- DISPLAY FEATURES TABLE ---\n",
    "print(f\"Total Features Used: {len(feature_cols)}\")\n",
    "print(\"-\" * 30)\n",
    "feature_preview = pd.DataFrame(feature_cols, columns=['Feature Name']).T\n",
    "display(feature_preview)\n",
    "\n",
    "# --- TIME-SERIES SPLIT ---\n",
    "TRAIN_END_YEAR = 2014\n",
    "VAL_END_YEAR = 2019\n",
    "\n",
    "# 1. Training Set (< 2014)\n",
    "mask_train = df_model['year'] < TRAIN_END_YEAR\n",
    "X_train_raw = df_model[mask_train][feature_cols]\n",
    "y_train = df_model[mask_train][TARGET_COL]\n",
    "\n",
    "# 2. Validation Set (>= 2014 and < 2019)\n",
    "mask_val = (df_model['year'] >= TRAIN_END_YEAR) & (df_model['year'] < VAL_END_YEAR)\n",
    "X_val_raw = df_model[mask_val][feature_cols]\n",
    "y_val = df_model[mask_val][TARGET_COL]\n",
    "\n",
    "# 3. Test Set (>= 2019)\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "X_test_raw = df_model[mask_test][feature_cols]\n",
    "y_test = df_model[mask_test][TARGET_COL]\n",
    "\n",
    "# --- IMPUTATION (Handle NaNs before scaling) ---\n",
    "imputer = SimpleImputer(strategy='mean')  # Or 'median' if data is skewed\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train_raw), columns=feature_cols)\n",
    "X_val_imputed = pd.DataFrame(imputer.transform(X_val_raw), columns=feature_cols)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test_raw), columns=feature_cols)\n",
    "\n",
    "# Optional: Print NaN counts to verify (should be 0 after imputation)\n",
    "print(\"NaNs in X_train_imputed:\", X_train_imputed.isnull().sum().sum())\n",
    "print(\"NaNs in X_val_imputed:\", X_val_imputed.isnull().sum().sum())\n",
    "print(\"NaNs in X_test_imputed:\", X_test_imputed.isnull().sum().sum())\n",
    "\n",
    "# --- SCALING (Required for Neural Networks) ---\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_imputed)\n",
    "X_val = scaler.transform(X_val_imputed)\n",
    "X_test = scaler.transform(X_test_imputed)\n",
    "\n",
    "# --- RESHAPE FOR 1D CNN ---\n",
    "# PyTorch Conv1d expects input shape: (Batch Size, Channels, Sequence Length)\n",
    "# For tabular data, we usually treat 'Channels' as 1 and 'Sequence Length' as number of features.\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val_cnn = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train_cnn, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_cnn, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_cnn, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"\\nTraining Samples   (<{TRAIN_END_YEAR})     : {len(X_train)}\")\n",
    "print(f\"Validation Samples ({TRAIN_END_YEAR}-{VAL_END_YEAR - 1}): {len(X_val)}\")\n",
    "print(f\"Testing Samples    (>={VAL_END_YEAR})    : {len(X_test)}\")\n",
    "print(f\"CNN Input Shape (Batch, Channels, Features): {X_train_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607fbb7",
   "metadata": {},
   "source": [
    "### 4. Initial Model Testing\n",
    "We train a basic **1D-CNN** model using standard settings. We plot the training vs validation loss to check for overfitting or underfitting. The architecture involves a convolutional layer, pooling, flattening, and dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774242a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEFINE 1D-CNN STRUCTURE ---\n",
    "class SimpleCNN1D(nn.Module):\n",
    "    def __init__(self, input_len):\n",
    "        super(SimpleCNN1D, self).__init__()\n",
    "        # Conv1d: in_channels=1 (tabular row), out_channels=32 filters\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Calculate size after pooling for the linear layer\n",
    "        conv_out_size = input_len // 2 * 32\n",
    "        \n",
    "        self.fc1 = nn.Linear(conv_out_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, 1, features]\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# --- TRAINING HELPER FUNCTION ---\n",
    "def train_model_init(model_init, X_t, y_t, X_v, y_v, lr=0.001, epochs=150, batch_size=32, verbose=True):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model_init.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_t, y_t), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    train_losses_init = []\n",
    "    val_losses_init = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model_init.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_init(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * batch_X.size(0)\n",
    "            \n",
    "        train_mse = epoch_loss / len(X_t)\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        \n",
    "        model_init.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model_init(X_v)\n",
    "            val_loss = criterion(val_outputs, y_v)\n",
    "            val_rmse = np.sqrt(val_loss.item())\n",
    "            \n",
    "        train_losses_init.append(train_rmse)\n",
    "        val_losses_init.append(val_rmse)\n",
    "        \n",
    "        if verbose and (epoch % 20 == 0 or epoch == epochs-1):\n",
    "            print(f\"Epoch {epoch}/{epochs} | Train RMSE: {train_rmse:.2f} | Val RMSE: {val_rmse:.2f}\")\n",
    "            \n",
    "    return train_losses_init, val_losses_init\n",
    "\n",
    "# --- INITIAL MODEL TRAINING ---\n",
    "input_features_init = X_train_tensor.shape[2]  # Sequence length / num features\n",
    "model_init = SimpleCNN1D(input_features_init).to(device)\n",
    "\n",
    "train_hist_init, val_hist_init = train_model_init(\n",
    "    model_init, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor\n",
    ")\n",
    "\n",
    "# --- PLOT LEARNING CURVE ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_hist_init, label='Training RMSE', color='blue')\n",
    "plt.plot(val_hist_init, label='Validation RMSE', color='red')\n",
    "plt.title(f'1D-CNN Learning Curve ({CHOSEN_CROP})', fontsize=15)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# --- Predict on Train, Validation, and Test sets ---\n",
    "model_init.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train_init = model_init(X_train_tensor).cpu().numpy().flatten()\n",
    "    y_pred_val_init = model_init(X_val_tensor).cpu().numpy().flatten()\n",
    "    y_pred_test_init = model_init(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# --- Compute Metrics ---\n",
    "rmse_train_init = np.sqrt(mean_squared_error(y_train, y_pred_train_init))\n",
    "rmse_val_init = np.sqrt(mean_squared_error(y_val, y_pred_val_init))\n",
    "rmse_test_init = np.sqrt(mean_squared_error(y_test, y_pred_test_init))\n",
    "\n",
    "r2_train_init = r2_score(y_train, y_pred_train_init)\n",
    "r2_val_init = r2_score(y_val, y_pred_val_init)\n",
    "r2_test_init = r2_score(y_test, y_pred_test_init)\n",
    "\n",
    "# --- Prepare Summary Table ---\n",
    "metrics_df_init = pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'R²'],\n",
    "    'Train': [rmse_train_init, r2_train_init],\n",
    "    'Validation': [rmse_val_init, r2_val_init],\n",
    "    'Test 0': [rmse_test_init, r2_test_init]\n",
    "})\n",
    "\n",
    "# --- Display Table ---\n",
    "print(metrics_df_init.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d9630",
   "metadata": {},
   "source": [
    "### 5. Tuning the Model (Optuna)\n",
    "To improve performance, we use **Optuna** to find the best CNN architecture. We run trials adjusting the number of filters, kernel sizes, dropout rate, learning rate, and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DYNAMIC 1D-CNN BUILDER ---\n",
    "class DynamicCNN1D(nn.Module):\n",
    "    def __init__(self, input_len, n_filters, kernel_size, dropout, activation_name):\n",
    "        super(DynamicCNN1D, self).__init__()\n",
    "        \n",
    "        # Choose Activation Function\n",
    "        if activation_name == \"ReLU\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation_name == \"LeakyReLU\":\n",
    "            self.activation = nn.LeakyReLU()\n",
    "        else:\n",
    "            self.activation = nn.Tanh()\n",
    "\n",
    "        # Convolutional Block\n",
    "        # padding = kernel_size // 2 maintains roughly same size before pooling\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=n_filters, \n",
    "                               kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "        # Calculate Flatten Size\n",
    "        # Output length after MaxPool1d(2) is floor(input_len / 2)\n",
    "        # We must handle cases where input_len < 2 properly, though tabular usually > 20\n",
    "        feature_map_len = input_len // 2\n",
    "        flat_dim = feature_map_len * n_filters\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(flat_dim, n_filters)\n",
    "        self.fc2 = nn.Linear(n_filters, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.dropout_layer(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# --- OPTUNA OBJECTIVE FUNCTION ---\n",
    "def objective(trial):\n",
    "    # 1. Suggest Hyperparameters\n",
    "    n_filters = trial.suggest_int(\"n_filters\", 16, 128, step=16)\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5, 7])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64])  # Larger batches stable\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"ReLU\", \"LeakyReLU\"])  # Drop Tanh\n",
    "    optimizer_name = \"Adam\"  # Fixed to Adam; comment out if testing SGD\n",
    "\n",
    "    # 2. Build Model\n",
    "    # input_features taken from X_train_tensor.shape[2]\n",
    "    model = DynamicCNN1D(input_features, n_filters, kernel_size, dropout, activation).to(device)\n",
    "    \n",
    "    # 3. Setup Training\n",
    "    criterion = nn.MSELoss()\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "        \n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), \n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 4. Training Loop with Pruning\n",
    "    epochs = 50  # Reduced slightly for speed during tuning\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate on Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_tensor)\n",
    "            val_mse = criterion(val_pred, y_val_tensor).item()\n",
    "            val_rmse = np.sqrt(val_mse)\n",
    "\n",
    "        # Pruning check\n",
    "        trial.report(val_rmse, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_rmse\n",
    "\n",
    "# --- RUN OPTIMIZATION ---\n",
    "study_name = f'{CHOSEN_CROP.capitalize()}_Yield_CNN'\n",
    "study = optuna.create_study(direction='minimize', study_name=study_name)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"\\nBest Parameters found:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a3401",
   "metadata": {},
   "source": [
    "### 6. Visualizing Optimization\n",
    "We generate charts to understand the tuning process. These visual tools show us which specific settings (like kernel size or number of filters) had the biggest impact on reducing the model's error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d396ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OPTUNA VISUALIZATIONS ---\n",
    "name = f\"{CHOSEN_CROP.capitalize()}_Yield_CNN\"\n",
    "\n",
    "# 1. Optimization History\n",
    "fig = plot_optimization_history(study)\n",
    "fig.update_layout(title=f'{name} Optimization History', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "# 2. Parallel Coordinate (Hyperparameter Relationships)\n",
    "fig = plot_parallel_coordinate(study)\n",
    "fig.update_layout(title=f'{name} Parallel Coordinate Plot', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "# 3. Slice Plot (Individual Parameter impact)\n",
    "fig = plot_slice(study)\n",
    "fig.update_layout(title=f'{name} Slice Plot', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "# 4. Parameter Importance\n",
    "try:\n",
    "    fig = plot_param_importances(study)\n",
    "    fig.update_layout(title=f'{name} Hyperparameter Importance', width=900, height=500)\n",
    "    fig.show()\n",
    "except (ValueError, RuntimeError) as e:\n",
    "    print(f'Could not plot parameter importance: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99bf3cf",
   "metadata": {},
   "source": [
    "### 7. Final Model Training\n",
    "Using the best settings found during the tuning phase, we build the final 1D-CNN. We train this model on both the Training and Validation data combined to maximize learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Combine Train + Validation for Final Training\n",
    "# Combine raw arrays and reshape for CNN [Total Samples, 1, Features]\n",
    "X_train_full = np.vstack((X_train, X_val))\n",
    "X_train_full_cnn = X_train_full.reshape(X_train_full.shape[0], 1, X_train_full.shape[1])\n",
    "y_train_full = np.concatenate((y_train, y_val))\n",
    "\n",
    "# Convert full set to tensor\n",
    "X_train_full_tensor = torch.tensor(X_train_full_cnn, dtype=torch.float32).to(device)\n",
    "y_train_full_tensor = torch.tensor(y_train_full, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# 2. Retrieve Best Params\n",
    "bp = study.best_params\n",
    "\n",
    "# 3. Initialize Best Model\n",
    "final_model = DynamicCNN1D(\n",
    "    input_features,\n",
    "    bp['n_filters'], \n",
    "    bp['kernel_size'], \n",
    "    bp['dropout'], \n",
    "    bp['activation']\n",
    ").to(device)\n",
    "\n",
    "# 4. Train on Full History\n",
    "# We train for more epochs since we are using more data\n",
    "#optimizer_name = bp['optimizer']\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=bp['lr'])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "train_loader = DataLoader(TensorDataset(X_train_full_tensor, y_train_full_tensor), \n",
    "                          batch_size=bp['batch_size'], shuffle=True)\n",
    "\n",
    "print(\"Training Final Model...\")\n",
    "final_model.train()\n",
    "for epoch in range(150):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 5. Final Prediction & Evaluation\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    # --- Prepare Original Splits for Evaluation ---\n",
    "    # Reshape original train/val to match CNN input [Samples, 1, Features]\n",
    "    X_train_cnn = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_val_cnn   = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "    # Convert to Tensors\n",
    "    X_train_tensor_eval = torch.tensor(X_train_cnn, dtype=torch.float32).to(device)\n",
    "    X_val_tensor_eval   = torch.tensor(X_val_cnn, dtype=torch.float32).to(device)\n",
    "\n",
    "    # --- Generate Predictions ---\n",
    "    y_pred_train_final = final_model(X_train_tensor_eval).cpu().numpy().flatten()\n",
    "    y_pred_val_final   = final_model(X_val_tensor_eval).cpu().numpy().flatten()\n",
    "    y_pred_test_final  = final_model(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# --- Calculate Metrics for All Sets ---\n",
    "# Train\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train_final))\n",
    "r2_train = r2_score(y_train, y_pred_train_final)\n",
    "\n",
    "# Validation\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val_final))\n",
    "r2_val = r2_score(y_val, y_pred_val_final)\n",
    "\n",
    "# Test\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test_final))\n",
    "r2_test = r2_score(y_test, y_pred_test_final)\n",
    "\n",
    "# --- Create Performance Matrix ---\n",
    "metrics_data = {\n",
    "    'Metric': ['RMSE', 'R2'],\n",
    "    'Train': [rmse_train, r2_train],\n",
    "    'Validation': [rmse_val, r2_val],\n",
    "    'Test': [rmse_test, r2_test]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "\n",
    "print(\"\\n--- Final Tuned Model Metrics ---\")\n",
    "print(df_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1bd7",
   "metadata": {},
   "source": [
    "### 8. Results and Analysis\n",
    "We evaluate the final performance on the Test data (2019–2023).\n",
    "* **Comparison:** We check if the Tuned 1D-CNN beats the Baseline and the Initial Model.\n",
    "* **Trend Analysis:** We plot the predicted yields against actual yields over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Improvement % (Comparing Tuned vs Initial)\n",
    "imp_final = (rmse_init_test - rmse_test) / rmse_init_test * 100\n",
    "\n",
    "print(\"--- Final Performance Report (Test Set) ---\")\n",
    "print(f\"Initial Model:  RMSE={rmse_init_test:.2f}, R2={r2_init_test:.4f}\")\n",
    "print(f\"Tuned CNN Model: RMSE={rmse_test:.2f}, R2={r2_test:.4f} (RMSE Improved {imp_final:.2f}%)\")\n",
    "\n",
    "# --- PLOTTING RESULTS ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Axis Limits\n",
    "all_preds = np.concatenate([y_pred_init_test, y_pred_test_final])\n",
    "all_true = np.concatenate([y_test, y_test])\n",
    "min_val, max_val = min(min(all_preds), min(all_true)), max(max(all_preds), max(all_true))\n",
    "\n",
    "# 1. Initial Model Plot\n",
    "axes[0].scatter(y_test, y_pred_init_test, alpha=0.4, color='orange')\n",
    "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[0].set_title(f'Initial CNN Model\\nRMSE: {rmse_init_test:.2f} | R2: {r2_init_test:.3f}')\n",
    "axes[0].set_xlabel('Actual Values')\n",
    "axes[0].set_ylabel('Predicted Values')\n",
    "\n",
    "# 2. Tuned Model Plot\n",
    "axes[1].scatter(y_test, y_pred_test_final, alpha=0.4, color='green')\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[1].set_title(f'Tuned CNN Model\\nRMSE: {rmse_test:.2f} | R2: {r2_test:.3f}')\n",
    "axes[1].set_xlabel('Actual Values')\n",
    "\n",
    "plt.suptitle(f'{CHOSEN_CROP.capitalize()} Yield: Performance Comparison (Actual vs Predicted)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fcb6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FULL TIMELINE PLOT (THAILAND ONLY) ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Generate Predictions for all data\n",
    "# Using the scaler and model already fit/loaded\n",
    "X_all_scaled = scaler.transform(df_model[feature_cols])\n",
    "# Reshape for CNN [Samples, 1, Features]\n",
    "X_all_cnn = X_all_scaled.reshape(X_all_scaled.shape[0], 1, X_all_scaled.shape[1])\n",
    "X_all_tensor = torch.tensor(X_all_cnn, dtype=torch.float32).to(device)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    all_predictions = final_model(X_all_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# 2. Create DataFrame with 'Area' included\n",
    "df_full_trend = pd.DataFrame({\n",
    "    'Year': df_model['year'],\n",
    "    'Area': df_model['area'], # Added Area column for filtering\n",
    "    'Actual': df_model[TARGET_COL],\n",
    "    'Predicted': all_predictions\n",
    "})\n",
    "\n",
    "# 3. Filter for Thailand Only\n",
    "TARGET_COUNTRY = 'Thailand'\n",
    "country_trend = df_full_trend[df_full_trend['Area'] == TARGET_COUNTRY].sort_values('Year')\n",
    "\n",
    "# Check if data exists for the country\n",
    "if country_trend.empty:\n",
    "    print(f\"No data found for {TARGET_COUNTRY}. Please check the spelling or choose another country.\")\n",
    "else:\n",
    "    # 4. Plotting\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Plot Lines for specific country\n",
    "    plt.plot(country_trend['Year'], country_trend['Actual'], \n",
    "             marker='o', label=f'Actual Yield ({TARGET_COUNTRY})', linewidth=2, color='blue')\n",
    "    plt.plot(country_trend['Year'], country_trend['Predicted'], \n",
    "             marker='x', linestyle='--', label=f'Predicted Yield ({TARGET_COUNTRY})', linewidth=2, color='orange')\n",
    "\n",
    "    # Define Split Boundaries based on the global config\n",
    "    MIN_YEAR = country_trend['Year'].min()\n",
    "    MAX_YEAR = country_trend['Year'].max()\n",
    "    train_boundary = TRAIN_END_YEAR - 0.5\n",
    "    val_boundary = VAL_END_YEAR - 0.5\n",
    "\n",
    "    # --- Highlight Periods ---\\\n",
    "    # We use a try/except or safe bounds in case the country doesn't have data in all periods\n",
    "    try:\n",
    "        plt.axvspan(MIN_YEAR - 0.5, train_boundary, color='green', alpha=0.1, label=f'Train (<{TRAIN_END_YEAR})')\n",
    "        plt.axvspan(train_boundary, val_boundary, color='yellow', alpha=0.1, label=f'Validation ({TRAIN_END_YEAR}-{VAL_END_YEAR - 1})')\n",
    "        plt.axvspan(val_boundary, MAX_YEAR + 0.5, color='red', alpha=0.1, label=f'Test (>={VAL_END_YEAR})')\n",
    "        \n",
    "        # Add Text Labels\n",
    "        y_max = country_trend['Actual'].max()\n",
    "        text_y = y_max * 1.05 \n",
    "\n",
    "        plt.text((MIN_YEAR + train_boundary)/2, text_y, 'TRAINING', ha='center', fontsize=12, fontweight='bold', color='green')\n",
    "        plt.text((train_boundary + val_boundary)/2, text_y, 'VALIDATION', ha='center', fontsize=12, fontweight='bold', color='#D4AC0D')\n",
    "        plt.text((val_boundary + MAX_YEAR)/2, text_y, 'TESTING', ha='center', fontsize=12, fontweight='bold', color='red')\n",
    "    except:\n",
    "        pass # Skip highlighting if year ranges don't align perfectly with this specific country's data\n",
    "\n",
    "    # Final Formatting\n",
    "    plt.title(f'Full Timeline Analysis: Actual vs. Predicted Yield ({CHOSEN_CROP}) - {TARGET_COUNTRY}', fontsize=16)\n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.ylabel('Yield (hg/ha)', fontsize=12)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ensure integer ticks for years\n",
    "    plt.xticks(np.arange(int(MIN_YEAR), int(MAX_YEAR) + 1, 2))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02369b59",
   "metadata": {},
   "source": [
    "* **Geographic Error:** We map the error rates by country to see where the model performs best and where it struggles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RE-CREATE COMPARISON DF WITH FEATURE JOINED ---\n",
    "# We need the original 'area' column from the test set for joining\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "test_set_context = df_model[mask_test][['area', 'year']] \n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Value': y_test,\n",
    "    'Predicted_Value': y_pred_final_test\n",
    "})\n",
    "\n",
    "# Join works automatically because y_test retained index from original df_model\n",
    "comparison_df = comparison_df.join(test_set_context)\n",
    "comparison_df = comparison_df[['year', 'area', 'Actual_Value', 'Predicted_Value']]\n",
    "\n",
    "print(\"--- Actual vs. Predicted Test Set Results ---\")\n",
    "print(comparison_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Name Cleaning for Map Plotting\n",
    "comparison_df['area'] = comparison_df['area'].replace({\n",
    "    'United_States_of_America': 'United States',\n",
    "    'United_Kingdom_of_Great_Britain_and_Northern_Ireland': 'United Kingdom',\n",
    "    'Russian_Federation': 'Russia',\n",
    "    'Viet_Nam': 'Vietnam',\n",
    "    'Türkiye': 'Turkey',\n",
    "    'Bolivia_(Plurinational_State_of)': 'Bolivia',\n",
    "    'Iran_(Islamic_Republic_of)': 'Iran',\n",
    "    \"Lao_People's_Democratic_Republic\": 'Laos',\n",
    "    'China,_mainland': 'China',\n",
    "    'China,_Taiwan_Province_of': 'Taiwan',\n",
    "    \"Democratic_People's_Republic_of_Korea\": 'North Korea',\n",
    "    'Republic_of_Korea': 'South Korea',\n",
    "    'Côte_d\\'Ivoire': \"Cote d'Ivoire\",\n",
    "    'United_Republic_of_Tanzania': 'Tanzania',\n",
    "    'Micronesia_(Federated_States_of)': 'Micronesia',\n",
    "    'Venezuela_(Bolivarian_Republic_of)': 'Venezuela'\n",
    "})\n",
    "\n",
    "def plot_geographic_error(comparison_df):\n",
    "    # Squared Error (for RMSE)\n",
    "    comparison_df['Squared_Error'] = (comparison_df['Actual_Value'] - comparison_df['Predicted_Value']) ** 2\n",
    "    # Squared Percentage Error (for RMSPE)\n",
    "    epsilon = 1e-6 \n",
    "    comparison_df['Squared_Percentage_Error'] = (\n",
    "        (comparison_df['Actual_Value'] - comparison_df['Predicted_Value']) / \n",
    "        (comparison_df['Actual_Value'] + epsilon)\n",
    "    ) ** 2\n",
    "\n",
    "    # Aggregate Errors by Country\n",
    "    rmse_df = (\n",
    "        comparison_df.groupby('area')['Squared_Error']\n",
    "        .mean().apply(np.sqrt).reset_index()\n",
    "        .rename(columns={'area': 'Country', 'Squared_Error': 'RMSE'})\n",
    "    )\n",
    "    rmspe_df = (\n",
    "        comparison_df.groupby('area')['Squared_Percentage_Error']\n",
    "        .mean().apply(np.sqrt).multiply(100).reset_index()\n",
    "        .rename(columns={'area': 'Country', 'Squared_Percentage_Error': 'RMSPE'})\n",
    "    )\n",
    "    ap_df = comparison_df.groupby('area')[['Actual_Value', 'Predicted_Value']].mean().reset_index()\n",
    "    ap_df = ap_df.rename(columns={'area': 'Country'})\n",
    "\n",
    "    # Merge stats\n",
    "    error_stats = rmspe_df.merge(rmse_df, on='Country', how='left')\n",
    "    error_stats = error_stats.merge(ap_df, on='Country', how='left') \n",
    "\n",
    "    # Plot\n",
    "    fig = px.choropleth(\n",
    "        error_stats,\n",
    "        locations='Country',\n",
    "        color='RMSPE',\n",
    "        locationmode='country names',\n",
    "        color_continuous_scale=['green', 'red'], \n",
    "        range_color=[0, 50], \n",
    "        title='Geographic Distribution of Prediction Error (RMSPE) - 1D CNN',\n",
    "        labels={'RMSPE': 'RMSPE (%)'},\n",
    "        hover_name='Country',\n",
    "        hover_data={'RMSPE': ':.2f', 'RMSE': ':.2f', 'Actual_Value': ':.2f', 'Predicted_Value': ':.2f'},\n",
    "        projection='natural earth'\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title_font_size=18,\n",
    "        coloraxis_colorbar=dict(title='RMSPE (%)', orientation='h', len=0.5, yanchor='bottom', y=-0.12),\n",
    "        geo=dict(showframe=False, showcoastlines=True, showcountries=True, countrycolor='black', bgcolor='lightgrey')\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "plot_geographic_error(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fc4f6",
   "metadata": {},
   "source": [
    "### 9. Key Factors (Feature Importance)\n",
    "1D-CNNs, like basic Neural Networks, don't have built-in feature importance. We calculate **Permutation Importance** by shuffling each feature column one at a time and measuring the error increase. Since the CNN requires 3D input, we create a wrapper to handle the reshaping automatically during the permutation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e313a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WRAPPER FOR SKLEARN COMPATIBILITY (Reshaping logic added) ---\n",
    "class PyTorchEstimator:\n",
    "    \"\"\"Wrapper to make PyTorch model behave like a Sklearn estimator for permutation_importance\"\"\"\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass # Model is already trained\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Reshape X from [Batch, Features] to [Batch, 1, Features] for CNN\n",
    "            X_reshaped = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "            X_tensor = torch.tensor(X_reshaped, dtype=torch.float32).to(self.device)\n",
    "            preds = self.model(X_tensor).cpu().numpy().flatten()\n",
    "        return preds\n",
    "\n",
    "# --- CALCULATE PERMUTATION IMPORTANCE ---\n",
    "# Using validation set to gauge importance generalization\n",
    "wrapped_model = PyTorchEstimator(final_model, device)\n",
    "# X_val is the 2D array, the wrapper handles reshaping to 3D\n",
    "results = permutation_importance(wrapped_model, X_val, y_val, scoring='neg_root_mean_squared_error', n_repeats=5, random_state=42)\n",
    "\n",
    "# --- PROCESS RESULTS ---\n",
    "importance_means = np.abs(results.importances_mean)\n",
    "feature_names = np.array(feature_cols)\n",
    "\n",
    "# Create DataFrame\n",
    "fi_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance_means\n",
    "}).sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print Top 20\n",
    "print(\"\\n--- Top 20 Most Important Features (Permutation Importance) ---\")\n",
    "print(fi_df.head(20))\n",
    "\n",
    "# --- PLOT ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=fi_df.head(20), palette='viridis')\n",
    "plt.title(f'Feature Importance (Permutation) - {CHOSEN_CROP.capitalize()} 1D-CNN Model', fontsize=15)\n",
    "plt.xlabel('Increase in RMSE when shuffled')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
