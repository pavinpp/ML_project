{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5986cd18",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction: PyTorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a747c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Tools for visualizing Optuna results\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "# Making the plots look a bit nicer\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Check if I have a GPU available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Cool, running on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008b386",
   "metadata": {},
   "source": [
    "### 1. Loading Data & Picking the Target\n",
    "Loading the dataset and picking which crop to predict. I'll stick with **Rice** for now, but it's easy to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_parquet('Parquet/XY_v3.parquet')\n",
    "\n",
    "# --- CHECKING OPTIONS ---\n",
    "target_columns = [col for col in df.columns if col.startswith('Y_')]\n",
    "available_crops = [col.replace('Y_', '') for col in target_columns]\n",
    "\n",
    "print(\"Here are the available crops:\")\n",
    "print(available_crops)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- CHOOSE CROP HERE ---\n",
    "CHOSEN_CROP = 'rice'  # <--- Change this to 'lettuce', 'maize', etc. to test others\n",
    "# ---------------------------\n",
    "\n",
    "TARGET_COL = f'Y_{CHOSEN_CROP}'\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Can't find {TARGET_COL}. Check the spelling?\")\n",
    "\n",
    "print(f\"Locked in target: {TARGET_COL}\")\n",
    "\n",
    "# Drop rows where the target is missing\n",
    "df_model = df.dropna(subset=[TARGET_COL])\n",
    "print(f\"Valid data points found: {len(df_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce99f69",
   "metadata": {},
   "source": [
    "### 2. Cleaning & Prep\n",
    "I'm removing the absolute min and max yield rows for each country—just to get rid of extreme outliers that might confuse the training.\n",
    "\n",
    "Then, I'm splitting the data by time (Train < 2014, Val 2014-2018, Test >= 2019) and scaling the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# --- Remove min/max outliers per country ---\n",
    "df_model = df_model.copy()\n",
    "\n",
    "# Find indices for min and max yields\n",
    "idx_min = df_model.groupby('area')[TARGET_COL].idxmin().values\n",
    "idx_max = df_model.groupby('area')[TARGET_COL].idxmax().values\n",
    "\n",
    "# Combine them\n",
    "rows_to_drop = np.concatenate([idx_min, idx_max])\n",
    "\n",
    "# Drop them\n",
    "df_model = df_model.iloc[~df_model.index.isin(rows_to_drop)].reset_index(drop=True)\n",
    "print(f\"Data count after cleaning outliers: {len(df_model)}\")\n",
    "\n",
    "# --- DROP IRRELEVANT COLUMNS ---\n",
    "cols_to_drop = [c for c in df_model.columns \n",
    "                if c.startswith(\"avg_yield_\") and CHOSEN_CROP not in c]\n",
    "df_model = df_model.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- SETUP FEATURES ---\n",
    "feature_cols = [c for c in df_model.columns \n",
    "                if not c.startswith('Y_') and c not in ['area']]\n",
    "\n",
    "print(f\"Total input features: {len(feature_cols)}\")\n",
    "\n",
    "# --- TIME-BASED SPLIT ---\n",
    "TRAIN_END_YEAR = 2014\n",
    "VAL_END_YEAR = 2019\n",
    "\n",
    "# 1. Train (< 2014)\n",
    "mask_train = df_model['year'] < TRAIN_END_YEAR\n",
    "X_train_raw = df_model[mask_train][feature_cols]\n",
    "y_train = df_model[mask_train][TARGET_COL]\n",
    "\n",
    "# 2. Validation (2014 - 2018)\n",
    "mask_val = (df_model['year'] >= TRAIN_END_YEAR) & (df_model['year'] < VAL_END_YEAR)\n",
    "X_val_raw = df_model[mask_val][feature_cols]\n",
    "y_val = df_model[mask_val][TARGET_COL]\n",
    "\n",
    "# 3. Test (>= 2019)\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "X_test_raw = df_model[mask_test][feature_cols]\n",
    "y_test = df_model[mask_test][TARGET_COL]\n",
    "\n",
    "# --- FILL MISSING VALUES ---\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train_raw), columns=feature_cols)\n",
    "X_val_imputed = pd.DataFrame(imputer.transform(X_val_raw), columns=feature_cols)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test_raw), columns=feature_cols)\n",
    "\n",
    "# --- NORMALIZE (SCALE) ---\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_imputed)\n",
    "X_val = scaler.transform(X_val_imputed)\n",
    "X_test = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples:       {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607fbb7",
   "metadata": {},
   "source": [
    "### 3. First Try (Initial Model)\n",
    "I'll define a simple network and run it just to see if the pipeline works without crashing. I'll check the metrics on all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774242a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEFINE THE NETWORK ---\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# --- TRAINING HELPER FUNCTION ---\n",
    "def train_model(model, X_t, y_t, X_v, y_v, lr=0.001, epochs=150, batch_size=32, verbose=True):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_t, y_t), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * batch_X.size(0)\n",
    "            \n",
    "        # Calculate metrics\n",
    "        train_rmse = np.sqrt(epoch_loss / len(X_t))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_v)\n",
    "            val_loss = criterion(val_outputs, y_v)\n",
    "            val_rmse = np.sqrt(val_loss.item())\n",
    "            \n",
    "        train_losses.append(train_rmse)\n",
    "        val_losses.append(val_rmse)\n",
    "        \n",
    "        if verbose and (epoch % 50 == 0 or epoch == epochs-1):\n",
    "            print(f\"Epoch {epoch}/{epochs} -> Train RMSE: {train_rmse:.2f} | Val RMSE: {val_rmse:.2f}\")\n",
    "            \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# --- RUNNING THE INITIAL MODEL ---\n",
    "input_dim = X_train.shape[1]\n",
    "model_init = SimpleNN(input_dim).to(device)\n",
    "\n",
    "# Training with standard settings\n",
    "train_hist, val_hist = train_model(model_init, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, \n",
    "                                   lr=0.001, epochs=150, batch_size=32)\n",
    "\n",
    "# --- PLOTTING HISTORY ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_hist, label='Training RMSE', color='blue')\n",
    "plt.plot(val_hist, label='Validation RMSE', color='red')\n",
    "plt.title(f'Learning Curve (First Try - {CHOSEN_CROP})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- EVALUATION TABLE ---\n",
    "def get_metrics(model, X, y_true):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).cpu().numpy().flatten()\n",
    "    y_true_np = y_true\n",
    "    # Handle tensor vs numpy\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true_np = y_true.cpu().numpy().flatten()\n",
    "        \n",
    "    rmse = np.sqrt(mean_squared_error(y_true_np, preds))\n",
    "    r2 = r2_score(y_true_np, preds)\n",
    "    return rmse, r2, preds\n",
    "\n",
    "# Get stats for all sets\n",
    "rmse_t, r2_t, _ = get_metrics(model_init, X_train_tensor, y_train_tensor)\n",
    "rmse_v, r2_v, _ = get_metrics(model_init, X_val_tensor, y_val_tensor)\n",
    "rmse_test, r2_test, preds_init_test = get_metrics(model_init, X_test_tensor, y_test)\n",
    "\n",
    "# Show results\n",
    "metrics_data = {\n",
    "    'Metric': ['RMSE', 'R²'],\n",
    "    'Train': [rmse_t, r2_t],\n",
    "    'Validation': [rmse_v, r2_v],\n",
    "    'Test': [rmse_test, r2_test]\n",
    "}\n",
    "print(\"\\n--- Initial Model Performance ---\")\n",
    "display(pd.DataFrame(metrics_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d9630",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Tuning (Optuna)\n",
    "Now the fun part. I'm using Optuna to find the best configuration (number of units, dropout, learning rate, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FLEXIBLE MODEL FOR OPTUNA ---\n",
    "class DynamicNN(nn.Module):\n",
    "    def __init__(self, input_dim, n_layers, n_units, dropout, activation_name):\n",
    "        super(DynamicNN, self).__init__()\n",
    "        layers = []\n",
    "        in_features = input_dim\n",
    "        \n",
    "        # Choose Activation Function\n",
    "        if activation_name == \"ReLU\":\n",
    "            act_fn = nn.ReLU()\n",
    "        elif activation_name == \"LeakyReLU\":\n",
    "            act_fn = nn.LeakyReLU()\n",
    "        else:\n",
    "            act_fn = nn.ReLU()\n",
    "\n",
    "        # Stack Layers\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(nn.Linear(in_features, n_units))\n",
    "            layers.append(act_fn)\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_features = n_units\n",
    "            \n",
    "        layers.append(nn.Linear(in_features, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# --- OBJECTIVE FUNCTION ---\n",
    "def objective(trial):\n",
    "    # Defining the search space\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 3, 3)   # Keeping this fixed for now\n",
    "    n_units = trial.suggest_int(\"n_units\", 32, 48)   # Trying values around 42\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.14, 0.18)\n",
    "    lr = trial.suggest_float(\"lr\", 0.0006, 0.0010, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"LeakyReLU\", \"ReLU\"])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\"])\n",
    "\n",
    "    # Build model with these params\n",
    "    model = DynamicNN(input_dim, n_layers, n_units, dropout, activation).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), \n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Quick training loop\n",
    "    epochs = 40 # Keeping epochs lower for speed during tuning\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_tensor)\n",
    "            val_rmse = np.sqrt(criterion(val_pred, y_val_tensor).item())\n",
    "\n",
    "        # Pruning mechanism (stops bad trials early)\n",
    "        trial.report(val_rmse, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_rmse\n",
    "\n",
    "# --- START TUNING ---\n",
    "study = optuna.create_study(direction='minimize', study_name='Crop_Yield_NN_Optuna')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"\\nFound the best settings:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a3401",
   "metadata": {},
   "source": [
    "### 5. Optuna Visuals\n",
    "Let's look at the charts to see how the optimization process went and which parameters mattered most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d396ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization History\n",
    "fig = plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "# Parameter Importance\n",
    "try:\n",
    "    fig = plot_param_importances(study)\n",
    "    fig.show()\n",
    "except:\n",
    "    print(\"Oops, couldn't plot importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99bf3cf",
   "metadata": {},
   "source": [
    "### 6. Training the Final Model\n",
    "I'll take the best parameters from Optuna and train a fresh model. This time, I'll combine the Training and Validation sets to give the model maximum data before the final Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Train and Validation Data\n",
    "X_train_full = np.vstack((X_train, X_val))\n",
    "y_train_full = np.concatenate((y_train, y_val))\n",
    "\n",
    "X_train_full_tensor = torch.tensor(X_train_full, dtype=torch.float32).to(device)\n",
    "y_train_full_tensor = torch.tensor(y_train_full, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "bp = study.best_params\n",
    "\n",
    "final_model = DynamicNN(\n",
    "    input_dim,\n",
    "    bp['n_layers'], \n",
    "    bp['n_units'], \n",
    "    bp['dropout'], \n",
    "    bp['activation']\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=bp['lr'])\n",
    "criterion = nn.MSELoss()\n",
    "train_loader = DataLoader(TensorDataset(X_train_full_tensor, y_train_full_tensor), \n",
    "                          batch_size=bp['batch_size'], shuffle=True)\n",
    "\n",
    "print(\"Training the final version now...\")\n",
    "final_model.train()\n",
    "for epoch in range(150):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1bd7",
   "metadata": {},
   "source": [
    "### 7. Results & Comparison\n",
    "Let's see the numbers. I'll compare the Initial Model side-by-side with the Tuned Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Final Model\n",
    "# Note: Evaluating 'Train' and 'Val' on original splits for consistent comparison,\n",
    "# even though the model saw the Val data during training this time.\n",
    "rmse_f_t, r2_f_t, _ = get_metrics(final_model, X_train_tensor, y_train_tensor)\n",
    "rmse_f_v, r2_f_v, _ = get_metrics(final_model, X_val_tensor, y_val_tensor)\n",
    "rmse_f_test, r2_f_test, preds_final_test = get_metrics(final_model, X_test_tensor, y_test)\n",
    "\n",
    "metrics_final = {\n",
    "    'Metric': ['RMSE', 'R²'],\n",
    "    'Train': [rmse_f_t, r2_f_t],\n",
    "    'Validation': [rmse_f_v, r2_f_v],\n",
    "    'Test': [rmse_f_test, r2_f_test]\n",
    "}\n",
    "\n",
    "print(\"--- Final Tuned Model Metrics ---\")\n",
    "display(pd.DataFrame(metrics_final))\n",
    "\n",
    "# --- PLOT COMPARISON ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "all_preds = np.concatenate([preds_init_test, preds_final_test])\n",
    "all_true = np.concatenate([y_test, y_test])\n",
    "min_val, max_val = min(all_preds.min(), all_true.min()), max(all_preds.max(), all_true.max())\n",
    "\n",
    "# Initial Model Plot\n",
    "axes[0].scatter(y_test, preds_init_test, alpha=0.4, color='orange')\n",
    "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[0].set_title(f'Initial Model\\nTest RMSE: {rmse_test:.2f}')\n",
    "\n",
    "# Tuned Model Plot\n",
    "axes[1].scatter(y_test, preds_final_test, alpha=0.4, color='green')\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[1].set_title(f'Tuned Model\\nTest RMSE: {rmse_f_test:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TIMELINE PLOT ---\n",
    "\n",
    "# 1. Get Predictions for ALL data\n",
    "# (Need to scale and tensorize everything first)\n",
    "X_all = scaler.transform(df_model[feature_cols])\n",
    "X_all_tensor = torch.tensor(X_all, dtype=torch.float32).to(device)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    all_predictions = final_model(X_all_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# 2. Create DataFrame\n",
    "df_full_trend = pd.DataFrame({\n",
    "    'Year': df_model['year'],\n",
    "    'Actual': df_model[TARGET_COL],\n",
    "    'Predicted': all_predictions\n",
    "})\n",
    "\n",
    "# 3. Aggregate by Year\n",
    "yearly_trend = df_full_trend.groupby('Year').mean()\n",
    "\n",
    "# 4. Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Lines\n",
    "plt.plot(yearly_trend.index, yearly_trend['Actual'],\n",
    "         marker='o', label='Actual Yield', linewidth=2, color='blue')\n",
    "\n",
    "plt.plot(yearly_trend.index, yearly_trend['Predicted'],\n",
    "         marker='x', linestyle='--', label='Predicted Yield', linewidth=2, color='orange')\n",
    "\n",
    "# --- Time Boundaries ---\n",
    "MIN_YEAR = yearly_trend.index.min()\n",
    "MAX_YEAR = yearly_trend.index.max()\n",
    "\n",
    "train_boundary = TRAIN_END_YEAR - 0.5\n",
    "val_boundary = VAL_END_YEAR - 0.5\n",
    "\n",
    "# --- Background Colors ---\n",
    "plt.axvspan(MIN_YEAR - 0.5, train_boundary, color='green', alpha=0.1,\n",
    "            label=f'Train (<{TRAIN_END_YEAR})')\n",
    "\n",
    "plt.axvspan(train_boundary, val_boundary, color='yellow', alpha=0.1,\n",
    "            label=f'Validation ({TRAIN_END_YEAR}-{VAL_END_YEAR - 1})')\n",
    "\n",
    "plt.axvspan(val_boundary, MAX_YEAR + 0.5, color='red', alpha=0.1,\n",
    "            label=f'Test (>={VAL_END_YEAR})')\n",
    "\n",
    "# --- Separators ---\n",
    "plt.axvline(train_boundary, color='grey', linestyle=':', alpha=0.5)\n",
    "plt.axvline(val_boundary, color='grey', linestyle=':', alpha=0.5)\n",
    "\n",
    "# --- Text Labels ---\n",
    "y_max = yearly_trend['Actual'].max()\n",
    "text_y = y_max * 1.05\n",
    "\n",
    "plt.text((MIN_YEAR + train_boundary)/2, text_y, 'TRAINING',\n",
    "         ha='center', fontsize=12, fontweight='bold', color='green')\n",
    "\n",
    "plt.text((train_boundary + val_boundary)/2, text_y, 'VALIDATION',\n",
    "         ha='center', fontsize=12, fontweight='bold', color='#D4AC0D')\n",
    "\n",
    "plt.text((val_boundary + MAX_YEAR)/2, text_y, 'TESTING',\n",
    "         ha='center', fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "# --- Labels & Grid ---\n",
    "plt.title(f'Full Timeline Analysis: Actual vs. Predicted Yield ({CHOSEN_CROP})', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Yield (hg/ha)', fontsize=12)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.xticks(np.arange(MIN_YEAR, MAX_YEAR + 1, 2))\n",
    "plt.xlim(MIN_YEAR - 0.5, MAX_YEAR + 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Adding country info ---\n",
    "df_full_trend['Area'] = df_model['area']\n",
    "\n",
    "# --- Country-specific Analysis ---\n",
    "TARGET_COUNTRY = \"Vietnam\"\n",
    "df_country = df_full_trend[df_full_trend['Area'] == TARGET_COUNTRY]\n",
    "country_trend = df_country.groupby('Year')[['Actual', 'Predicted']].mean()\n",
    "\n",
    "# --- Plotting Country Trend ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Lines\n",
    "plt.plot(country_trend.index, country_trend['Actual'],\n",
    "         marker='o', label=f'Actual Yield ({TARGET_COUNTRY})', linewidth=2, color='blue')\n",
    "plt.plot(country_trend.index, country_trend['Predicted'],\n",
    "         marker='x', linestyle='--', label=f'Predicted Yield ({TARGET_COUNTRY})', linewidth=2, color='orange')\n",
    "\n",
    "# --- Boundaries ---\n",
    "MIN_YEAR = country_trend.index.min()\n",
    "MAX_YEAR = country_trend.index.max()\n",
    "train_boundary = TRAIN_END_YEAR - 0.5\n",
    "val_boundary = VAL_END_YEAR - 0.5\n",
    "\n",
    "# --- Shaded Regions ---\n",
    "plt.axvspan(MIN_YEAR - 0.5, train_boundary, color='green', alpha=0.1, label=f'Train (<{TRAIN_END_YEAR})')\n",
    "plt.axvspan(train_boundary, val_boundary, color='yellow', alpha=0.1, label=f'Validation ({TRAIN_END_YEAR}-{VAL_END_YEAR-1})')\n",
    "plt.axvspan(val_boundary, MAX_YEAR + 0.5, color='red', alpha=0.1, label=f'Test (>={VAL_END_YEAR})')\n",
    "\n",
    "# --- Vertical Lines ---\n",
    "plt.axvline(train_boundary, color='grey', linestyle=':', alpha=0.5)\n",
    "plt.axvline(val_boundary, color='grey', linestyle=':', alpha=0.5)\n",
    "\n",
    "# --- Labels ---\n",
    "y_max = country_trend['Actual'].max()\n",
    "text_y = y_max * 1.1\n",
    "\n",
    "plt.text((MIN_YEAR + train_boundary)/2, text_y, 'TRAINING', ha='center', fontsize=12, fontweight='bold', color='green')\n",
    "plt.text((train_boundary + val_boundary)/2, text_y, 'VALIDATION', ha='center', fontsize=12, fontweight='bold', color='#D4AC0D')\n",
    "plt.text((val_boundary + MAX_YEAR)/2, text_y, 'TESTING', ha='center', fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "# --- Final Polish ---\n",
    "plt.title(f'Yield Analysis for {TARGET_COUNTRY}: Actual vs. Predicted ({CHOSEN_CROP})', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Yield (hg/ha)', fontsize=12)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(np.arange(MIN_YEAR, MAX_YEAR + 1, 2))\n",
    "plt.xlim(MIN_YEAR - 0.5, MAX_YEAR + 0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02369b59",
   "metadata": {},
   "source": [
    "### 8. Geographic Error Map\n",
    "Which countries is the model struggling with? Let's map out the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046da8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# --- 1. Filter for Test Data ---\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "test_context = df_model[mask_test][['area', 'year']]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Value': y_test,\n",
    "    'Predicted_Value': preds_final_test\n",
    "})\n",
    "\n",
    "# Join country info\n",
    "comparison_df = comparison_df.join(test_context)\n",
    "\n",
    "# --- 2. Keep only the latest year for each country ---\n",
    "latest_year = comparison_df.groupby('area')['year'].transform('max')\n",
    "comparison_df_latest = comparison_df[comparison_df['year'] == latest_year]\n",
    "\n",
    "print(comparison_df_latest.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_by_country = (\n",
    "    comparison_df\n",
    "    .groupby('area')\n",
    "    .apply(lambda x: np.sqrt(np.mean((x['Actual_Value'] - x['Predicted_Value'])**2)))\n",
    "    .reset_index(name='RMSE')\n",
    ")\n",
    "\n",
    "# --- 3. Sort (High Error -> Low Error) ---\n",
    "rmse_by_country_sorted = rmse_by_country.sort_values(by='RMSE', ascending=False)\n",
    "\n",
    "# --- 4. Show the list ---\n",
    "print(rmse_by_country_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01755bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Cleaning up country names for the map\n",
    "comparison_df['area'] = comparison_df_latest['area'].replace({\n",
    "    'United_States_of_America': 'United States',\n",
    "    'Russian_Federation': 'Russia',\n",
    "    'Viet_Nam': 'Vietnam',\n",
    "    'Türkiye': 'Turkey',\n",
    "    'China, mainland': 'China',\n",
    "    'Republic_of_Korea': 'South Korea'\n",
    "})\n",
    "\n",
    "# Calculating Squared Error\n",
    "comparison_df['Squared_Error'] = (comparison_df['Actual_Value'] - comparison_df['Predicted_Value']) ** 2\n",
    "\n",
    "# Calculating Error Percentage for RMSPE\n",
    "comparison_df['Error_Pct'] = ((comparison_df['Actual_Value'] - comparison_df['Predicted_Value']) / (comparison_df['Actual_Value'] + 1e-6)) ** 2\n",
    "\n",
    "# Aggregating stats by country\n",
    "map_data = comparison_df.groupby('area').agg(\n",
    "    RMSPE=('Error_Pct', lambda x: np.sqrt(x.mean()) * 100),\n",
    "    RMSE=('Squared_Error', lambda x: np.sqrt(x.mean())),\n",
    "    Actual_Mean=('Actual_Value', 'mean'),\n",
    "    Predicted_Mean=('Predicted_Value', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "map_data.rename(columns={'area':'Country'}, inplace=True)\n",
    "\n",
    "# Plotting the World Map\n",
    "fig = px.choropleth(\n",
    "    map_data,\n",
    "    locations='Country',\n",
    "    locationmode='country names',\n",
    "    color='RMSPE',\n",
    "    color_continuous_scale=['green', 'red'],\n",
    "    range_color=[0, 50],\n",
    "    title='Prediction Error by Country (RMSPE)',\n",
    "    hover_data={\n",
    "        'RMSPE': ':.2f',\n",
    "        'RMSE': ':.2f',\n",
    "        'Actual_Mean': ':.2f',\n",
    "        'Predicted_Mean': ':.2f'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fc4f6",
   "metadata": {},
   "source": [
    "### 9. Feature Importance\n",
    "Since Neural Nets are basically black boxes, I'm using **Permutation Importance** to figure out which variables actually drive the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e313a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to make PyTorch work with Scikit-Learn tools\n",
    "class PyTorchEstimator:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "    def fit(self, X, y): pass\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_t = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "            return self.model(X_t).cpu().numpy().flatten()\n",
    "\n",
    "estimator = PyTorchEstimator(final_model, device)\n",
    "res = permutation_importance(estimator, X_val, y_val, scoring='neg_root_mean_squared_error', n_repeats=5)\n",
    "\n",
    "imps = pd.DataFrame({'Feature': feature_cols, 'Importance': np.abs(res.importances_mean)})\n",
    "imps = imps.sort_values('Importance', ascending=False).head(15)\n",
    "\n",
    "sns.barplot(x='Importance', y='Feature', data=imps, palette='viridis')\n",
    "plt.title('Top 15 Features')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
