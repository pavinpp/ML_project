{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5986cd18",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction: PyTorch Neural Network with Optuna (Part 5)\n",
    "\n",
    "## Overview\n",
    "Here I'm training a **Feedforward Neural Network (PyTorch)** to predict crop yields. I've set it up so we can easily swap the target crop in the data loading part.\n",
    "\n",
    "## My Plan\n",
    "1.  **Pick a Crop:** Choose what we want to predict (like Rice).\n",
    "2.  **Clean Up:** Remove some outliers (min/max yields per country) to help the model learn better.\n",
    "3.  **Split Data:** Divide by year (Train, Val, Test) so we aren't cheating by predicting the past with future data.\n",
    "4.  **Scale:** Normalize everything so the Neural Net doesn't get confused by big numbers.\n",
    "5.  **Initial Model:** Try a basic network first to see how it does.\n",
    "6.  **Tune It:** Use **Optuna** to automatically find the best settings (hyperparameters).\n",
    "7.  **Final Test:** See if the tuned model is actually better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a747c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Optuna Visualization stuff\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "# Making plots look nice\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Check if I have a GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008b386",
   "metadata": {},
   "source": [
    "### 1. Loading Data & Choosing a Crop\n",
    "Grab the dataset and decide what to predict. I'm sticking with **Rice** for now. I'll also drop rows where the target yield is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_parquet('Parquet/XY_v3.parquet')\n",
    "\n",
    "# --- SEE WHAT CROPS WE HAVE ---\n",
    "target_columns = [col for col in df.columns if col.startswith('Y_')]\n",
    "available_crops = [col.replace('Y_', '') for col in target_columns]\n",
    "\n",
    "print(\"--- Crops available ---\")\n",
    "print(available_crops)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- PICK YOUR CROP HERE ---\n",
    "CHOSEN_CROP = 'rice'  # <--- Change to 'lettuce', 'pepper', etc. if you want\n",
    "# ---------------------------\n",
    "\n",
    "TARGET_COL = f'Y_{CHOSEN_CROP}'\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target {TARGET_COL} not found. Typo?\")\n",
    "\n",
    "print(f\"Target: {TARGET_COL}\")\n",
    "\n",
    "# Drop missing targets\n",
    "df_model = df.dropna(subset=[TARGET_COL])\n",
    "print(f\"Rows with valid target: {len(df_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce99f69",
   "metadata": {},
   "source": [
    "### 2. Cleaning & Preparing Features\n",
    "Before I set up my features, I need to remove some extreme outliers. Specifically, I'm removing the min and max yield rows for each country to make the model more robust.\n",
    "\n",
    "Then I'll split the data by year (Train < 2014, Val 2014-2018, Test >= 2019) and scale everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# --- Remove min/max TARGET_COL rows per country (robust version) ---\n",
    "df_model = df_model.copy()\n",
    "\n",
    "# Get row positions (not index labels)\n",
    "idx_min = df_model.groupby('area')[TARGET_COL].idxmin().values\n",
    "idx_max = df_model.groupby('area')[TARGET_COL].idxmax().values\n",
    "\n",
    "# Combine them safely\n",
    "rows_to_drop = np.concatenate([idx_min, idx_max])\n",
    "\n",
    "# Drop by position\n",
    "df_model = df_model.iloc[~df_model.index.isin(rows_to_drop)].reset_index(drop=True)\n",
    "print(f\"Rows after dropping min/max outliers: {len(df_model)}\")\n",
    "\n",
    "# --- DROP UNUSED COLUMNS ---\n",
    "cols_to_drop = [c for c in df_model.columns \n",
    "                if c.startswith(\"avg_yield_\") and CHOSEN_CROP not in c]\n",
    "df_model = df_model.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- DEFINE FEATURES ---\n",
    "feature_cols = [c for c in df_model.columns \n",
    "                if not c.startswith('Y_') and c not in ['area']]\n",
    "\n",
    "print(f\"Total Features: {len(feature_cols)}\")\n",
    "\n",
    "# --- SPLIT DATA BY YEAR ---\n",
    "TRAIN_END_YEAR = 2014\n",
    "VAL_END_YEAR = 2019\n",
    "\n",
    "# 1. Train (< 2014)\n",
    "mask_train = df_model['year'] < TRAIN_END_YEAR\n",
    "X_train_raw = df_model[mask_train][feature_cols]\n",
    "y_train = df_model[mask_train][TARGET_COL]\n",
    "\n",
    "# 2. Validation (2014 - 2018)\n",
    "mask_val = (df_model['year'] >= TRAIN_END_YEAR) & (df_model['year'] < VAL_END_YEAR)\n",
    "X_val_raw = df_model[mask_val][feature_cols]\n",
    "y_val = df_model[mask_val][TARGET_COL]\n",
    "\n",
    "# 3. Test (>= 2019)\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "X_test_raw = df_model[mask_test][feature_cols]\n",
    "y_test = df_model[mask_test][TARGET_COL]\n",
    "\n",
    "# --- IMPUTE NANS ---\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train_raw), columns=feature_cols)\n",
    "X_val_imputed = pd.DataFrame(imputer.transform(X_val_raw), columns=feature_cols)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test_raw), columns=feature_cols)\n",
    "\n",
    "# --- SCALE DATA ---\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_imputed)\n",
    "X_val = scaler.transform(X_val_imputed)\n",
    "X_test = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Make Tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train)}\")\n",
    "print(f\"Val size:   {len(X_val)}\")\n",
    "print(f\"Test size:  {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607fbb7",
   "metadata": {},
   "source": [
    "### 3. Initial Model Testing\n",
    "I'll try a standard Feedforward Network first to check for any weird errors. I'll also check the metrics for Train, Validation, and Test to see how it generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774242a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BUILD NETWORK ---\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# --- TRAIN FUNCTION ---\n",
    "def train_model(model, X_t, y_t, X_v, y_v, lr=0.001, epochs=150, batch_size=32, verbose=True):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_t, y_t), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * batch_X.size(0)\n",
    "            \n",
    "        # Record losses\n",
    "        train_rmse = np.sqrt(epoch_loss / len(X_t))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_v)\n",
    "            val_loss = criterion(val_outputs, y_v)\n",
    "            val_rmse = np.sqrt(val_loss.item())\n",
    "            \n",
    "        train_losses.append(train_rmse)\n",
    "        val_losses.append(val_rmse)\n",
    "        \n",
    "        if verbose and (epoch % 50 == 0 or epoch == epochs-1):\n",
    "            print(f\"Epoch {epoch}/{epochs} | Train RMSE: {train_rmse:.2f} | Val RMSE: {val_rmse:.2f}\")\n",
    "            \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# --- TRAIN INITIAL MODEL ---\n",
    "input_dim = X_train.shape[1]\n",
    "model_init = SimpleNN(input_dim).to(device)\n",
    "\n",
    "# Using specific hyperparameters requested\n",
    "train_hist, val_hist = train_model(model_init, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, \n",
    "                                   lr=0.001, epochs=150, batch_size=32)\n",
    "\n",
    "# --- PLOT LEARNING CURVE ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_hist, label='Training RMSE', color='blue')\n",
    "plt.plot(val_hist, label='Validation RMSE', color='red')\n",
    "plt.title(f'Initial Model Learning Curve ({CHOSEN_CROP})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- METRICS TABLE ---\n",
    "def get_metrics(model, X, y_true):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).cpu().numpy().flatten()\n",
    "    y_true_np = y_true\n",
    "    # Handle if y_true is tensor or numpy\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true_np = y_true.cpu().numpy().flatten()\n",
    "        \n",
    "    rmse = np.sqrt(mean_squared_error(y_true_np, preds))\n",
    "    r2 = r2_score(y_true_np, preds)\n",
    "    return rmse, r2, preds\n",
    "\n",
    "# Calculate for all splits\n",
    "rmse_t, r2_t, _ = get_metrics(model_init, X_train_tensor, y_train_tensor)\n",
    "rmse_v, r2_v, _ = get_metrics(model_init, X_val_tensor, y_val_tensor)\n",
    "rmse_test, r2_test, preds_init_test = get_metrics(model_init, X_test_tensor, y_test)\n",
    "\n",
    "# Display nicer table\n",
    "metrics_data = {\n",
    "    'Metric': ['RMSE', 'R²'],\n",
    "    'Train': [rmse_t, r2_t],\n",
    "    'Validation': [rmse_v, r2_v],\n",
    "    'Test': [rmse_test, r2_test]\n",
    "}\n",
    "print(\"\\n--- Initial Model Metrics ---\")\n",
    "display(pd.DataFrame(metrics_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d9630",
   "metadata": {},
   "source": [
    "### 4. Tuning with Optuna\n",
    "Now I'm using Optuna to hunt for the best architecture. I've set the search space exactly as planned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DYNAMIC MODEL BUILDER ---\n",
    "class DynamicNN(nn.Module):\n",
    "    def __init__(self, input_dim, n_layers, n_units, dropout, activation_name):\n",
    "        super(DynamicNN, self).__init__()\n",
    "        layers = []\n",
    "        in_features = input_dim\n",
    "        \n",
    "        # Select Activation\n",
    "        if activation_name == \"ReLU\":\n",
    "            act_fn = nn.ReLU()\n",
    "        elif activation_name == \"LeakyReLU\":\n",
    "            act_fn = nn.LeakyReLU()\n",
    "        else:\n",
    "            act_fn = nn.ReLU()\n",
    "\n",
    "        # Build Layers\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(nn.Linear(in_features, n_units))\n",
    "            layers.append(act_fn)\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_features = n_units\n",
    "            \n",
    "        layers.append(nn.Linear(in_features, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# --- OPTUNA OBJECTIVE ---\n",
    "def objective(trial):\n",
    "    # Scoped Search Space\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 3, 3)   # Fixed\n",
    "    n_units = trial.suggest_int(\"n_units\", 32, 48)   # Band around 42\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.14, 0.18)\n",
    "    lr = trial.suggest_float(\"lr\", 0.0006, 0.0010, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"LeakyReLU\", \"ReLU\"])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\"])\n",
    "\n",
    "    # Build & Setup\n",
    "    model = DynamicNN(input_dim, n_layers, n_units, dropout, activation).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), \n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Training Loop\n",
    "    epochs = 40 # Slightly fewer for tuning speed\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Check Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_tensor)\n",
    "            val_rmse = np.sqrt(criterion(val_pred, y_val_tensor).item())\n",
    "\n",
    "        # Pruning\n",
    "        trial.report(val_rmse, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_rmse\n",
    "\n",
    "# --- RUN STUDY ---\n",
    "study = optuna.create_study(direction='minimize', study_name='Crop_Yield_NN_Optuna')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"\\nBest Params:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a3401",
   "metadata": {},
   "source": [
    "### 5. Visualizing the Tuning Process\n",
    "Just some quick plots to see what Optuna found interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d396ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization History\n",
    "fig = plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "# Parameter Importance\n",
    "try:\n",
    "    fig = plot_param_importances(study)\n",
    "    fig.show()\n",
    "except:\n",
    "    print(\"Couldn't plot importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99bf3cf",
   "metadata": {},
   "source": [
    "### 6. Final Model\n",
    "Now I'll build the final model using the best settings. I'll train it on the combined Train + Validation data to give it as much info as possible before the final test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Train + Val\n",
    "X_train_full = np.vstack((X_train, X_val))\n",
    "y_train_full = np.concatenate((y_train, y_val))\n",
    "\n",
    "X_train_full_tensor = torch.tensor(X_train_full, dtype=torch.float32).to(device)\n",
    "y_train_full_tensor = torch.tensor(y_train_full, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "bp = study.best_params\n",
    "\n",
    "final_model = DynamicNN(\n",
    "    input_dim,\n",
    "    bp['n_layers'], \n",
    "    bp['n_units'], \n",
    "    bp['dropout'], \n",
    "    bp['activation']\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=bp['lr'])\n",
    "criterion = nn.MSELoss()\n",
    "train_loader = DataLoader(TensorDataset(X_train_full_tensor, y_train_full_tensor), \n",
    "                          batch_size=bp['batch_size'], shuffle=True)\n",
    "\n",
    "print(\"Training Final Model...\")\n",
    "final_model.train()\n",
    "for epoch in range(150):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1bd7",
   "metadata": {},
   "source": [
    "### 7. Results & Analysis\n",
    "Let's see the numbers! I'll compare the Initial Model vs the Tuned Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Metrics for Final Model\n",
    "# Note: I'm evaluating 'Train' and 'Val' on the original splits for comparison consistency,\n",
    "# even though the model saw the Val data during training this time.\n",
    "rmse_f_t, r2_f_t, _ = get_metrics(final_model, X_train_tensor, y_train_tensor)\n",
    "rmse_f_v, r2_f_v, _ = get_metrics(final_model, X_val_tensor, y_val_tensor)\n",
    "rmse_f_test, r2_f_test, preds_final_test = get_metrics(final_model, X_test_tensor, y_test)\n",
    "\n",
    "metrics_final = {\n",
    "    'Metric': ['RMSE', 'R²'],\n",
    "    'Train': [rmse_f_t, r2_f_t],\n",
    "    'Validation': [rmse_f_v, r2_f_v],\n",
    "    'Test': [rmse_f_test, r2_f_test]\n",
    "}\n",
    "\n",
    "print(\"--- Final Tuned Model Metrics ---\")\n",
    "display(pd.DataFrame(metrics_final))\n",
    "\n",
    "# --- COMPARE PLOTS ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "all_preds = np.concatenate([preds_init_test, preds_final_test])\n",
    "all_true = np.concatenate([y_test, y_test])\n",
    "min_val, max_val = min(all_preds.min(), all_true.min()), max(all_preds.max(), all_true.max())\n",
    "\n",
    "# Initial\n",
    "axes[0].scatter(y_test, preds_init_test, alpha=0.4, color='orange')\n",
    "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[0].set_title(f'Initial Model\\nTest RMSE: {rmse_test:.2f}')\n",
    "\n",
    "# Tuned\n",
    "axes[1].scatter(y_test, preds_final_test, alpha=0.4, color='green')\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[1].set_title(f'Tuned Model\\nTest RMSE: {rmse_f_test:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FULL TIMELINE PLOT ---\n",
    "\n",
    "# 1. Predictions\n",
    "# (Scaling & Tensor conversion needed since it's a PyTorch model)\n",
    "X_all = scaler.transform(df_model[feature_cols])\n",
    "X_all_tensor = torch.tensor(X_all, dtype=torch.float32).to(device)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    all_predictions = final_model(X_all_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# 2. Build DataFrame\n",
    "df_full_trend = pd.DataFrame({\n",
    "    'Year': df_model['year'],\n",
    "    'Actual': df_model[TARGET_COL],\n",
    "    'Predicted': all_predictions\n",
    "})\n",
    "\n",
    "# 3. Aggregate yearly\n",
    "yearly_trend = df_full_trend.groupby('Year').mean()\n",
    "\n",
    "# 4. Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot lines\n",
    "plt.plot(yearly_trend.index, yearly_trend['Actual'],\n",
    "         marker='o', label='Actual Yield', linewidth=2, color='blue')\n",
    "\n",
    "plt.plot(yearly_trend.index, yearly_trend['Predicted'],\n",
    "         marker='x', linestyle='--', label='Predicted Yield', linewidth=2, color='orange')\n",
    "\n",
    "# --- Boundaries ---\n",
    "MIN_YEAR = yearly_trend.index.min()\n",
    "MAX_YEAR = yearly_trend.index.max()\n",
    "\n",
    "train_boundary = TRAIN_END_YEAR - 0.5\n",
    "val_boundary = VAL_END_YEAR - 0.5\n",
    "\n",
    "# --- Shaded Regions ---\n",
    "plt.axvspan(MIN_YEAR - 0.5, train_boundary, color='green', alpha=0.1,\n",
    "            label=f'Train (<{TRAIN_END_YEAR})')\n",
    "\n",
    "plt.axvspan(train_boundary, val_boundary, color='yellow', alpha=0.1,\n",
    "            label=f'Validation ({TRAIN_END_YEAR}-{VAL_END_YEAR - 1})')\n",
    "\n",
    "plt.axvspan(val_boundary, MAX_YEAR + 0.5, color='red', alpha=0.1,\n",
    "            label=f'Test (>={VAL_END_YEAR})')\n",
    "\n",
    "# --- Split Lines ---\n",
    "plt.axvline(train_boundary, color='grey', linestyle=':', alpha=0.5)\n",
    "plt.axvline(val_boundary, color='grey', linestyle=':', alpha=0.5)\n",
    "\n",
    "# --- Labels ---\n",
    "y_max = yearly_trend['Actual'].max()\n",
    "text_y = y_max * 1.05\n",
    "\n",
    "plt.text((MIN_YEAR + train_boundary)/2, text_y, 'TRAINING',\n",
    "         ha='center', fontsize=12, fontweight='bold', color='green')\n",
    "\n",
    "plt.text((train_boundary + val_boundary)/2, text_y, 'VALIDATION',\n",
    "         ha='center', fontsize=12, fontweight='bold', color='#D4AC0D')\n",
    "\n",
    "plt.text((val_boundary + MAX_YEAR)/2, text_y, 'TESTING',\n",
    "         ha='center', fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "# --- Final Styling ---\n",
    "plt.title(f'Full Timeline Analysis: Actual vs. Predicted Yield ({CHOSEN_CROP})', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Yield (hg/ha)', fontsize=12)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.xticks(np.arange(MIN_YEAR, MAX_YEAR + 1, 2))\n",
    "plt.xlim(MIN_YEAR - 0.5, MAX_YEAR + 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02369b59",
   "metadata": {},
   "source": [
    "### 8. Geographic Error Map\n",
    "Checking where the model messes up the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Re-join test data with Country names\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "test_countries = df_model[mask_test]['area'].values\n",
    "\n",
    "comp_df = pd.DataFrame({\n",
    "    'area': test_countries,\n",
    "    'Actual': y_test,\n",
    "    'Predicted': preds_final_test\n",
    "})\n",
    "\n",
    "# Clean names for map\n",
    "comp_df['area'] = comp_df['area'].replace({\n",
    "    'United_States_of_America': 'United States',\n",
    "    'Viet_Nam': 'Vietnam',\n",
    "    'China,_mainland': 'China',\n",
    "    # Add more if needed...\n",
    "})\n",
    "\n",
    "# Calculate RMSPE\n",
    "comp_df['Sq_Err_Pct'] = ((comp_df['Actual'] - comp_df['Predicted']) / (comp_df['Actual'] + 1e-6))**2\n",
    "map_data = comp_df.groupby('area')['Sq_Err_Pct'].mean().apply(np.sqrt).mul(100).reset_index(name='RMSPE')\n",
    "\n",
    "fig = px.choropleth(\n",
    "    map_data, \n",
    "    locations='area', \n",
    "    locationmode='country names', \n",
    "    color='RMSPE',\n",
    "    title='Prediction Error by Country (RMSPE %)',\n",
    "    color_continuous_scale=['green', 'red']\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fc4f6",
   "metadata": {},
   "source": [
    "### 9. Feature Importance\n",
    "Since Neural Nets are \"black boxes\", I'm using Permutation Importance to see which variables actually matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e313a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for Permutation Importance\n",
    "class PyTorchEstimator:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "    def fit(self, X, y): pass\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_t = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "            return self.model(X_t).cpu().numpy().flatten()\n",
    "\n",
    "estimator = PyTorchEstimator(final_model, device)\n",
    "res = permutation_importance(estimator, X_val, y_val, scoring='neg_root_mean_squared_error', n_repeats=5)\n",
    "\n",
    "imps = pd.DataFrame({'Feature': feature_cols, 'Importance': np.abs(res.importances_mean)})\n",
    "imps = imps.sort_values('Importance', ascending=False).head(15)\n",
    "\n",
    "sns.barplot(x='Importance', y='Feature', data=imps, palette='viridis')\n",
    "plt.title('Top 15 Features')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}