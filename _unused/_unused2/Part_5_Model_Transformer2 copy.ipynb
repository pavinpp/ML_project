{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Optuna Visualization Tools\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_parquet('Parquet/XY_v2.parquet')\n",
    "\n",
    "# --- LIST AVAILABLE CROPS ---\n",
    "# Assumes targets start with 'Y_'\n",
    "target_columns = [col for col in df.columns if col.startswith('Y_')]\n",
    "available_crops = [col.replace('Y_', '') for col in target_columns]\n",
    "\n",
    "print(\"--- Available Crops found in Dataset ---\")\n",
    "print(available_crops)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- CONFIGURATION: SET CROP HERE ---\n",
    "CHOSEN_CROP = 'rice'  # <--- CHANGE THIS to 'lettuce', 'pepper', etc. based on list above\n",
    "# ------------------------------------\n",
    "\n",
    "# Define Target and Dynamic Lag Features\n",
    "TARGET_COL = f'Y_{CHOSEN_CROP}'\n",
    "LAG_1_FEATURE = f'avg_yield_{CHOSEN_CROP}_1y'\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target {TARGET_COL} not found in dataset. Check spelling.\")\n",
    "\n",
    "print(f\"Predicting Target: {TARGET_COL}\")\n",
    "print(f\"Using Lag 1 Feature: {LAG_1_FEATURE}\")\n",
    "\n",
    "# Clean Missing Targets for the chosen crop\n",
    "df_model = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "print(f\"Data Loaded. Rows with valid target: {len(df_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- IMPORTS (Add these if not already present) ---\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# --- DROP UNWANTED COLUMNS ---\n",
    "# Drop all columns that start with \"avg_yield_\" but do NOT match the chosen crop\n",
    "cols_to_drop = [c for c in df_model.columns \n",
    "                if c.startswith(\"avg_yield_\") and CHOSEN_CROP not in c]\n",
    "\n",
    "df_model = df_model.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- FEATURE SELECTION ---\n",
    "# Select independent variables (exclude 'Y_' columns and metadata)\n",
    "feature_cols = [c for c in df_model.columns \n",
    "                if not c.startswith('Y_') and c not in ['area']]\n",
    "\n",
    "# --- DISPLAY FEATURES TABLE ---\n",
    "print(f\"Total Features Used: {len(feature_cols)}\")\n",
    "print(\"-\" * 30)\n",
    "feature_preview = pd.DataFrame(feature_cols, columns=['Feature Name']).T\n",
    "display(feature_preview)\n",
    "\n",
    "# --- TIME-SERIES SPLIT ---\n",
    "TRAIN_END_YEAR = 2014\n",
    "VAL_END_YEAR = 2019\n",
    "\n",
    "# 1. Training Set (< 2014)\n",
    "mask_train = df_model['year'] < TRAIN_END_YEAR\n",
    "X_train_raw = df_model[mask_train][feature_cols]\n",
    "y_train = df_model[mask_train][TARGET_COL]\n",
    "\n",
    "# 2. Validation Set (>= 2014 and < 2019)\n",
    "mask_val = (df_model['year'] >= TRAIN_END_YEAR) & (df_model['year'] < VAL_END_YEAR)\n",
    "X_val_raw = df_model[mask_val][feature_cols]\n",
    "y_val = df_model[mask_val][TARGET_COL]\n",
    "\n",
    "# 3. Test Set (>= 2019)\n",
    "mask_test = df_model['year'] >= VAL_END_YEAR\n",
    "X_test_raw = df_model[mask_test][feature_cols]\n",
    "y_test = df_model[mask_test][TARGET_COL]\n",
    "\n",
    "# --- IMPUTATION (Handle NaNs before scaling) ---\n",
    "imputer = SimpleImputer(strategy='mean')  # Or 'median' if data is skewed\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train_raw), columns=feature_cols)\n",
    "X_val_imputed = pd.DataFrame(imputer.transform(X_val_raw), columns=feature_cols)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test_raw), columns=feature_cols)\n",
    "\n",
    "# Optional: Print NaN counts to verify (should be 0 after imputation)\n",
    "print(\"NaNs in X_train_imputed:\", X_train_imputed.isnull().sum().sum())\n",
    "print(\"NaNs in X_val_imputed:\", X_val_imputed.isnull().sum().sum())\n",
    "print(\"NaNs in X_test_imputed:\", X_test_imputed.isnull().sum().sum())\n",
    "\n",
    "X_train_imputed.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: yield(t) = yield(t-1)\n",
    "# Note: We use the raw dataframe for baseline lag feature access\n",
    "y_pred_baseline = df_model[mask_test][LAG_1_FEATURE]\n",
    "\n",
    "# Clean NaNs for metric calculation\n",
    "mask_valid = ~y_pred_baseline.isna() & ~y_test.isna()\n",
    "y_test_clean = y_test[mask_valid]\n",
    "y_pred_clean = y_pred_baseline[mask_valid]\n",
    "\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test_clean, y_pred_clean))\n",
    "r2_baseline = r2_score(y_test_clean, y_pred_clean)\n",
    "\n",
    "print(f\"Baseline RMSE: {rmse_baseline:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1. Torch Datasets & Loaders\n",
    "# =========================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Make sure these exist from previous cells:\n",
    "# X_train_imputed, X_val_imputed, X_test_imputed\n",
    "# y_train, y_val, y_test\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        X: pandas DataFrame or numpy array (n_samples, n_features)\n",
    "        y: pandas Series or numpy array (n_samples,)\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = TabularDataset(X_train_imputed, y_train)\n",
    "val_dataset   = TabularDataset(X_val_imputed, y_val)\n",
    "test_dataset  = TabularDataset(X_test_imputed, y_test)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 16 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "input_dim = X_train_imputed.shape[1]\n",
    "print(f\"Input dim: {input_dim}, Train samples: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ee079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2. Transformer Regression Model (TFT-style)\n",
    "# =========================\n",
    "\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        d_model=64,\n",
    "        nhead=4,\n",
    "        num_layers=2,\n",
    "        dim_feedforward=128,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Project feature vector -> model dimension\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Output head\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, input_dim)\n",
    "        We treat features as a single 'token':\n",
    "          - project to d_model\n",
    "          - add fake sequence dimension of length 1\n",
    "        \"\"\"\n",
    "        # (B, F) -> (B, d_model)\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        # (B, d_model) -> (B, 1, d_model)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Transformer encoder (sequence length = 1 here)\n",
    "        x = self.encoder(x)  # (B, 1, d_model)\n",
    "\n",
    "        # Pool over sequence dimension (trivial when seq_len=1)\n",
    "        x = x.mean(dim=1)    # (B, d_model)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc_out(x).squeeze(-1)  # (B,)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3. Training & Evaluation\n",
    "# =========================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = TransformerRegressor(input_dim,\n",
    "        d_model=64,\n",
    "        nhead=4,\n",
    "        num_layers=2,\n",
    "        dim_feedforward=128,\n",
    "        dropout=0.1).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=5\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ---------- helper: RMSE ----------\n",
    "def compute_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# ---------- helper: one epoch ----------\n",
    "def run_epoch(loader, model, criterion, optimizer=None):\n",
    "    \"\"\"\n",
    "    If optimizer is provided -> training mode\n",
    "    Otherwise -> evaluation mode\n",
    "    \"\"\"\n",
    "    if optimizer is not None:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.set_grad_enabled(optimizer is not None):\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * X_batch.size(0)\n",
    "            all_preds.append(preds.detach().cpu().numpy())\n",
    "            all_targets.append(y_batch.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    return avg_loss, all_preds, all_targets\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TRAINING LOOP (Transformer model)\n",
    "# =========================\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_rmse\": [],\n",
    "    \"val_rmse\": []\n",
    "}\n",
    "\n",
    "num_epochs = 150\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # -------- TRAIN --------\n",
    "    train_loss, train_preds, train_targets = run_epoch(\n",
    "        train_loader, model, criterion, optimizer\n",
    "    )\n",
    "    train_rmse = compute_rmse(train_targets, train_preds)\n",
    "\n",
    "    # -------- VAL --------\n",
    "    val_loss, val_preds, val_targets = run_epoch(\n",
    "        val_loader, model, criterion, optimizer=None\n",
    "    )\n",
    "    val_rmse = compute_rmse(val_targets, val_preds)\n",
    "\n",
    "    # Scheduler (optional, if you defined it)\n",
    "    try:\n",
    "        scheduler.step(val_loss)\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    # Save history\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"train_rmse\"].append(train_rmse)\n",
    "    history[\"val_rmse\"].append(val_rmse)\n",
    "\n",
    "    # Track best model by val_loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state = model.state_dict()\n",
    "\n",
    "    # -------- PRINT in your format --------\n",
    "    if epoch == 0 or (epoch % 20 == 0) or epoch == num_epochs - 1:\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs} | \"\n",
    "            f\"Train RMSE: {train_rmse:.2f} | Val RMSE: {val_rmse:.2f}\"\n",
    "        )\n",
    "\n",
    "# Load best weights\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "print(f\"\\nBest validation loss (RMSE): {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8217bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(len(history[\"train_loss\"]))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, history[\"train_rmse\"], label=\"Train Loss (RMSE)\")\n",
    "plt.plot(epochs, history[\"val_rmse\"], label=\"Val Loss (RMSE)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (RMSE)\")\n",
    "plt.title(\"Transformer Model – Train vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss, test_preds, test_targets = run_epoch(\n",
    "    test_loader, model, criterion, optimizer=None\n",
    ")\n",
    "\n",
    "# Flatten to 1D\n",
    "test_preds = test_preds.reshape(-1)\n",
    "test_targets = test_targets.reshape(-1)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(test_targets, test_preds))\n",
    "test_r2   = r2_score(test_targets, test_preds)\n",
    "\n",
    "print(f\"Test MSE:  {test_loss:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test R²:   {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def run_epoch(loader, model, criterion, optimizer=None):\n",
    "    \"\"\"\n",
    "    If optimizer is provided -> training mode\n",
    "    Otherwise -> evaluation mode\n",
    "    \"\"\"\n",
    "    if optimizer is not None:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.set_grad_enabled(optimizer is not None):\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * X_batch.size(0)\n",
    "            all_preds.append(preds.detach().cpu().numpy())\n",
    "            all_targets.append(y_batch.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    return avg_loss, all_preds, all_targets\n",
    "\n",
    "# convenience: create loaders for different batch sizes\n",
    "def create_dataloaders(batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "input_dim = train_dataset[0][0].shape[0]\n",
    "print(\"Input dim:\", input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # ---------- hyperparameters (around your current values) ----------\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 128])\n",
    "    nhead   = trial.suggest_categorical(\"nhead\", [2, 4, 8])\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 3])\n",
    "    dim_feedforward = trial.suggest_categorical(\"dim_feedforward\", [64, 128, 256])\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.05, 0.1, 0.2])\n",
    "    lr = trial.suggest_float(\"lr\", 5e-4,5e-3, log=True)           \n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    # Transformer requirement: d_model divisible by nhead\n",
    "    if d_model % nhead != 0:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # ---------- dataloaders ----------\n",
    "    train_loader, val_loader, _ = create_dataloaders(batch_size)\n",
    "\n",
    "    # ---------- model / optimizer / loss ----------\n",
    "    model = TransformerRegressor(\n",
    "        input_dim=input_dim,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout,\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    max_epochs = 80       # shorter than your full 150-epoch run\n",
    "    patience   = 10\n",
    "    best_val_rmse = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # ---- train ----\n",
    "        train_loss, train_preds, train_targets = run_epoch(\n",
    "            train_loader, model, criterion, optimizer\n",
    "        )\n",
    "\n",
    "        # ---- validate ----\n",
    "        val_loss, val_preds, val_targets = run_epoch(\n",
    "            val_loader, model, criterion, optimizer=None\n",
    "        )\n",
    "\n",
    "        val_rmse = compute_rmse(val_targets, val_preds)\n",
    "\n",
    "        # report to Optuna (for pruning / logging)\n",
    "        trial.report(val_rmse, step=epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        # early stopping on best RMSE\n",
    "        if val_rmse < best_val_rmse - 1e-3:\n",
    "            best_val_rmse = val_rmse\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "\n",
    "    # objective value = best validation RMSE seen in this trial\n",
    "    return best_val_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"Transformer_Optuna\"\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial value (Val RMSE):\", study.best_trial.value)\n",
    "print(\"Best trial params:\")\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization.matplotlib import (\n",
    "    plot_optimization_history,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_slice,\n",
    "    plot_param_importances,\n",
    ")\n",
    "\n",
    "def set_title_safe(ax, title):\n",
    "    if hasattr(ax, \"set_title\"):\n",
    "        ax.set_title(title)\n",
    "    else:\n",
    "        ax.flat[0].set_title(title)\n",
    "\n",
    "name = f\"{CHOSEN_CROP.capitalize()}_Yield_Transformer\" if \"CHOSEN_CROP\" in globals() else \"Yield_Transformer\"\n",
    "\n",
    "# 1. Optimization History\n",
    "ax = plot_optimization_history(study)\n",
    "set_title_safe(ax, f\"{name} – Optimization History\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Parallel Coordinate\n",
    "ax = plot_parallel_coordinate(study)\n",
    "set_title_safe(ax, f\"{name} – Parallel Coordinate\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Slice Plot\n",
    "ax = plot_slice(study)\n",
    "set_title_safe(ax, f\"{name} – Slice Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Parameter Importance\n",
    "try:\n",
    "    ax = plot_param_importances(study)\n",
    "    set_title_safe(ax, f\"{name} – Hyperparameter Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except (ValueError, RuntimeError) as e:\n",
    "    print(f\"Could not plot parameter importance: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "print(\"Best params for final model:\", best_params)\n",
    "\n",
    "# dataloaders using best batch size\n",
    "batch_size_best = best_params.get(\"batch_size\", 128)\n",
    "train_loader, val_loader, test_loader = create_dataloaders(batch_size_best)\n",
    "\n",
    "# final model\n",
    "final_model = TransformerRegressor(\n",
    "    input_dim=input_dim,\n",
    "    d_model=best_params[\"d_model\"],\n",
    "    nhead=best_params[\"nhead\"],\n",
    "    num_layers=best_params[\"num_layers\"],\n",
    "    dim_feedforward=best_params[\"dim_feedforward\"],\n",
    "    dropout=best_params[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=5\n",
    ")\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_rmse\": [],\n",
    "    \"val_rmse\": []\n",
    "}\n",
    "\n",
    "num_epochs = 150\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # ---- train ----\n",
    "    train_loss, train_preds, train_targets = run_epoch(\n",
    "        train_loader, model, criterion, optimizer\n",
    "    )\n",
    "    train_rmse = compute_rmse(train_targets, train_preds)\n",
    "\n",
    "    # ---- validate ----\n",
    "    val_loss, val_preds, val_targets = run_epoch(\n",
    "        val_loader, model, criterion, optimizer=None\n",
    "    )\n",
    "    val_rmse = compute_rmse(val_targets, val_preds)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # store history\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"train_rmse\"].append(train_rmse)\n",
    "    history[\"val_rmse\"].append(val_rmse)\n",
    "\n",
    "    # track best\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state = model.state_dict()\n",
    "\n",
    "    # print in your preferred style\n",
    "    if epoch == 0 or (epoch % 20 == 0) or epoch == num_epochs - 1:\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs} | \"\n",
    "            f\"Train RMSE: {train_rmse:.2f} | Val RMSE: {val_rmse:.2f}\"\n",
    "        )\n",
    "\n",
    "# load best weights\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "print(f\"\\nBest validation loss (MSE): {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bca9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- RMSE curves ----\n",
    "epochs = range(len(history[\"train_rmse\"]))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, history[\"train_rmse\"], label=\"Train RMSE\", linewidth=2)\n",
    "plt.plot(epochs, history[\"val_rmse\"], label=\"Validation RMSE\", linewidth=2)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Transformer – Train vs Validation RMSE (Best Hyperparams)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# ---- Test evaluation ----\n",
    "test_loss, final_test_preds, final_test_targets = run_epoch(\n",
    "    test_loader, model, criterion, optimizer=None\n",
    ")\n",
    "\n",
    "final_test_predstest_preds = test_preds.reshape(-1)\n",
    "final_test_targets = test_targets.reshape(-1)\n",
    "\n",
    "final_test_rmse = compute_rmse(test_targets, test_preds)\n",
    "final_test_r2   = r2_score(test_targets, test_preds)\n",
    "\n",
    "print(f\"Test MSE:  {test_loss:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test R²:   {test_r2:.4f}\")\n",
    "\n",
    "# optional: predicted vs true scatter\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(test_targets, test_preds, alpha=0.3)\n",
    "lim_min = min(test_targets.min(), test_preds.min())\n",
    "lim_max = max(test_targets.max(), test_preds.max())\n",
    "plt.plot([lim_min, lim_max], [lim_min, lim_max], linestyle=\"--\")\n",
    "plt.xlabel(\"True Yield\")\n",
    "plt.ylabel(\"Predicted Yield\")\n",
    "title_crop = CHOSEN_CROP if \"CHOSEN_CROP\" in globals() else \"Crop\"\n",
    "plt.title(f\"Transformer (Optuna Best) – {title_crop} – Test Set\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate Improvement %\n",
    "imp_final = (rmse_baseline - final_test_rmse) / rmse_baseline * 100\n",
    "\n",
    "print(\"--- Final Performance Report (Test Set, Transformer) ---\")\n",
    "print(f\"Baseline Model:     RMSE={rmse_baseline:.2f}, R2={r2_baseline:.4f}\")\n",
    "print(f\"Initial TFT Model:  RMSE={test_rmse:.2f}, R2={test_r2:.4f}\")\n",
    "print(f\"Tuned TFT Model:    RMSE={final_test_rmse:.2f}, R2={final_test_r2:.4f} \"\n",
    "      f\"(RMSE Improved {imp_final:.2f}%)\")\n",
    "\n",
    "# --- PLOTTING RESULTS ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Axis Limits (use all predictions & truths)\n",
    "all_preds = np.concatenate([y_pred_baseline,test_preds, final_test_preds])\n",
    "all_true  = np.concatenate([y_test_clean,y_test,y_test])\n",
    "\n",
    "min_val = min(all_preds.min(), all_true.min())\n",
    "max_val = max(all_preds.max(), all_true.max())\n",
    "\n",
    "# 1. Baseline Plot\n",
    "axes[0].scatter(y_test_clean, y_pred_clean, alpha=0.4)\n",
    "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[0].set_title(f'Baseline Model\\nRMSE: {rmse_baseline:.2f} | R2: {r2_baseline:.3f}')\n",
    "axes[0].set_xlabel(\"True\")\n",
    "axes[0].set_ylabel(\"Predicted\")\n",
    "\n",
    "# 2. Initial Transformer Plot\n",
    "axes[1].scatter(y_test, test_preds, alpha=0.4)\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[1].set_title(f'Initial TFT Model\\nRMSE: {test_rmse:.2f} | R2: {test_r2:.3f}')\n",
    "axes[1].set_xlabel(\"True\")\n",
    "\n",
    "# 3. Tuned Transformer Plot\n",
    "axes[2].scatter(y_test, final_test_preds, alpha=0.4)\n",
    "axes[2].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "axes[2].set_title(f'Tuned TFT Model\\nRMSE: {final_test_rmse:.2f} | R2: {final_test_r2:.3f}')\n",
    "axes[2].set_xlabel(\"True\")\n",
    "\n",
    "title_crop = CHOSEN_CROP if \"CHOSEN_CROP\" in globals() else \"Crop\"\n",
    "plt.suptitle(f'{title_crop.capitalize()} Yield – Transformer Baseline vs Initial vs Tuned',\n",
    "             fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FULL TIMELINE PLOT (FILTER BY COUNTRY) ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Country to plot (parameter)\n",
    "TARGET_COUNTRY = \"Thailand\"    # <<--- Change here anytime\n",
    "\n",
    "# 1. Generate Predictions for all data (scaled)\n",
    "X_all_scaled = scaler.transform(df_model[feature_cols])\n",
    "X_all_tensor = torch.tensor(X_all_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    all_predictions = final_model(X_all_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# 2. Create DataFrame with Area column\n",
    "df_full_trend = pd.DataFrame({\n",
    "    'Year': df_model['year'],\n",
    "    'Area': df_model['area'],\n",
    "    'Actual': df_model[TARGET_COL],\n",
    "    'Predicted': all_predictions\n",
    "})\n",
    "\n",
    "# 3. Filter for selected country\n",
    "country_trend = df_full_trend[df_full_trend['Area'] == TARGET_COUNTRY]\n",
    "\n",
    "# 4. Aggregate by Year\n",
    "yearly_trend = country_trend.groupby('Year')[['Actual', 'Predicted']].mean()\n",
    "\n",
    "# 5. Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(yearly_trend.index, yearly_trend['Actual'], \n",
    "         marker='o', label=f'Actual Yield ({TARGET_COUNTRY})', linewidth=2)\n",
    "plt.plot(yearly_trend.index, yearly_trend['Predicted'], \n",
    "         marker='x', linestyle='--', label=f'Predicted Yield ({TARGET_COUNTRY})', linewidth=2)\n",
    "\n",
    "# Define split boundaries\n",
    "MIN_YEAR = yearly_trend.index.min()\n",
    "MAX_YEAR = yearly_trend.index.max()\n",
    "train_boundary = TRAIN_END_YEAR - 0.5\n",
    "val_boundary   = VAL_END_YEAR - 0.5\n",
    "\n",
    "# Highlight training / validation / testing\n",
    "plt.axvspan(MIN_YEAR - 0.5, train_boundary, color='green',  alpha=0.1)\n",
    "plt.axvspan(train_boundary, val_boundary,   color='yellow', alpha=0.1)\n",
    "plt.axvspan(val_boundary, MAX_YEAR + 0.5,   color='red',    alpha=0.1)\n",
    "\n",
    "# Text labels\n",
    "y_max = yearly_trend['Actual'].max()\n",
    "text_y = y_max * 1.05\n",
    "\n",
    "plt.text((MIN_YEAR + train_boundary)/2, text_y, 'TRAINING',   ha='center', fontsize=12, fontweight='bold', color='green')\n",
    "plt.text((train_boundary + val_boundary)/2, text_y, 'VALIDATION', ha='center', fontsize=12, fontweight='bold', color='#D4AC0D')\n",
    "plt.text((val_boundary + MAX_YEAR)/2, text_y, 'TESTING',     ha='center', fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "# Final formatting\n",
    "plt.title(f'Full Timeline Analysis: Actual vs Predicted Yield ({CHOSEN_CROP}, {TARGET_COUNTRY})',\n",
    "          fontsize=16)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Yield (hg/ha)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(np.arange(MIN_YEAR, MAX_YEAR + 1, 2))\n",
    "plt.xlim(MIN_YEAR - 0.5, MAX_YEAR + 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
